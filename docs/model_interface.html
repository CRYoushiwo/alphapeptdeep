---

title: Model Interface


keywords: fastai
sidebar: home_sidebar



nb_path: "nbdev_nbs/model/model_interface.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbdev_nbs/model/model_interface.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Description">Description<a class="anchor-link" href="#Description"> </a></h2><p>This notebook mainly defines the basic interface that is used to interact with the deep learning models. Its 'public' functions are intended to stay untouched over the project, while the specific workings of the interface can be changed (i.e. programming polymorphism concept). For example, models can always be loaded with the <code>load()</code> function and details of the loading can be changed by inheriting the interface and changing the functions that <code>load()</code> calls. More details are given below.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Imports">Imports<a class="anchor-link" href="#Imports"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Utility-functions">Utility functions<a class="anchor-link" href="#Utility-functions"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_cosine_schedule_with_warmup" class="doc_header"><code>get_cosine_schedule_with_warmup</code><a href="https://github.com/MannLabs/peptdeep/tree/main/peptdeep/model/model_interface.py#L35" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_cosine_schedule_with_warmup</code>(<strong><code>optimizer</code></strong>, <strong><code>num_warmup_steps</code></strong>, <strong><code>num_training_steps</code></strong>, <strong><code>num_cycles</code></strong>=<em><code>0.5</code></em>, <strong><code>last_epoch</code></strong>=<em><code>-1</code></em>)</p>
</blockquote>
<p>Create a schedule with a learning rate that decreases following the
values of the cosine function between 0 and <code>pi * cycles</code> after a warmup
period during which it increases linearly between 0 and 1.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="append_nAA_column_if_missing" class="doc_header"><code>append_nAA_column_if_missing</code><a href="https://github.com/MannLabs/peptdeep/tree/main/peptdeep/model/model_interface.py#L56" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>append_nAA_column_if_missing</code>(<strong><code>precursor_df</code></strong>)</p>
</blockquote>
<p>column containing the number of Amino Acids</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Interface-Class">Interface Class<a class="anchor-link" href="#Interface-Class"> </a></h2><p>The <a href="/alphapeptdeep/model_interface.html#ModelInterface"><code>ModelInterface</code></a> below is intended to provide a standardized way to handle deep learning models. It does not contain the PyTorch-based models themselves, but provides methods to <code>load()</code>, <code>save()</code>, <code>build()</code>, <code>train()</code> and <code>predict()</code> new models. These methods are intended to stay unchanged. 
To adapt the interface to a new usecase, we inherit the interface in a new class and re-implement the relevant method <code>_get_features_from_batch_df()</code>. Sometimes we also need to re-implement <code>_get_targets_from_batch_df()</code> and <code>_prepare_predict_data_df()</code>.</p>
<p>The interface will adapt the training and prediction procedures. The implementation below will automatically empty the GPU cache at the end of <code>train()</code> and <code>predict()</code> to save GPU memory.</p>
<p>For example, if we would like to design a new model for peptides with different purposes, for example RT prediction, we need to:</p>
<ul>
<li>Design the pytorch model (<code>class RTPrediction(torch.nn.Module):...</code>).</li>
<li>Design the sub-class inherited from ModelInterface (<code>class RTPredictionModel(ModelInterface):...</code>).</li>
<li>In <code>__init__</code> method, define <code>self.target_column_to_train = "detect_value"</code> and <code>self.target_column_to_predict = "predict_value"</code>. Also define <code>self._min_pred_value = some_value</code>.</li>
<li><p>Re-implement <code>def _get_features_from_batch_df(self, batch_df): return self._get_aa_indice_features(batch_df)</code> (default) to predict property for sequence. For modified sequence, use <code>def _get_features_from_batch_df(self, batch_df): return self._get_aa_mod_features(batch_df)</code>.</p>
</li>
<li><p>At last, execute the model in a python script or a notebook:</p>

<pre><code>model = RTPredictionModel()
model.build(model_class=RTPrediction)
df = ... # the training data
model.train(df)
pred_df = model.predict(df)</code></pre>
</li>
</ul>
<p>Check out <code>peptdeep.model.generic_property_prediction</code> for details. <code>peptdeep.model.rt.AlphaRTModel</code> and <code>peptdeep.model.ccs.AlphaCCSModel</code> are also similar. MS2 prediction model is more complicated as the output value for a peptide is not a scalar value, see <code>peptdeep.model.ms2.pDeepModel</code>.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ModelInterface" class="doc_header"><code>class</code> <code>ModelInterface</code><a href="https://github.com/MannLabs/peptdeep/tree/main/peptdeep/model/model_interface.py#L67" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ModelInterface</code>(<strong><code>device</code></strong>:<code>str</code>=<em><code>'gpu'</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Provides standardized methods to interact
with ml models. Inherit into new class and override
the abstract (i.e. not implemented) methods.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Testing-the-APIs">Testing the APIs<a class="anchor-link" href="#Testing-the-APIs"> </a></h1><p>Building a model for peptide classification (e.g. detectability)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First, design the <code>torch.nn.Module</code> (Transformer model)</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">peptdeep.model.building_block</span> <span class="k">as</span> <span class="nn">building_block</span>

<span class="k">class</span> <span class="nc">Test_Bert</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
        <span class="n">nlayers</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">input_dim</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="c1">#ascii code number</span>
        <span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.1</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Model based on a transformer Architecture from </span>
<span class="sd">        Huggingface&#39;s BertEncoder class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_nn</span> <span class="o">=</span>  <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">building_block</span><span class="o">.</span><span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_nn</span> <span class="o">=</span> <span class="n">building_block</span><span class="o">.</span><span class="n">Hidden_HFace_Transformer</span><span class="p">(</span>
            <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">nlayers</span><span class="o">=</span><span class="n">nlayers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">output_nn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">building_block</span><span class="o">.</span><span class="n">SeqAttentionSum</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_nn</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_nn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_nn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Second, implement the ModelInterface APIs</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Test_Model</span><span class="p">(</span><span class="n">ModelInterface</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">model_class</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="o">=</span><span class="n">Test_Bert</span><span class="p">,</span> <span class="c1">#model class defined above</span>
        <span class="n">device</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="s1">&#39;gpu&#39;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
            <span class="n">model_class</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_func</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span> <span class="c1"># loss for binary classification</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_column_to_predict</span> <span class="o">=</span> <span class="s1">&#39;predicted_prob&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_column_to_train</span> <span class="o">=</span> <span class="s1">&#39;detected_prob&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Last, test the model</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;sequence&#39;</span><span class="p">:[</span><span class="s1">&#39;ABCD&#39;</span><span class="p">]</span><span class="o">*</span><span class="mi">10</span><span class="p">,</span>
<span class="p">})</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;detected_prob&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Test_Model</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="k">assert</span> <span class="s1">&#39;predicted_prob&#39;</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span>
<span class="n">df</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sequence</th>
      <th>detected_prob</th>
      <th>nAA</th>
      <th>predicted_prob</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ABCD</td>
      <td>1.0</td>
      <td>4</td>
      <td>0.781049</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ABCD</td>
      <td>1.0</td>
      <td>4</td>
      <td>0.781049</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ABCD</td>
      <td>1.0</td>
      <td>4</td>
      <td>0.781049</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ABCD</td>
      <td>1.0</td>
      <td>4</td>
      <td>0.781049</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ABCD</td>
      <td>1.0</td>
      <td>4</td>
      <td>0.781049</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ABCD</td>
      <td>1.0</td>
      <td>4</td>
      <td>0.781049</td>
    </tr>
    <tr>
      <th>6</th>
      <td>ABCD</td>
      <td>1.0</td>
      <td>4</td>
      <td>0.781049</td>
    </tr>
    <tr>
      <th>7</th>
      <td>ABCD</td>
      <td>1.0</td>
      <td>4</td>
      <td>0.781049</td>
    </tr>
    <tr>
      <th>8</th>
      <td>ABCD</td>
      <td>1.0</td>
      <td>4</td>
      <td>0.781049</td>
    </tr>
    <tr>
      <th>9</th>
      <td>ABCD</td>
      <td>1.0</td>
      <td>4</td>
      <td>0.781049</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Test-build_from_py_codes()">Test <code>build_from_py_codes()</code><a class="anchor-link" href="#Test-build_from_py_codes()"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">peptdeep.model.ms2</span> <span class="kn">import</span> <span class="n">pDeepModel</span>
<span class="kn">from</span> <span class="nn">peptdeep.pretrained_models</span> <span class="kn">import</span> <span class="n">model_zip</span>
<span class="n">ms2_model</span> <span class="o">=</span> <span class="n">pDeepModel</span><span class="p">()</span>
<span class="n">ms2_model</span><span class="o">.</span><span class="n">build_from_py_codes</span><span class="p">(</span>
    <span class="n">model_zip</span><span class="p">,</span> <span class="s1">&#39;generic/ms2.pth.model.py&#39;</span><span class="p">,</span> 
    <span class="n">include_model_params_yaml</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">ms2_model</span><span class="o">.</span><span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Model(
  (dropout): Dropout(p=0.1, inplace=False)
  (input_nn): Input_AA_Mod_PositionalEncoding(
    (mod_nn): Mod_Embedding_FixFirstK(
      (nn): Linear(in_features=103, out_features=2, bias=False)
    )
    (aa_emb): Embedding(27, 240, padding_idx=0)
    (pos_encoder): PositionalEncoding()
  )
  (meta_nn): Meta_Embedding(
    (nn): Linear(in_features=9, out_features=7, bias=True)
  )
  (hidden_nn): Hidden_HFace_Transformer(
    (bert): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=256, out_features=256, bias=True)
              (key): Linear(in_features=256, out_features=256, bias=True)
              (value): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=256, out_features=256, bias=True)
              (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=256, out_features=1024, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=1024, out_features=256, bias=True)
            (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=256, out_features=256, bias=True)
              (key): Linear(in_features=256, out_features=256, bias=True)
              (value): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=256, out_features=256, bias=True)
              (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=256, out_features=1024, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=1024, out_features=256, bias=True)
            (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=256, out_features=256, bias=True)
              (key): Linear(in_features=256, out_features=256, bias=True)
              (value): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=256, out_features=256, bias=True)
              (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=256, out_features=1024, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=1024, out_features=256, bias=True)
            (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=256, out_features=256, bias=True)
              (key): Linear(in_features=256, out_features=256, bias=True)
              (value): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=256, out_features=256, bias=True)
              (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=256, out_features=1024, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=1024, out_features=256, bias=True)
            (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (output_nn): Decoder_Linear(
    (nn): Sequential(
      (0): Linear(in_features=256, out_features=64, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=64, out_features=4, bias=True)
    )
  )
  (modloss_nn): ModuleList(
    (0): Hidden_HFace_Transformer(
      (bert): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=256, out_features=256, bias=True)
                (key): Linear(in_features=256, out_features=256, bias=True)
                (value): Linear(in_features=256, out_features=256, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=256, out_features=256, bias=True)
                (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=256, out_features=1024, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=1024, out_features=256, bias=True)
              (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (1): Decoder_Linear(
      (nn): Sequential(
        (0): Linear(in_features=256, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
        (2): Linear(in_features=64, out_features=4, bias=True)
      )
    )
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

