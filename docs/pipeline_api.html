---

title: *The high-level pipeline APIs


keywords: fastai
sidebar: home_sidebar



nb_path: "nbdev_nbs/pipeline_api.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbdev_nbs/pipeline_api.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="load_settings" class="doc_header"><code>load_settings</code><a href="https://github.com/MannLabs/alphapeptdeep/tree/main/peptdeep/pipeline_api.py#L36" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>load_settings</code>(<strong><code>settings_yaml</code></strong>:<code>str</code>)</p>
</blockquote>
<p>Load settings yaml file into
<code>peptdeep.settings.global_settings</code> (dict).</p>
<h2 id="Parameters">Parameters<a class="anchor-link" href="#Parameters"> </a></h2><p>settings_yaml : str
    The settings yaml file.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Transfer-learning-pipeline">Transfer learning pipeline<a class="anchor-link" href="#Transfer-learning-pipeline"> </a></h2><p>Transfer learning pipeline includes:</p>
<ol>
<li>Loading PSM files of the search engine results.</li>
<li>Matching PSMs against the MS files.</li>
<li>Loading pre-trained models and refining RT/CCS(/MS2) models.</li>
</ol>
<p>The refined models will be saved in the path pointed by "PEPTDEEP_HOME" in <code>peptdeep.settings.global_settings</code>.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="import_psm_df" class="doc_header"><code>import_psm_df</code><a href="https://github.com/MannLabs/alphapeptdeep/tree/main/peptdeep/pipeline_api.py#L52" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>import_psm_df</code>(<strong><code>psm_files</code></strong>:<code>list</code>, <strong><code>psm_type</code></strong>:<code>str</code>)</p>
</blockquote>
<p>Import PSM files of a search engine as a pd.DataFrame</p>
<h2 id="Parameters">Parameters<a class="anchor-link" href="#Parameters"> </a></h2><p>psm_files : list of str
    PSM file paths
psm_type : str
    PSM type or search engine name/type</p>
<h2 id="Returns">Returns<a class="anchor-link" href="#Returns"> </a></h2><p>pd.DataFrame
    DataFrame that contains all PSM information</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="match_psms" class="doc_header"><code>match_psms</code><a href="https://github.com/MannLabs/alphapeptdeep/tree/main/peptdeep/pipeline_api.py#L78" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>match_psms</code>(<strong><code>settings_dict</code></strong>:<code>dict</code>=<em><code>{'model': {'frag_types': ['b', 'y', 'b_modloss', 'y_modloss'], 'max_frag_charge': 2}, 'PEPTDEEP_HOME': '~/peptdeep', 'local_model_zip_name': 'pretrained_models.zip', 'model_url': 'https://github.com/MannLabs/alphapeptdeep/releases/download/pre-trained-models/pretrained_models.zip', 'thread_num': 8, 'log_level': 'info', 'log_level_choices': ['debug', 'info', 'warning', 'error', 'critical'], 'common': {'modloss_importance_level': 1.0}, 'peak_matching': {'ms2_ppm': True, 'ms2_tol_value': 20.0, 'ms1_ppm': True, 'ms1_tol_value': 20.0}, 'model_mgr': {'default_nce': 30.0, 'default_instrument': 'Lumos', 'mask_modloss': True, 'model_type': 'generic', 'model_choices': ['generic', 'phos', 'hla', 'digly'], 'external_ms2_model': '', 'external_rt_model': '', 'external_ccs_model': '', 'instrument_group': {'Lumos': 'Lumos', 'QE': 'QE', 'timsTOF': 'timsTOF', 'SciexTOF': 'SciexTOF', 'Fusion': 'Lumos', 'Eclipse': 'Lumos', 'Velos': 'Lumos', 'Elite': 'Lumos', 'OrbitrapTribrid': 'Lumos', 'ThermoTribrid': 'Lumos', 'QE+': 'QE', 'QEHF': 'QE', 'QEHFX': 'QE', 'Exploris': 'QE', 'Exploris480': 'QE', 'LUMOS': 'Lumos', 'TIMSTOF': 'timsTOF', 'SCIEXTOF': 'SciexTOF', 'FUSION': 'Lumos', 'ECLIPSE': 'Lumos', 'VELOS': 'Lumos', 'ELITE': 'Lumos', 'ORBITRAPTRIBRID': 'Lumos', 'THERMOTRIBRID': 'Lumos', 'EXPLORIS': 'QE', 'EXPLORIS480': 'QE'}, 'predict': {'batch_size_ms2': 512, 'batch_size_rt_ccs': 1024, 'verbose': True, 'multiprocessing': True}, 'transfer': {'model_output_folder': '', 'epoch_ms2': 20, 'warmup_epoch_ms2': 10, 'batch_size_ms2': 512, 'lr_ms2': 0.0001, 'epoch_rt_ccs': 40, 'warmup_epoch_rt_ccs': 10, 'batch_size_rt_ccs': 1024, 'lr_rt_ccs': 0.0001, 'verbose': False, 'grid_nce_search': True, 'grid_nce_first': 15.0, 'grid_nce_last': 45.0, 'grid_nce_step': 3.0, 'grid_instrument': ['Lumos'], 'psm_type': 'alphapept', 'psm_type_choices': ['alphapept', 'pfind', 'maxquant', 'diann', 'speclib_tsv'], 'psm_files': [], 'ms_file_type': 'alphapept_hdf', 'ms_file_type_choices': ['alphapept_hdf', 'thermo_raw', 'mgf', 'mzml'], 'ms_files': [], 'psm_num_to_train_ms2': 100000000, 'psm_num_per_mod_to_train_ms2': 50, 'psm_num_to_train_rt_ccs': 100000000, 'psm_num_per_mod_to_train_rt_ccs': 50, 'top_n_mods_to_train': 10}}, 'percolator': {'require_model_tuning': True, 'raw_num_to_tune': 8, 'require_raw_specific_tuning': True, 'raw_specific_ms2_tuning': False, 'psm_num_per_raw_to_tune': 200, 'epoch_per_raw_to_tune': 5, 'multiprocessing': True, 'top_k_frags_to_calc_spc': 10, 'ms2_ppm': True, 'ms2_tol': 20, 'calibrate_frag_mass_error': False, 'max_perc_train_sample': 1000000, 'min_perc_train_sample': 100, 'percolator_backend': 'sklearn', 'percolator_backend_choices': ['sklearn', 'pytorch'], 'percolator_model': 'linear', 'percolator_model_choices': {'pytorch_as_backend': ['linear', 'mlp'], 'sklearn_as_backend': ['linear', 'random_forest']}, 'lr_percolator_torch_model': 0.1, 'percolator_iter_num': 5, 'cv_fold': 1, 'fdr': 0.01, 'fdr_level': 'psm', 'fdr_level_choices': ['psm', 'precursor', 'peptide', 'sequence'], 'use_fdr_for_each_raw': False, 'frag_types': ['b_z1', 'b_z2', 'y_z1', 'y_z2'], 'input_files': {'psm_type': 'alphapept', 'psm_type_choices': ['alphapept', 'pfind', 'maxquant'], 'psm_files': [], 'ms_file_type': 'alphapept_hdf', 'ms_file_type_choices': ['hdf', 'thermo_raw', 'mgf', 'mzml'], 'ms_files': [], 'other_score_column_mapping': {'alphapept': {}, 'pfind': {'raw_score': 'Raw_Score'}, 'msfragger': {'hyperscore': 'hyperscore', 'nextscore': 'nextscore'}, 'maxquant': {}}}, 'output_folder': 'C:/datasets/percolaotr'}, 'library': {'input': {'type': 'fasta', 'type_choices': ['fasta', 'sequence_table', 'peptide_table', 'precursor_table'], 'paths': ['xxx.fasta'], 'fasta': {'protease': '([KR])', 'protease_choices': ['trypsin/P', '([KR])', 'trypsin', '([KR](?=[^P]))', 'lys-c', 'K', 'lys-n', '\\w(?=K)', 'chymotrypsin'], 'max_miss_cleave': 2}, 'fix_mods': ['Carbamidomethyl@C'], 'var_mods': ['Oxidation@M'], 'min_var_mod_num': 0, 'max_var_mod_num': 2, 'min_precursor_charge': 2, 'max_precursor_charge': 4, 'min_peptide_len': 7, 'max_peptide_len': 35, 'min_precursor_mz': 200.0, 'max_precursor_mz': 2000.0, 'decoy': 'pseudo_reverse', 'decoy_choices': ['pseudo_reverse', 'diann', 'None'], 'max_frag_charge': 2, 'frag_types': ['b', 'y']}, 'output_folder': '~/peptdeep_library', 'output_tsv': {'enabled': False, 'min_fragment_mz': 200, 'max_fragment_mz': 2000, 'min_relative_intensity': 0.01, 'keep_higest_k_peaks': 12, 'translate_batch_size': 1000000, 'translate_mod_to_unimod_id': False}}}</code></em>)</p>
</blockquote>
<p>Match the PSMs against the MS files.</p>
<p>All required information is in settings_dict:</p>

<pre><code>mgr_settings = settings_dict['model_mgr']
mgr_settings['transfer']['psm_files'] # list. PSM file paths
mgr_settings['transfer']['psm_type'] # str. PSM type or earch engine type
mgr_settings['transfer']['ms_files'] # list. MS files or RAW files
mgr_settings['transfer']['ms_file_type'] # str. MS file type
settings_dict['model']['frag_types'] # list. Fragment types to be considered, e.g. b_z1, y_modloss_z2 ...
settings_dict['model']['max_frag_charge'] # int. Max fragment charge to be considered
settings_dict['peak_matching']['ms2_ppm'] # bool. If use ppm as MS2 tolerance
settings_dict['peak_matching']['ms2_tol_value'] # float. MS2 tolerance value</code></pre>
<h2 id="Parameters">Parameters<a class="anchor-link" href="#Parameters"> </a></h2><p>settings_dict : dict, optional
    The settings dict, by default <code>peptdeep.settings.global_settings</code>.</p>
<h2 id="Returns">Returns<a class="anchor-link" href="#Returns"> </a></h2><p>tuple of pd.DataFrame
    The PSM DataFrame and the matched fragment intensity DataFrame</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="transfer_learn" class="doc_header"><code>transfer_learn</code><a href="https://github.com/MannLabs/alphapeptdeep/tree/main/peptdeep/pipeline_api.py#L149" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>transfer_learn</code>(<strong><code>settings_dict</code></strong>:<code>dict</code>=<em><code>{'model': {'frag_types': ['b', 'y', 'b_modloss', 'y_modloss'], 'max_frag_charge': 2}, 'PEPTDEEP_HOME': '~/peptdeep', 'local_model_zip_name': 'pretrained_models.zip', 'model_url': 'https://github.com/MannLabs/alphapeptdeep/releases/download/pre-trained-models/pretrained_models.zip', 'thread_num': 8, 'log_level': 'info', 'log_level_choices': ['debug', 'info', 'warning', 'error', 'critical'], 'common': {'modloss_importance_level': 1.0}, 'peak_matching': {'ms2_ppm': True, 'ms2_tol_value': 20.0, 'ms1_ppm': True, 'ms1_tol_value': 20.0}, 'model_mgr': {'default_nce': 30.0, 'default_instrument': 'Lumos', 'mask_modloss': True, 'model_type': 'generic', 'model_choices': ['generic', 'phos', 'hla', 'digly'], 'external_ms2_model': '', 'external_rt_model': '', 'external_ccs_model': '', 'instrument_group': {'Lumos': 'Lumos', 'QE': 'QE', 'timsTOF': 'timsTOF', 'SciexTOF': 'SciexTOF', 'Fusion': 'Lumos', 'Eclipse': 'Lumos', 'Velos': 'Lumos', 'Elite': 'Lumos', 'OrbitrapTribrid': 'Lumos', 'ThermoTribrid': 'Lumos', 'QE+': 'QE', 'QEHF': 'QE', 'QEHFX': 'QE', 'Exploris': 'QE', 'Exploris480': 'QE', 'LUMOS': 'Lumos', 'TIMSTOF': 'timsTOF', 'SCIEXTOF': 'SciexTOF', 'FUSION': 'Lumos', 'ECLIPSE': 'Lumos', 'VELOS': 'Lumos', 'ELITE': 'Lumos', 'ORBITRAPTRIBRID': 'Lumos', 'THERMOTRIBRID': 'Lumos', 'EXPLORIS': 'QE', 'EXPLORIS480': 'QE'}, 'predict': {'batch_size_ms2': 512, 'batch_size_rt_ccs': 1024, 'verbose': True, 'multiprocessing': True}, 'transfer': {'model_output_folder': '', 'epoch_ms2': 20, 'warmup_epoch_ms2': 10, 'batch_size_ms2': 512, 'lr_ms2': 0.0001, 'epoch_rt_ccs': 40, 'warmup_epoch_rt_ccs': 10, 'batch_size_rt_ccs': 1024, 'lr_rt_ccs': 0.0001, 'verbose': False, 'grid_nce_search': True, 'grid_nce_first': 15.0, 'grid_nce_last': 45.0, 'grid_nce_step': 3.0, 'grid_instrument': ['Lumos'], 'psm_type': 'alphapept', 'psm_type_choices': ['alphapept', 'pfind', 'maxquant', 'diann', 'speclib_tsv'], 'psm_files': [], 'ms_file_type': 'alphapept_hdf', 'ms_file_type_choices': ['alphapept_hdf', 'thermo_raw', 'mgf', 'mzml'], 'ms_files': [], 'psm_num_to_train_ms2': 100000000, 'psm_num_per_mod_to_train_ms2': 50, 'psm_num_to_train_rt_ccs': 100000000, 'psm_num_per_mod_to_train_rt_ccs': 50, 'top_n_mods_to_train': 10}}, 'percolator': {'require_model_tuning': True, 'raw_num_to_tune': 8, 'require_raw_specific_tuning': True, 'raw_specific_ms2_tuning': False, 'psm_num_per_raw_to_tune': 200, 'epoch_per_raw_to_tune': 5, 'multiprocessing': True, 'top_k_frags_to_calc_spc': 10, 'ms2_ppm': True, 'ms2_tol': 20, 'calibrate_frag_mass_error': False, 'max_perc_train_sample': 1000000, 'min_perc_train_sample': 100, 'percolator_backend': 'sklearn', 'percolator_backend_choices': ['sklearn', 'pytorch'], 'percolator_model': 'linear', 'percolator_model_choices': {'pytorch_as_backend': ['linear', 'mlp'], 'sklearn_as_backend': ['linear', 'random_forest']}, 'lr_percolator_torch_model': 0.1, 'percolator_iter_num': 5, 'cv_fold': 1, 'fdr': 0.01, 'fdr_level': 'psm', 'fdr_level_choices': ['psm', 'precursor', 'peptide', 'sequence'], 'use_fdr_for_each_raw': False, 'frag_types': ['b_z1', 'b_z2', 'y_z1', 'y_z2'], 'input_files': {'psm_type': 'alphapept', 'psm_type_choices': ['alphapept', 'pfind', 'maxquant'], 'psm_files': [], 'ms_file_type': 'alphapept_hdf', 'ms_file_type_choices': ['hdf', 'thermo_raw', 'mgf', 'mzml'], 'ms_files': [], 'other_score_column_mapping': {'alphapept': {}, 'pfind': {'raw_score': 'Raw_Score'}, 'msfragger': {'hyperscore': 'hyperscore', 'nextscore': 'nextscore'}, 'maxquant': {}}}, 'output_folder': 'C:/datasets/percolaotr'}, 'library': {'input': {'type': 'fasta', 'type_choices': ['fasta', 'sequence_table', 'peptide_table', 'precursor_table'], 'paths': ['xxx.fasta'], 'fasta': {'protease': '([KR])', 'protease_choices': ['trypsin/P', '([KR])', 'trypsin', '([KR](?=[^P]))', 'lys-c', 'K', 'lys-n', '\\w(?=K)', 'chymotrypsin'], 'max_miss_cleave': 2}, 'fix_mods': ['Carbamidomethyl@C'], 'var_mods': ['Oxidation@M'], 'min_var_mod_num': 0, 'max_var_mod_num': 2, 'min_precursor_charge': 2, 'max_precursor_charge': 4, 'min_peptide_len': 7, 'max_peptide_len': 35, 'min_precursor_mz': 200.0, 'max_precursor_mz': 2000.0, 'decoy': 'pseudo_reverse', 'decoy_choices': ['pseudo_reverse', 'diann', 'None'], 'max_frag_charge': 2, 'frag_types': ['b', 'y']}, 'output_folder': '~/peptdeep_library', 'output_tsv': {'enabled': False, 'min_fragment_mz': 200, 'max_fragment_mz': 2000, 'min_relative_intensity': 0.01, 'keep_higest_k_peaks': 12, 'translate_batch_size': 1000000, 'translate_mod_to_unimod_id': False}}}</code></em>, <strong><code>verbose</code></strong>=<em><code>True</code></em>)</p>
</blockquote>
<p>Transfer learn / refine the RT/CCS(/MS2) models.</p>
<p>All required information in settings_dict:</p>

<pre><code>mgr_settings = settings_dict['model_mgr']
mgr_settings['transfer']['verbose'] = verbose # bool
settings_dict['PEPTDEEP_HOME'] # str. The folder to store all refined models. By default "~/peptdeep".</code></pre>
<p>For transfer learning of MS2 model, the required information:</p>

<pre><code>mgr_settings['transfer']['psm_files'] # list. PSM file paths
mgr_settings['transfer']['psm_type'] # str. PSM type or earch engine type
mgr_settings['transfer']['ms_files'] # list. MS files or RAW files
mgr_settings['transfer']['ms_file_type'] # str. MS file type
settings_dict['model']['frag_types'] # list. Fragment types to be considered, e.g. b_z1, y_modloss_z2 ...
settings_dict['model']['max_frag_charge'] # int. Max fragment charge to be considered
settings_dict['peak_matching']['ms2_ppm'] # bool. If use ppm as MS2 tolerance
settings_dict['peak_matching']['ms2_tol_value'] # float. MS2 tolerance value</code></pre>
<h2 id="Parameters">Parameters<a class="anchor-link" href="#Parameters"> </a></h2><p>settings_dict : dict, optional
    The settings dict, by default <code>peptdeep.settings.global_settings</code>.
verbose : bool, optional
    Print the training details, by default True</p>
<h2 id="Raises">Raises<a class="anchor-link" href="#Raises"> </a></h2><p>Exception
    Any kinds of exception if the pipeline fails.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Library-generation-pipeline">Library generation pipeline<a class="anchor-link" href="#Library-generation-pipeline"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="generate_library" class="doc_header"><code>generate_library</code><a href="https://github.com/MannLabs/alphapeptdeep/tree/main/peptdeep/pipeline_api.py#L251" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>generate_library</code>(<strong><code>settings_dict</code></strong>:<code>dict</code>=<em><code>{'model': {'frag_types': ['b', 'y', 'b_modloss', 'y_modloss'], 'max_frag_charge': 2}, 'PEPTDEEP_HOME': '~/peptdeep', 'local_model_zip_name': 'pretrained_models.zip', 'model_url': 'https://github.com/MannLabs/alphapeptdeep/releases/download/pre-trained-models/pretrained_models.zip', 'thread_num': 8, 'log_level': 'info', 'log_level_choices': ['debug', 'info', 'warning', 'error', 'critical'], 'common': {'modloss_importance_level': 1.0}, 'peak_matching': {'ms2_ppm': True, 'ms2_tol_value': 20.0, 'ms1_ppm': True, 'ms1_tol_value': 20.0}, 'model_mgr': {'default_nce': 30.0, 'default_instrument': 'Lumos', 'mask_modloss': True, 'model_type': 'generic', 'model_choices': ['generic', 'phos', 'hla', 'digly'], 'external_ms2_model': '', 'external_rt_model': '', 'external_ccs_model': '', 'instrument_group': {'Lumos': 'Lumos', 'QE': 'QE', 'timsTOF': 'timsTOF', 'SciexTOF': 'SciexTOF', 'Fusion': 'Lumos', 'Eclipse': 'Lumos', 'Velos': 'Lumos', 'Elite': 'Lumos', 'OrbitrapTribrid': 'Lumos', 'ThermoTribrid': 'Lumos', 'QE+': 'QE', 'QEHF': 'QE', 'QEHFX': 'QE', 'Exploris': 'QE', 'Exploris480': 'QE', 'LUMOS': 'Lumos', 'TIMSTOF': 'timsTOF', 'SCIEXTOF': 'SciexTOF', 'FUSION': 'Lumos', 'ECLIPSE': 'Lumos', 'VELOS': 'Lumos', 'ELITE': 'Lumos', 'ORBITRAPTRIBRID': 'Lumos', 'THERMOTRIBRID': 'Lumos', 'EXPLORIS': 'QE', 'EXPLORIS480': 'QE'}, 'predict': {'batch_size_ms2': 512, 'batch_size_rt_ccs': 1024, 'verbose': True, 'multiprocessing': True}, 'transfer': {'model_output_folder': '', 'epoch_ms2': 20, 'warmup_epoch_ms2': 10, 'batch_size_ms2': 512, 'lr_ms2': 0.0001, 'epoch_rt_ccs': 40, 'warmup_epoch_rt_ccs': 10, 'batch_size_rt_ccs': 1024, 'lr_rt_ccs': 0.0001, 'verbose': False, 'grid_nce_search': True, 'grid_nce_first': 15.0, 'grid_nce_last': 45.0, 'grid_nce_step': 3.0, 'grid_instrument': ['Lumos'], 'psm_type': 'alphapept', 'psm_type_choices': ['alphapept', 'pfind', 'maxquant', 'diann', 'speclib_tsv'], 'psm_files': [], 'ms_file_type': 'alphapept_hdf', 'ms_file_type_choices': ['alphapept_hdf', 'thermo_raw', 'mgf', 'mzml'], 'ms_files': [], 'psm_num_to_train_ms2': 100000000, 'psm_num_per_mod_to_train_ms2': 50, 'psm_num_to_train_rt_ccs': 100000000, 'psm_num_per_mod_to_train_rt_ccs': 50, 'top_n_mods_to_train': 10}}, 'percolator': {'require_model_tuning': True, 'raw_num_to_tune': 8, 'require_raw_specific_tuning': True, 'raw_specific_ms2_tuning': False, 'psm_num_per_raw_to_tune': 200, 'epoch_per_raw_to_tune': 5, 'multiprocessing': True, 'top_k_frags_to_calc_spc': 10, 'ms2_ppm': True, 'ms2_tol': 20, 'calibrate_frag_mass_error': False, 'max_perc_train_sample': 1000000, 'min_perc_train_sample': 100, 'percolator_backend': 'sklearn', 'percolator_backend_choices': ['sklearn', 'pytorch'], 'percolator_model': 'linear', 'percolator_model_choices': {'pytorch_as_backend': ['linear', 'mlp'], 'sklearn_as_backend': ['linear', 'random_forest']}, 'lr_percolator_torch_model': 0.1, 'percolator_iter_num': 5, 'cv_fold': 1, 'fdr': 0.01, 'fdr_level': 'psm', 'fdr_level_choices': ['psm', 'precursor', 'peptide', 'sequence'], 'use_fdr_for_each_raw': False, 'frag_types': ['b_z1', 'b_z2', 'y_z1', 'y_z2'], 'input_files': {'psm_type': 'alphapept', 'psm_type_choices': ['alphapept', 'pfind', 'maxquant'], 'psm_files': [], 'ms_file_type': 'alphapept_hdf', 'ms_file_type_choices': ['hdf', 'thermo_raw', 'mgf', 'mzml'], 'ms_files': [], 'other_score_column_mapping': {'alphapept': {}, 'pfind': {'raw_score': 'Raw_Score'}, 'msfragger': {'hyperscore': 'hyperscore', 'nextscore': 'nextscore'}, 'maxquant': {}}}, 'output_folder': 'C:/datasets/percolaotr'}, 'library': {'input': {'type': 'fasta', 'type_choices': ['fasta', 'sequence_table', 'peptide_table', 'precursor_table'], 'paths': ['xxx.fasta'], 'fasta': {'protease': '([KR])', 'protease_choices': ['trypsin/P', '([KR])', 'trypsin', '([KR](?=[^P]))', 'lys-c', 'K', 'lys-n', '\\w(?=K)', 'chymotrypsin'], 'max_miss_cleave': 2}, 'fix_mods': ['Carbamidomethyl@C'], 'var_mods': ['Oxidation@M'], 'min_var_mod_num': 0, 'max_var_mod_num': 2, 'min_precursor_charge': 2, 'max_precursor_charge': 4, 'min_peptide_len': 7, 'max_peptide_len': 35, 'min_precursor_mz': 200.0, 'max_precursor_mz': 2000.0, 'decoy': 'pseudo_reverse', 'decoy_choices': ['pseudo_reverse', 'diann', 'None'], 'max_frag_charge': 2, 'frag_types': ['b', 'y']}, 'output_folder': '~/peptdeep_library', 'output_tsv': {'enabled': False, 'min_fragment_mz': 200, 'max_fragment_mz': 2000, 'min_relative_intensity': 0.01, 'keep_higest_k_peaks': 12, 'translate_batch_size': 1000000, 'translate_mod_to_unimod_id': False}}}</code></em>)</p>
</blockquote>
<p>Generate/predict a spectral library.</p>
<p>All required information in settings_dict:</p>

<pre><code>lib_settings = settings_dict['library']
output_folder = lib_settings['output_folder'] # str. Output folder of the library
lib_settings['input']['type'] # str. Input type for the library, could be 'fasta', 'sequence', 'peptide', or 'precursor'
lib_settings['input']['paths'] # list of str. Input files to generate librarys
lib_settings['output_tsv']['enabled'] # bool. If output tsv for diann/spectronaut</code></pre>
<h2 id="Parameters">Parameters<a class="anchor-link" href="#Parameters"> </a></h2><p>settings_dict : dict, optional
    The settings dict, by default <code>peptdeep.settings.global_settings</code>.</p>
<h2 id="Raises">Raises<a class="anchor-link" href="#Raises"> </a></h2><p>Exception
    Any kinds of exception if the pipeline fails.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Rescoring-(percolator)-pipeline">Rescoring (percolator) pipeline<a class="anchor-link" href="#Rescoring-(percolator)-pipeline"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="rescore_psms" class="doc_header"><code>rescore_psms</code><a href="https://github.com/MannLabs/alphapeptdeep/tree/main/peptdeep/pipeline_api.py#L330" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>rescore_psms</code>(<strong><code>settings_dict</code></strong>:<code>dict</code>=<em><code>{'model': {'frag_types': ['b', 'y', 'b_modloss', 'y_modloss'], 'max_frag_charge': 2}, 'PEPTDEEP_HOME': '~/peptdeep', 'local_model_zip_name': 'pretrained_models.zip', 'model_url': 'https://github.com/MannLabs/alphapeptdeep/releases/download/pre-trained-models/pretrained_models.zip', 'thread_num': 8, 'log_level': 'info', 'log_level_choices': ['debug', 'info', 'warning', 'error', 'critical'], 'common': {'modloss_importance_level': 1.0}, 'peak_matching': {'ms2_ppm': True, 'ms2_tol_value': 20.0, 'ms1_ppm': True, 'ms1_tol_value': 20.0}, 'model_mgr': {'default_nce': 30.0, 'default_instrument': 'Lumos', 'mask_modloss': True, 'model_type': 'generic', 'model_choices': ['generic', 'phos', 'hla', 'digly'], 'external_ms2_model': '', 'external_rt_model': '', 'external_ccs_model': '', 'instrument_group': {'Lumos': 'Lumos', 'QE': 'QE', 'timsTOF': 'timsTOF', 'SciexTOF': 'SciexTOF', 'Fusion': 'Lumos', 'Eclipse': 'Lumos', 'Velos': 'Lumos', 'Elite': 'Lumos', 'OrbitrapTribrid': 'Lumos', 'ThermoTribrid': 'Lumos', 'QE+': 'QE', 'QEHF': 'QE', 'QEHFX': 'QE', 'Exploris': 'QE', 'Exploris480': 'QE', 'LUMOS': 'Lumos', 'TIMSTOF': 'timsTOF', 'SCIEXTOF': 'SciexTOF', 'FUSION': 'Lumos', 'ECLIPSE': 'Lumos', 'VELOS': 'Lumos', 'ELITE': 'Lumos', 'ORBITRAPTRIBRID': 'Lumos', 'THERMOTRIBRID': 'Lumos', 'EXPLORIS': 'QE', 'EXPLORIS480': 'QE'}, 'predict': {'batch_size_ms2': 512, 'batch_size_rt_ccs': 1024, 'verbose': True, 'multiprocessing': True}, 'transfer': {'model_output_folder': '', 'epoch_ms2': 20, 'warmup_epoch_ms2': 10, 'batch_size_ms2': 512, 'lr_ms2': 0.0001, 'epoch_rt_ccs': 40, 'warmup_epoch_rt_ccs': 10, 'batch_size_rt_ccs': 1024, 'lr_rt_ccs': 0.0001, 'verbose': False, 'grid_nce_search': True, 'grid_nce_first': 15.0, 'grid_nce_last': 45.0, 'grid_nce_step': 3.0, 'grid_instrument': ['Lumos'], 'psm_type': 'alphapept', 'psm_type_choices': ['alphapept', 'pfind', 'maxquant', 'diann', 'speclib_tsv'], 'psm_files': [], 'ms_file_type': 'alphapept_hdf', 'ms_file_type_choices': ['alphapept_hdf', 'thermo_raw', 'mgf', 'mzml'], 'ms_files': [], 'psm_num_to_train_ms2': 100000000, 'psm_num_per_mod_to_train_ms2': 50, 'psm_num_to_train_rt_ccs': 100000000, 'psm_num_per_mod_to_train_rt_ccs': 50, 'top_n_mods_to_train': 10}}, 'percolator': {'require_model_tuning': True, 'raw_num_to_tune': 8, 'require_raw_specific_tuning': True, 'raw_specific_ms2_tuning': False, 'psm_num_per_raw_to_tune': 200, 'epoch_per_raw_to_tune': 5, 'multiprocessing': True, 'top_k_frags_to_calc_spc': 10, 'ms2_ppm': True, 'ms2_tol': 20, 'calibrate_frag_mass_error': False, 'max_perc_train_sample': 1000000, 'min_perc_train_sample': 100, 'percolator_backend': 'sklearn', 'percolator_backend_choices': ['sklearn', 'pytorch'], 'percolator_model': 'linear', 'percolator_model_choices': {'pytorch_as_backend': ['linear', 'mlp'], 'sklearn_as_backend': ['linear', 'random_forest']}, 'lr_percolator_torch_model': 0.1, 'percolator_iter_num': 5, 'cv_fold': 1, 'fdr': 0.01, 'fdr_level': 'psm', 'fdr_level_choices': ['psm', 'precursor', 'peptide', 'sequence'], 'use_fdr_for_each_raw': False, 'frag_types': ['b_z1', 'b_z2', 'y_z1', 'y_z2'], 'input_files': {'psm_type': 'alphapept', 'psm_type_choices': ['alphapept', 'pfind', 'maxquant'], 'psm_files': [], 'ms_file_type': 'alphapept_hdf', 'ms_file_type_choices': ['hdf', 'thermo_raw', 'mgf', 'mzml'], 'ms_files': [], 'other_score_column_mapping': {'alphapept': {}, 'pfind': {'raw_score': 'Raw_Score'}, 'msfragger': {'hyperscore': 'hyperscore', 'nextscore': 'nextscore'}, 'maxquant': {}}}, 'output_folder': 'C:/datasets/percolaotr'}, 'library': {'input': {'type': 'fasta', 'type_choices': ['fasta', 'sequence_table', 'peptide_table', 'precursor_table'], 'paths': ['xxx.fasta'], 'fasta': {'protease': '([KR])', 'protease_choices': ['trypsin/P', '([KR])', 'trypsin', '([KR](?=[^P]))', 'lys-c', 'K', 'lys-n', '\\w(?=K)', 'chymotrypsin'], 'max_miss_cleave': 2}, 'fix_mods': ['Carbamidomethyl@C'], 'var_mods': ['Oxidation@M'], 'min_var_mod_num': 0, 'max_var_mod_num': 2, 'min_precursor_charge': 2, 'max_precursor_charge': 4, 'min_peptide_len': 7, 'max_peptide_len': 35, 'min_precursor_mz': 200.0, 'max_precursor_mz': 2000.0, 'decoy': 'pseudo_reverse', 'decoy_choices': ['pseudo_reverse', 'diann', 'None'], 'max_frag_charge': 2, 'frag_types': ['b', 'y']}, 'output_folder': '~/peptdeep_library', 'output_tsv': {'enabled': False, 'min_fragment_mz': 200, 'max_fragment_mz': 2000, 'min_relative_intensity': 0.01, 'keep_higest_k_peaks': 12, 'translate_batch_size': 1000000, 'translate_mod_to_unimod_id': False}}}</code></em>)</p>
</blockquote>
<p>Generate/predict a spectral library.</p>
<p>All required information in settings_dict:</p>

<pre><code>perc_settings = settings_dict['percolator']
output_folder = perc_settings['output_folder'] # str. Output folder of the rescored results
perc_settings['input_files']['psm_files'] # list of str. all PSM files (at 100% FDR and including decoys) from the search engines
perc_settings['input_files']['psm_type'] # str. PSM or search engine type, e.g. pfind, alphapept, maxquant
perc_settings['input_files']['ms_file_type'] # str. Could be alphapept_hdf, thermo, ...
perc_settings['input_files']['ms_files'] # list of str. MS file list to match MS2 peaks</code></pre>
<h2 id="Parameters">Parameters<a class="anchor-link" href="#Parameters"> </a></h2><p>settings_dict : dict, optional
    The settings dict, by default <code>peptdeep.settings.global_settings</code>.</p>
<h2 id="Raises">Raises<a class="anchor-link" href="#Raises"> </a></h2><p>Exception
    Any kinds of exception if the pipeline fails.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

</div>
 

