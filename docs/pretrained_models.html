---

title: *Integrated functionalities for MS2/RT/CCS models


keywords: fastai
sidebar: home_sidebar



nb_path: "nbdev_nbs/pretrained_models.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbdev_nbs/pretrained_models.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>peptdeep.pretrained_models</code> handles the pretrained models, including downloading, installing, and loading the models.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.-Downloading-and-installing-the-models">1. Downloading and installing the models<a class="anchor-link" href="#1.-Downloading-and-installing-the-models"> </a></h2><p>For continuous model deployment, we uploaded several pretrained models (compressed as a ZIP file) onto a net disk. peptdeep will automatically download the ZIP file into <code>global_settings['PEPTDEEP_HOME']/pretrained_models/pretrained_models.zip</code> when importing peptdeep.pretrained_models. The models will be downloaded only once, if we would like to update them to the latest models, we can call <code>download_models(overwrite=True)</code></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="is_model_zip" class="doc_header"><code>is_model_zip</code><a href="https://github.com/MannLabs/alphapeptdeep/tree/main/peptdeep/pretrained_models.py#L43" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>is_model_zip</code>(<strong><code>downloaded_zip</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="download_models" class="doc_header"><code>download_models</code><a href="https://github.com/MannLabs/alphapeptdeep/tree/main/peptdeep/pretrained_models.py#L47" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>download_models</code>(<strong><code>url</code></strong>:<code>str</code>=<em><code>'https://github.com/MannLabs/alphapeptdeep/releases/download/pre-trained-models/pretrained_models.zip'</code></em>, <strong><code>overwrite</code></strong>=<em><code>True</code></em>)</p>
</blockquote>
<p>[summary]</p>
<p>Args:
    url (str, optional): remote or local path.
      Defaults to peptdeep.pretrained_models.model_url.
    overwrite (bool, optional): overwirte old model files.
      Defaults to True.</p>
<p>Raises:
    FileNotFoundError: If remote url is not accessible.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.-Loading-the-models">2. Loading the models<a class="anchor-link" href="#2.-Loading-the-models"> </a></h2><p>peptdeep provides a convenient APIs to load models from ZIP files.</p>
<p><code>load_models()</code> will load the generic models for unmodified peptides, <code>load_phos_models()</code> will load the phospho models. Note that MS2/CCS prediction models are the same for generic and phospho models because this model was trained on both generic and phospho peptides.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="count_mods" class="doc_header"><code>count_mods</code><a href="https://github.com/MannLabs/alphapeptdeep/tree/main/peptdeep/pretrained_models.py#L102" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>count_mods</code>(<strong><code>psm_df</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="psm_sampling_with_important_mods" class="doc_header"><code>psm_sampling_with_important_mods</code><a href="https://github.com/MannLabs/alphapeptdeep/tree/main/peptdeep/pretrained_models.py#L131" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>psm_sampling_with_important_mods</code>(<strong><code>psm_df</code></strong>, <strong><code>n_sample</code></strong>, <strong><code>top_n_mods</code></strong>=<em><code>10</code></em>, <strong><code>n_sample_each_mod</code></strong>=<em><code>0</code></em>, <strong><code>uniform_sampling_column</code></strong>=<em><code>None</code></em>, <strong><code>random_state</code></strong>=<em><code>1337</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="load_phos_models" class="doc_header"><code>load_phos_models</code><a href="https://github.com/MannLabs/alphapeptdeep/tree/main/peptdeep/pretrained_models.py#L174" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>load_phos_models</code>(<strong><code>mask_modloss</code></strong>=<em><code>True</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="load_models" class="doc_header"><code>load_models</code><a href="https://github.com/MannLabs/alphapeptdeep/tree/main/peptdeep/pretrained_models.py#L183" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>load_models</code>(<strong><code>mask_modloss</code></strong>=<em><code>True</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="load_models_by_model_type_in_zip" class="doc_header"><code>load_models_by_model_type_in_zip</code><a href="https://github.com/MannLabs/alphapeptdeep/tree/main/peptdeep/pretrained_models.py#L192" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>load_models_by_model_type_in_zip</code>(<strong><code>model_type_in_zip</code></strong>:<code>str</code>, <strong><code>mask_modloss</code></strong>=<em><code>True</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3.-Using-ModelManager">3. Using <a href="/alphapeptdeep/pretrained_models.html#ModelManager"><code>ModelManager</code></a><a class="anchor-link" href="#3.-Using-ModelManager"> </a></h2><p>For users, <a href="/alphapeptdeep/pretrained_models.html#ModelManager"><code>ModelManager</code></a> class is the only thing we need to manage models (loading, transfer learning, etc). According to different arguments, <code>ModelManager::load_installed_models()</code> will call <code>load_models()</code> or <code>load_phos_models()</code>. For external models, <code>ModelManager::load_external_models()</code> will load them by file path or file stream. Here is an example:</p>

<pre><code>from zipfile import ZipFile

admodel = ModelManager()
ext_zip = 'external_models.zip' # model compressed in ZIP
rt_model_path = '/path/to/rt.pth' # model as file path
with ZipFile(ext_zip) as model_zip:
    with model_zip.open('generic/ms2.pth','r') as ms2_file:
        admodel.load_external_models(ms2_model_file=ms2_file, rt_model_file=rt_model_path)</code></pre>
<p>Transfer learning for different models could also be done in <a href="/alphapeptdeep/pretrained_models.html#ModelManager"><code>ModelManager</code></a> by using the given training dataframes.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="clear_error_modloss_intensities" class="doc_header"><code>clear_error_modloss_intensities</code><a href="https://github.com/MannLabs/alphapeptdeep/tree/main/peptdeep/pretrained_models.py#L223" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>clear_error_modloss_intensities</code>(<strong><code>fragment_mz_df</code></strong>, <strong><code>fragment_intensity_df</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ModelManager" class="doc_header"><code>class</code> <code>ModelManager</code><a href="https://github.com/MannLabs/alphapeptdeep/tree/main/peptdeep/pretrained_models.py#L233" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ModelManager</code>(<strong><code>mask_modloss</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>device</code></strong>:<code>str</code>=<em><code>'gpu'</code></em>, <strong><code>mgr_settings</code></strong>:<code>dict</code>=<em><code>{'default_nce': 30.0, 'default_instrument': 'Lumos', 'mask_modloss': True, 'model_type': 'generic', 'model_choices': ['generic', 'phos', 'hla', 'digly'], 'external_ms2_model': '', 'external_rt_model': '', 'external_ccs_model': '', 'instrument_group': {'Lumos': 'Lumos', 'QE': 'QE', 'timsTOF': 'timsTOF', 'SciexTOF': 'SciexTOF', 'Fusion': 'Lumos', 'Eclipse': 'Lumos', 'Velos': 'Lumos', 'Elite': 'Lumos', 'OrbitrapTribrid': 'Lumos', 'ThermoTribrid': 'Lumos', 'QE+': 'QE', 'QEHF': 'QE', 'QEHFX': 'QE', 'Exploris': 'QE', 'Exploris480': 'QE', 'LUMOS': 'Lumos', 'TIMSTOF': 'timsTOF', 'SCIEXTOF': 'SciexTOF', 'FUSION': 'Lumos', 'ECLIPSE': 'Lumos', 'VELOS': 'Lumos', 'ELITE': 'Lumos', 'ORBITRAPTRIBRID': 'Lumos', 'THERMOTRIBRID': 'Lumos', 'EXPLORIS': 'QE', 'EXPLORIS480': 'QE'}, 'predict': {'batch_size_ms2': 512, 'batch_size_rt_ccs': 1024, 'verbose': True, 'multiprocessing': True}, 'transfer': {'model_output_folder': '', 'epoch_ms2': 20, 'warmup_epoch_ms2': 10, 'batch_size_ms2': 512, 'lr_ms2': 0.0001, 'epoch_rt_ccs': 40, 'warmup_epoch_rt_ccs': 10, 'batch_size_rt_ccs': 1024, 'lr_rt_ccs': 0.0001, 'verbose': False, 'grid_nce_search': True, 'grid_nce_first': 15.0, 'grid_nce_last': 45.0, 'grid_nce_step': 3.0, 'grid_instrument': ['Lumos'], 'psm_type': 'alphapept', 'psm_type_choices': ['alphapept', 'pfind', 'maxquant', 'diann', 'speclib_tsv'], 'psm_files': [], 'ms_file_type': 'alphapept_hdf', 'ms_file_type_choices': ['alphapept_hdf', 'thermo_raw', 'mgf', 'mzml'], 'ms_files': [], 'psm_num_to_train_ms2': 100000000, 'psm_num_per_mod_to_train_ms2': 50, 'psm_num_to_train_rt_ccs': 100000000, 'psm_num_per_mod_to_train_rt_ccs': 50, 'top_n_mods_to_train': 10}}</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">peptdeep.model.rt</span> <span class="kn">import</span> <span class="n">IRT_PEPTIDE_DF</span>
<span class="n">model_mgr</span><span class="o">.</span><span class="n">predict_rt</span><span class="p">(</span><span class="n">IRT_PEPTIDE_DF</span><span class="p">)</span>
<span class="n">model_mgr</span><span class="o">.</span><span class="n">rt_model</span><span class="o">.</span><span class="n">add_irt_column_to_precursor_df</span><span class="p">(</span><span class="n">IRT_PEPTIDE_DF</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sequence</th>
      <th>pep_name</th>
      <th>irt</th>
      <th>mods</th>
      <th>mod_sites</th>
      <th>nAA</th>
      <th>rt_pred</th>
      <th>rt_norm_pred</th>
      <th>irt_pred</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>LGGNEQVTR</td>
      <td>RT-pep a</td>
      <td>-24.92</td>
      <td></td>
      <td></td>
      <td>9</td>
      <td>0.184235</td>
      <td>0.184235</td>
      <td>-26.123537</td>
    </tr>
    <tr>
      <th>1</th>
      <td>GAGSSEPVTGLDAK</td>
      <td>RT-pep b</td>
      <td>0.00</td>
      <td></td>
      <td></td>
      <td>14</td>
      <td>0.250092</td>
      <td>0.250092</td>
      <td>4.238100</td>
    </tr>
    <tr>
      <th>2</th>
      <td>VEATFGVDESNAK</td>
      <td>RT-pep c</td>
      <td>12.39</td>
      <td></td>
      <td></td>
      <td>13</td>
      <td>0.266133</td>
      <td>0.266133</td>
      <td>11.633120</td>
    </tr>
    <tr>
      <th>3</th>
      <td>YILAGVENSK</td>
      <td>RT-pep d</td>
      <td>19.79</td>
      <td></td>
      <td></td>
      <td>10</td>
      <td>0.290495</td>
      <td>0.290495</td>
      <td>22.864811</td>
    </tr>
    <tr>
      <th>4</th>
      <td>TPVISGGPYEYR</td>
      <td>RT-pep e</td>
      <td>28.71</td>
      <td></td>
      <td></td>
      <td>12</td>
      <td>0.303847</td>
      <td>0.303847</td>
      <td>29.020259</td>
    </tr>
    <tr>
      <th>5</th>
      <td>TPVITGAPYEYR</td>
      <td>RT-pep f</td>
      <td>33.38</td>
      <td></td>
      <td></td>
      <td>12</td>
      <td>0.316514</td>
      <td>0.316514</td>
      <td>34.860122</td>
    </tr>
    <tr>
      <th>6</th>
      <td>DGLDAASYYAPVR</td>
      <td>RT-pep g</td>
      <td>42.26</td>
      <td></td>
      <td></td>
      <td>13</td>
      <td>0.324423</td>
      <td>0.324423</td>
      <td>38.506308</td>
    </tr>
    <tr>
      <th>7</th>
      <td>ADVTPADFSEWSK</td>
      <td>RT-pep h</td>
      <td>54.62</td>
      <td></td>
      <td></td>
      <td>13</td>
      <td>0.345197</td>
      <td>0.345197</td>
      <td>48.083890</td>
    </tr>
    <tr>
      <th>8</th>
      <td>GTFIIDPGGVIR</td>
      <td>RT-pep i</td>
      <td>70.52</td>
      <td></td>
      <td></td>
      <td>12</td>
      <td>0.394248</td>
      <td>0.394248</td>
      <td>70.697474</td>
    </tr>
    <tr>
      <th>9</th>
      <td>GTFIIDPAAVIR</td>
      <td>RT-pep k</td>
      <td>87.23</td>
      <td></td>
      <td></td>
      <td>12</td>
      <td>0.434775</td>
      <td>0.434775</td>
      <td>89.381150</td>
    </tr>
    <tr>
      <th>10</th>
      <td>LFLQFGAQGSPFLK</td>
      <td>RT-pep l</td>
      <td>100.00</td>
      <td></td>
      <td></td>
      <td>14</td>
      <td>0.459583</td>
      <td>0.459583</td>
      <td>100.818303</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

