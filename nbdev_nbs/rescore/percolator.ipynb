{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp rescore.percolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "from peptdeep.utils import logging\n",
    "\n",
    "from alphabase.peptide.fragment import get_charged_frag_types\n",
    "\n",
    "from peptdeep.rescore.feature_extractor import (\n",
    "    ScoreFeatureExtractor,\n",
    "    ScoreFeatureExtractorMP\n",
    ")\n",
    "\n",
    "from peptdeep.rescore.fdr import (\n",
    "    fdr_from_ref, fdr_to_q_values, calc_fdr_for_df\n",
    ")\n",
    "\n",
    "from peptdeep.pretrained_models import ModelManager\n",
    "\n",
    "from peptdeep.settings import global_settings\n",
    "\n",
    "perc_settings = global_settings['percolator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LogisticRegressionTorch(torch.nn.Module):\n",
    "    def __init__(self, input_dim, **kwargs):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1337)\n",
    "        self.linear = torch.nn.Linear(input_dim, 1)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x).squeeze(1)\n",
    "\n",
    "class RescoreModelProvider:\n",
    "    def __init__(self):\n",
    "        self.model_dict = {}\n",
    "        self.model_dict['linear'] = LogisticRegressionTorch\n",
    "    def register(self, model_name, model_class):\n",
    "        self.model_dict[model_name.lower()] = model_class\n",
    "    def get_model(self, model_name, input_dim, **kwargs):\n",
    "        if model_name.lower() not in self.model_dict:\n",
    "            logging.info(\n",
    "                \"[PERC] \"\n",
    "                f\"PyTorch rescoring model '{model_name}' is not \"\n",
    "                \"implemented, switch to 'linear' model.\"\n",
    "            )\n",
    "            return self.model_dict['linear'](\n",
    "                input_dim, **kwargs\n",
    "            )\n",
    "        else:\n",
    "            return self.model_dict[model_name.lower()](\n",
    "                input_dim, **kwargs\n",
    "            )\n",
    "\n",
    "rescore_model_provider = RescoreModelProvider()\n",
    "\n",
    "class NNRescore:\n",
    "    def __init__(self, num_features, nn_model_type='linear'):\n",
    "        self.nn_model = rescore_model_provider.get_model(\n",
    "            nn_model_type, num_features\n",
    "        )\n",
    "        self.train_batch_size = 10000\n",
    "        self.predict_batch_size = 100000\n",
    "            \n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.nn_model.parameters(), \n",
    "            lr=perc_settings['lr_percolator_torch_model']\n",
    "        )\n",
    "        self.loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda')\n",
    "            self.nn_model.to(self.device)\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        self.epoch = 20\n",
    "\n",
    "    \n",
    "\n",
    "    def fit(self, features, labels):\n",
    "        labels = torch.tensor(\n",
    "            labels, dtype=torch.float, device=self.device\n",
    "        )\n",
    "        sample_idxes = np.random.RandomState(\n",
    "            1337\n",
    "        ).permutation(len(features))\n",
    "        for _ in range(self.epoch):\n",
    "            for i in range(0, len(features), self.train_batch_size):\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                outputs = self.nn_model(\n",
    "                    torch.tensor(features[\n",
    "                        sample_idxes[i:i+self.train_batch_size]\n",
    "                    ], dtype=torch.float, device=self.device)\n",
    "                )\n",
    "                loss = self.loss_func(\n",
    "                    outputs, labels[\n",
    "                        sample_idxes[i:i+self.train_batch_size]\n",
    "                    ]\n",
    "                )\n",
    "                loss.backward()\n",
    "\n",
    "                self.optimizer.step()\n",
    "\n",
    "    def decision_function(self, features):\n",
    "        outputs = np.empty(len(features))\n",
    "        for i in range(0, len(features), self.predict_batch_size):\n",
    "            outputs[\n",
    "                i:i+self.predict_batch_size\n",
    "            ] = self.nn_model(\n",
    "                torch.tensor(features[\n",
    "                    i:i+self.predict_batch_size\n",
    "                ], dtype=torch.float, device=self.device)\n",
    "            ).detach().cpu().numpy()\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build-in percolator algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class Percolator:\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        percolator_model:str=perc_settings['percolator_model'],\n",
    "        percolator_backend:str=perc_settings['percolator_backend'],\n",
    "        cv_fold:int = perc_settings['cv_fold'],\n",
    "        iter_num:int = perc_settings['ml_iter_num'],\n",
    "        ms2_ppm:bool = perc_settings['ms2_ppm'], \n",
    "        ms2_tol:float = perc_settings['ms2_tol'],\n",
    "        model_mgr:ModelManager = None\n",
    "    ):\n",
    "        \"\"\"Percolator model\n",
    "        Note that in the `Args` list,\n",
    "        ```\n",
    "          perc_settings = peptdeep.settings.global_settings['percolator']\n",
    "        ```\n",
    "\n",
    "        Args:\n",
    "            percolator_model (str, optional): machine learning \n",
    "              model type for rescoring, could be:\n",
    "                \"linear\": logistic regression\n",
    "                \"random_forest\": random forest\n",
    "              Defaults to perc_settings['percolator_model'].\n",
    "            percolator_backend(str, optional): `sklearn` or `pytorch`.\n",
    "              Defaults to perc_settings['percolator_backend']\n",
    "            cv_fold (int, optional): cross-validation fold. \n",
    "              Defaults to perc_settings['cv_fold'].\n",
    "            iter_num (int, optional): percolator iteration number. \n",
    "              Defaults to perc_settings['ml_iter_num'].\n",
    "            ms2_ppm (bool, optional): is ms2 tolerance the ppm. \n",
    "              Defaults to perc_settings['ms2_ppm'].\n",
    "            ms2_tol (float, optional): ms2 tolerance. \n",
    "              Defaults to perc_settings['ms2_tol'].\n",
    "            model_mgr (ModelManager, optional): \n",
    "              peptdeep.pretrained_model.ModelManager.\n",
    "              If None, self.model_mgr will be init by:\n",
    "              ```\n",
    "              self.model_mgr = ModelManager()\n",
    "              self.model_mgr.load_installed_models(\n",
    "                perc_settings['peptdeep_model_type'],\n",
    "                mask_modloss=perc_settings[\n",
    "                    'mask_modloss'\n",
    "                ]\n",
    "              )\n",
    "              ```\n",
    "              Defaults to None.\n",
    "        \"\"\"\n",
    "        if model_mgr is None:\n",
    "            self.model_mgr = ModelManager()\n",
    "            self.model_mgr.load_installed_models(\n",
    "                perc_settings['peptdeep_model_type'],\n",
    "                mask_modloss=perc_settings[\n",
    "                    'mask_modloss'\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.model_mgr = model_mgr\n",
    "        self.charged_frag_types = perc_settings['frag_types']\n",
    "        self.ms2_ppm = ms2_ppm\n",
    "        self.ms2_tol = ms2_tol\n",
    "        self.fdr_level = perc_settings['fdr_level']\n",
    "        self.fdr = perc_settings['fdr']\n",
    "        self.cv_fold = cv_fold\n",
    "        self.iter_num = iter_num\n",
    "\n",
    "        if perc_settings['multiprocessing']:\n",
    "            self.feature_extractor = ScoreFeatureExtractorMP(\n",
    "                model_mgr=self.model_mgr,\n",
    "            )\n",
    "        else:\n",
    "            self.feature_extractor = ScoreFeatureExtractor(\n",
    "                model_mgr=self.model_mgr,\n",
    "            )\n",
    "        self.feature_list = [\n",
    "            f for f in self.feature_extractor.score_feature_list\n",
    "        ]\n",
    "        self.feature_list += ['score','nAA','charge']\n",
    "        self.feature_list.append('ml_score') #self-boosted\n",
    "        psm_type = perc_settings['input_files']['psm_type']\n",
    "        self.feature_list += list(perc_settings['input_files'][\n",
    "            'other_score_column_mapping'\n",
    "        ][psm_type].keys())\n",
    "\n",
    "        self.max_train_sample = perc_settings['max_perc_train_sample']\n",
    "        self.min_train_sample = perc_settings['min_perc_train_sample']\n",
    "        self.per_raw_fdr = perc_settings['per_raw_fdr']\n",
    "\n",
    "        self.init_percolator_model(percolator_model, percolator_backend)\n",
    "\n",
    "    def init_percolator_model(self, \n",
    "        percolator_model=\"linear\", \n",
    "        percolator_backend=\"pytorch\"\n",
    "    ):\n",
    "        self.percolator_model = percolator_model.lower()\n",
    "        self.percolator_backend = percolator_backend.lower()\n",
    "        if percolator_backend.lower() == 'pytorch':\n",
    "            self.model = NNRescore(\n",
    "                len(self.feature_list),\n",
    "                nn_model_type=percolator_model\n",
    "            )\n",
    "        elif percolator_model == 'linear':\n",
    "            self.model = LogisticRegression(\n",
    "                solver='liblinear'\n",
    "            )\n",
    "        elif percolator_model == 'random_forest':\n",
    "            self.model = RandomForestClassifier()\n",
    "        else:\n",
    "            if torch.cuda.is_available():\n",
    "                logging.info(\n",
    "                    \"[PERC] \"\n",
    "                    f\"Rescoring model '{percolator_model}' is not \"\n",
    "                    \"implemented, switch to pytorch 'linear' model.\"\n",
    "                )\n",
    "                self.model = NNRescore(\n",
    "                    len(self.feature_list),\n",
    "                    nn_model_type='linear'\n",
    "                )\n",
    "                self.percolator_model = 'linear'\n",
    "                self.percolator_backend = 'pytorch'\n",
    "            else:\n",
    "                logging.info(\n",
    "                    \"[PERC] \"\n",
    "                    f\"Rescoring model '{percolator_model}' is not \"\n",
    "                    \"implemented, switch to sklearn 'linear' model.\"\n",
    "                )\n",
    "                self.model = LogisticRegression(\n",
    "                    solver='liblinear'\n",
    "                )\n",
    "                self.percolator_model = 'linear'\n",
    "                self.percolator_backend = 'sklearn'\n",
    "\n",
    "    def enable_model_fine_tuning(self, flag=True):\n",
    "        self.feature_extractor.require_model_tuning = flag\n",
    "        self.feature_extractor.require_raw_specific_rt_tuning = flag\n",
    "    def disable_model_fine_tuning(self):\n",
    "        self.feature_extractor.require_model_tuning = False\n",
    "        self.feature_extractor.require_raw_specific_rt_tuning = False\n",
    "\n",
    "    def _estimate_fdr(self, \n",
    "        df:pd.DataFrame,\n",
    "        fdr_level:str=None,\n",
    "        per_raw_fdr:bool=None,\n",
    "    )->pd.DataFrame:\n",
    "        df = df.sort_values(['ml_score','decoy'], ascending=False)\n",
    "        df = df.reset_index(drop=True)\n",
    "        if fdr_level is None: \n",
    "            fdr_level = self.fdr_level\n",
    "        if per_raw_fdr is None: \n",
    "            per_raw_fdr = self.per_raw_fdr\n",
    "        if per_raw_fdr:\n",
    "            df_list = []\n",
    "            for raw_name, df_raw in df.groupby('raw_name'):\n",
    "                df_list.append(self._estimate_fdr(df_raw, \n",
    "                    fdr_level = fdr_level,\n",
    "                    per_raw_fdr = False\n",
    "                ))\n",
    "            return pd.concat(df_list)\n",
    "        if fdr_level == 'psm':\n",
    "            target_values = 1-df['decoy'].values\n",
    "            decoy_cumsum = np.cumsum(df['decoy'].values)\n",
    "            target_cumsum = np.cumsum(target_values)\n",
    "            fdr_values = decoy_cumsum/target_cumsum\n",
    "            df['fdr'] = fdr_to_q_values(fdr_values)\n",
    "        else:\n",
    "            if fdr_level == 'precursor':\n",
    "                _df = df.groupby([\n",
    "                    'sequence','mods','mod_sites','charge','decoy'\n",
    "                ])['ml_score'].max()\n",
    "            elif fdr_level == 'peptide':\n",
    "                _df = df.groupby([\n",
    "                    'sequence','mods','mod_sites','decoy'\n",
    "                ])['ml_score'].max()\n",
    "            else:\n",
    "                _df = df.groupby(['sequence','decoy'])['ml_score'].max()\n",
    "            _df = _df.reset_index(drop=True)\n",
    "            _df = _df.sort_values(['ml_score','decoy'], ascending=False)\n",
    "            target_values = 1-_df['decoy'].values\n",
    "            decoy_cumsum = np.cumsum(_df['decoy'].values)\n",
    "            target_cumsum = np.cumsum(target_values)\n",
    "            fdr_values = decoy_cumsum/target_cumsum\n",
    "            _df['fdr'] = fdr_to_q_values(fdr_values)\n",
    "            df['fdr'] = fdr_from_ref(\n",
    "                df['ml_score'].values, _df['ml_score'].values, \n",
    "                _df['fdr'].values\n",
    "            )\n",
    "        return df\n",
    "\n",
    "    def _train(self, train_t_df, train_d_df):\n",
    "        if len(train_t_df) > self.max_train_sample:\n",
    "            train_t_df = train_t_df.sample(\n",
    "                n=self.max_train_sample, \n",
    "                random_state=1337\n",
    "            )\n",
    "        if len(train_d_df) > self.max_train_sample:\n",
    "            train_d_df = train_d_df.sample(\n",
    "                n=self.max_train_sample,\n",
    "                random_state=1337\n",
    "            )\n",
    "\n",
    "        train_df = pd.concat((train_t_df, train_d_df))\n",
    "        train_label = np.ones(len(train_df),dtype=np.int32)\n",
    "        train_label[len(train_t_df):] = 0\n",
    "\n",
    "        self.model.fit(\n",
    "            train_df[self.feature_list].values, \n",
    "            train_label\n",
    "        )\n",
    "\n",
    "    def _predict(self, test_df):\n",
    "        if self.percolator_model != 'random_forest':\n",
    "            test_df['ml_score'] = self.model.decision_function(\n",
    "                test_df[self.feature_list].values\n",
    "            )\n",
    "        else:\n",
    "            test_df['ml_score'] = self.model.predict_proba(\n",
    "                test_df[self.feature_list].values\n",
    "            )[:,1]\n",
    "        return test_df\n",
    "\n",
    "    def _cv_score(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        df = df.sample(\n",
    "            frac=1, random_state=1337\n",
    "        ).reset_index(drop=True)\n",
    "        df_target = df[df.decoy == 0]\n",
    "        df_decoy = df[df.decoy != 0]\n",
    "        if (\n",
    "            np.sum(df_target.fdr<0.01) < \n",
    "            self.min_train_sample*self.cv_fold \n",
    "            or len(df_decoy) < self.min_train_sample*self.cv_fold\n",
    "        ):\n",
    "            logging.info(\n",
    "                \"[PERC] \"\n",
    "                f'#target={np.sum(df_target.fdr<0.01)} or #decoy={len(df_decoy)} '\n",
    "                f'< minimal training sample={self.min_train_sample} '\n",
    "                f'for cv-fold={self.cv_fold}. Skip rescoring!!!'\n",
    "            )\n",
    "            return df\n",
    "        \n",
    "        if self.cv_fold > 1:\n",
    "            test_df_list = []\n",
    "            for i in range(self.cv_fold):\n",
    "                t_mask = np.ones(len(df_target), dtype=bool)\n",
    "                _slice = slice(i, len(df_target), self.cv_fold)\n",
    "                t_mask[_slice] = False\n",
    "                cv_df_target = df_target[t_mask]\n",
    "                train_t_df = cv_df_target[\n",
    "                    cv_df_target.fdr <= self.fdr\n",
    "                ]\n",
    "                test_t_df = df_target[_slice]\n",
    "                \n",
    "                d_mask = np.ones(len(df_decoy), dtype=bool)\n",
    "                _slice = slice(i, len(df_decoy), self.cv_fold)\n",
    "                d_mask[_slice] = False\n",
    "                train_d_df = df_decoy[d_mask]\n",
    "                test_d_df = df_decoy[_slice]\n",
    "\n",
    "                self._train(train_t_df, train_d_df)\n",
    "\n",
    "                test_df = pd.concat((test_t_df, test_d_df))\n",
    "                test_df_list.append(self._predict(test_df))\n",
    "        \n",
    "            return pd.concat(test_df_list)\n",
    "        else:\n",
    "            train_t_df = df_target[df_target.fdr <= self.fdr]\n",
    "\n",
    "            self._train(train_t_df, df_decoy)\n",
    "            test_df = pd.concat((df_target, df_decoy))\n",
    "        \n",
    "            return self._predict(test_df)\n",
    "\n",
    "    def extract_features(self,\n",
    "        psm_df:pd.DataFrame, ms2_file_dict:dict, ms2_file_type:str\n",
    "    )->pd.DataFrame:\n",
    "\n",
    "        psm_df['ml_score'] = psm_df.score\n",
    "        psm_df = self._estimate_fdr(psm_df, 'psm')\n",
    "        psm_df = self.feature_extractor.extract_features(\n",
    "            psm_df, ms2_file_dict, \n",
    "            ms2_file_type,\n",
    "            frag_types=self.charged_frag_types, \n",
    "            ms2_ppm=self.ms2_ppm, ms2_tol=self.ms2_tol\n",
    "        )\n",
    "\n",
    "        return psm_df\n",
    "\n",
    "    def re_score(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        logging.info(\n",
    "            \"[PERC] \"\n",
    "            f'{np.sum((df.fdr<=self.fdr) & (df.decoy==0))} '\n",
    "            f'target PSMs at {self.fdr} psm-level FDR'\n",
    "        )\n",
    "        for i in range(self.iter_num):\n",
    "            logging.info(f'[PERC] Iteration {i+1} of Percolator ...')\n",
    "            df = self._cv_score(df)\n",
    "            df = self._estimate_fdr(df, 'psm', False)\n",
    "            logging.info(\n",
    "                f'[PERC] {len(df[(df.fdr<=self.fdr) & (df.decoy==0)])} '\n",
    "                f'target PSMs at {self.fdr} psm-level FDR'\n",
    "            )\n",
    "        df = self._estimate_fdr(df)\n",
    "        logging.info(\n",
    "            \"[PERC] \"\n",
    "            f'{len(df[(df.fdr<=self.fdr) & (df.decoy==0)])} '\n",
    "            f'target PSMs at {self.fdr} {self.fdr_level}-level FDR'\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    def run(self,\n",
    "        psm_df:pd.DataFrame, ms2_file_dict:dict, ms2_file_type:str\n",
    "    )->pd.DataFrame:\n",
    "        df = self.extract_features(\n",
    "            psm_df, ms2_file_dict, ms2_file_type\n",
    "        )\n",
    "        return self.re_score(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-08 23:49:39> [PERC] PyTorch rescoring model 'random_forest' is not implemented, switch to 'linear' model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Percolator at 0x7fb4394b6d60>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "Percolator(percolator_model='linear', percolator_backend='pytorch')\n",
    "Percolator(percolator_model='linear', percolator_backend='sklearn')\n",
    "Percolator(percolator_model='random_forest', percolator_backend='sklearn')\n",
    "Percolator(percolator_model='random_forest', percolator_backend='pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
