{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp rescore.percolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from alphadeep.utils import logging\n",
    "\n",
    "from alphabase.peptide.fragment import get_charged_frag_types\n",
    "\n",
    "from alphadeep.rescore.feature_extractor import (\n",
    "    ScoreFeatureExtractor,\n",
    "    ScoreFeatureExtractorMP\n",
    ")\n",
    "\n",
    "from alphadeep.rescore.fdr import (\n",
    "    fdr_from_ref, fdr_to_q_values, calc_fdr_for_df\n",
    ")\n",
    "\n",
    "from alphadeep.pretrained_models import ModelManager\n",
    "\n",
    "from alphadeep.settings import global_settings\n",
    "\n",
    "perc_settings = global_settings['percolator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class DeepLearningScore(torch.nn.Module):\n",
    "    def __init__(self, in_features, nlayer=8):\n",
    "        super().__init__()\n",
    "        hidden = 128\n",
    "        self.nn = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features, hidden),\n",
    "            torch.nn.ReLU(),\n",
    "            *[]\n",
    "        )\n",
    "\n",
    "class Percolator:\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        ml_type=perc_settings['ml_type'], #or 'random_forest'\n",
    "        cv_fold = perc_settings['cv_fold'],\n",
    "        n_iteration = perc_settings['n_ml_iter'],\n",
    "        ms2_ppm = perc_settings['ms2_ppm'], \n",
    "        ms2_tol = perc_settings['ms2_tol'],\n",
    "        model_mgr:ModelManager = None,\n",
    "        **sklearn_kwargs\n",
    "    ):\n",
    "        if model_mgr is None:\n",
    "            self.model_mgr = ModelManager()\n",
    "            self.model_mgr.load_installed_models(\n",
    "                perc_settings['model_type'],\n",
    "                mask_modloss=perc_settings[\n",
    "                    'mask_modloss'\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.model_mgr = model_mgr\n",
    "        self.charged_frag_types = perc_settings['frag_types']\n",
    "        self.ms2_ppm = ms2_ppm\n",
    "        self.ms2_tol = ms2_tol\n",
    "        if ml_type == 'logistic_regression':\n",
    "            ml_type = 'lr'\n",
    "        self.ml_type = ml_type\n",
    "        self.fdr_level = perc_settings['fdr_level']\n",
    "        self.fdr = perc_settings['fdr']\n",
    "        self.cv_fold = cv_fold\n",
    "        self.n_iter = n_iteration\n",
    "\n",
    "        if ml_type == 'lr':\n",
    "            self.model = LogisticRegression(\n",
    "                solver='liblinear', **sklearn_kwargs\n",
    "            )\n",
    "        else:\n",
    "            self.model = RandomForestClassifier(**sklearn_kwargs)\n",
    "\n",
    "        if perc_settings['multiprocessing']:\n",
    "            self.feature_extractor = ScoreFeatureExtractorMP(\n",
    "                model_mgr=self.model_mgr,\n",
    "            )\n",
    "        else:\n",
    "            self.feature_extractor = ScoreFeatureExtractor(\n",
    "                model_mgr=self.model_mgr,\n",
    "            )\n",
    "        self.feature_list = [\n",
    "            f for f in self.feature_extractor.score_feature_list\n",
    "        ]\n",
    "        self.feature_list += ['score','nAA','charge']\n",
    "        self.feature_list.append('ml_score') #self-boosted\n",
    "        psm_type = perc_settings['input_files']['psm_type']\n",
    "        self.feature_list += list(perc_settings['input_files'][\n",
    "            'other_score_column_mapping'\n",
    "        ][psm_type].keys())\n",
    "\n",
    "        self.max_train_sample = perc_settings['max_perc_train_sample']\n",
    "        self.min_train_sample = perc_settings['min_perc_train_sample']\n",
    "\n",
    "    def enable_model_fine_tuning(self, flag=True):\n",
    "        self.feature_extractor.require_model_tuning = flag\n",
    "        self.feature_extractor.require_raw_specific_rt_tuning = flag\n",
    "    def disable_model_fine_tuning(self):\n",
    "        self.feature_extractor.require_model_tuning = False\n",
    "        self.feature_extractor.require_raw_specific_rt_tuning = False\n",
    "\n",
    "    def _estimate_fdr(self, df:pd.DataFrame, fdr_level=None)->pd.DataFrame:\n",
    "        df = df.sort_values(['ml_score','decoy'], ascending=False)\n",
    "        df = df.reset_index(drop=True)\n",
    "        if not fdr_level: fdr_level = self.fdr_level\n",
    "        if fdr_level == 'psm':\n",
    "            target_values = 1-df['decoy'].values\n",
    "            decoy_cumsum = np.cumsum(df['decoy'].values)\n",
    "            target_cumsum = np.cumsum(target_values)\n",
    "            fdr_values = decoy_cumsum/target_cumsum\n",
    "            df['fdr'] = fdr_to_q_values(fdr_values)\n",
    "        else:\n",
    "            if fdr_level == 'precursor':\n",
    "                _df = df.groupby([\n",
    "                    'sequence','mods','mod_sites','charge','decoy'\n",
    "                ])['ml_score'].max()\n",
    "            elif fdr_level == 'peptide':\n",
    "                _df = df.groupby([\n",
    "                    'sequence','mods','mod_sites','decoy'\n",
    "                ])['ml_score'].max()\n",
    "            else:\n",
    "                _df = df.groupby(['sequence','decoy'])['ml_score'].max()\n",
    "            _df = _df.reset_index(drop=True)\n",
    "            _df = _df.sort_values(['ml_score','decoy'], ascending=False)\n",
    "            target_values = 1-_df['decoy'].values\n",
    "            decoy_cumsum = np.cumsum(_df['decoy'].values)\n",
    "            target_cumsum = np.cumsum(target_values)\n",
    "            fdr_values = decoy_cumsum/target_cumsum\n",
    "            _df['fdr'] = fdr_to_q_values(fdr_values)\n",
    "            df['fdr'] = fdr_from_ref(\n",
    "                df['ml_score'].values, _df['ml_score'].values, \n",
    "                _df['fdr'].values\n",
    "            )\n",
    "        return df\n",
    "\n",
    "    def _train(self, train_t_df, train_d_df):\n",
    "        if len(train_t_df) > self.max_train_sample:\n",
    "            train_t_df = train_t_df.sample(\n",
    "                n=self.max_train_sample, \n",
    "                random_state=1337\n",
    "            )\n",
    "        if len(train_d_df) > self.max_train_sample:\n",
    "            train_d_df = train_d_df.sample(\n",
    "                n=self.max_train_sample,\n",
    "                random_state=1337\n",
    "            )\n",
    "\n",
    "        train_df = pd.concat((train_t_df, train_d_df))\n",
    "        train_label = np.ones(len(train_df),dtype=np.int32)\n",
    "        train_label[len(train_t_df):] = 0\n",
    "\n",
    "        self.model.fit(\n",
    "            train_df[self.feature_list].values, \n",
    "            train_label\n",
    "        )\n",
    "\n",
    "    def _predict(self, test_df):\n",
    "        if self.ml_type == 'lr':\n",
    "            test_df['ml_score'] = self.model.decision_function(\n",
    "                test_df[self.feature_list].values\n",
    "            )\n",
    "        else:\n",
    "            test_df['ml_score'] = self.model.predict_proba(\n",
    "                test_df[self.feature_list].values\n",
    "            )[:,1]\n",
    "        return test_df\n",
    "\n",
    "    def _cv_score(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        df = df.sample(\n",
    "            frac=1, random_state=1337\n",
    "        ).reset_index(drop=True)\n",
    "        df_target = df[df.decoy == 0]\n",
    "        df_decoy = df[df.decoy != 0]\n",
    "        if (\n",
    "            np.sum(df_target.fdr<0.01) < \n",
    "            self.min_train_sample*self.cv_fold \n",
    "            or len(df_decoy) < self.min_train_sample*self.cv_fold\n",
    "        ):\n",
    "            logging.info(\n",
    "                f'#target={np.sum(df_target.fdr<0.01)} or #decoy={len(df_decoy)} '\n",
    "                f'less then minimum training sample {self.min_train_sample} '\n",
    "                f'for cv-fold={self.cv_fold}'\n",
    "            )\n",
    "            return df\n",
    "        \n",
    "        if self.cv_fold > 1:\n",
    "            test_df_list = []\n",
    "            for i in range(self.cv_fold):\n",
    "                t_mask = np.ones(len(df_target), dtype=bool)\n",
    "                _slice = slice(i, len(df_target), self.cv_fold)\n",
    "                t_mask[_slice] = False\n",
    "                cv_df_target = df_target[t_mask]\n",
    "                train_t_df = cv_df_target[\n",
    "                    cv_df_target.fdr <= self.fdr\n",
    "                ]\n",
    "                test_t_df = df_target[_slice]\n",
    "                \n",
    "                d_mask = np.ones(len(df_decoy), dtype=bool)\n",
    "                _slice = slice(i, len(df_decoy), self.cv_fold)\n",
    "                d_mask[_slice] = False\n",
    "                train_d_df = df_decoy[d_mask]\n",
    "                test_d_df = df_decoy[_slice]\n",
    "\n",
    "                self._train(train_t_df, train_d_df)\n",
    "\n",
    "                test_df = pd.concat((test_t_df, test_d_df))\n",
    "                test_df_list.append(self._predict(test_df))\n",
    "        \n",
    "            return pd.concat(test_df_list)\n",
    "        else:\n",
    "            train_t_df = df_target[df_target.fdr <= self.fdr]\n",
    "\n",
    "            self._train(train_t_df, df_decoy)\n",
    "            test_df = pd.concat((df_target, df_decoy))\n",
    "        \n",
    "            return self._predict(test_df)\n",
    "\n",
    "    def extract_features(self,\n",
    "        psm_df:pd.DataFrame, ms2_file_dict:dict, ms2_file_type:str\n",
    "    )->pd.DataFrame:\n",
    "        for feat in self.feature_list:\n",
    "            if feat not in psm_df.columns:\n",
    "                self.feature_list.remove(feat)\n",
    "\n",
    "        psm_df['ml_score'] = psm_df.score\n",
    "        psm_df = self._estimate_fdr(psm_df, 'psm')\n",
    "        psm_df = self.feature_extractor.extract_features(\n",
    "            psm_df, ms2_file_dict, \n",
    "            ms2_file_type,\n",
    "            frag_types=self.charged_frag_types, \n",
    "            ms2_ppm=self.ms2_ppm, ms2_tol=self.ms2_tol\n",
    "        )\n",
    "        return psm_df\n",
    "\n",
    "    def re_score(self, df:pd.DataFrame)->pd.DataFrame:\n",
    "        logging.info(\n",
    "            f'{np.sum((df.fdr<=self.fdr) & (df.decoy==0))} '\n",
    "            f'target PSMs at {self.fdr} psm-level FDR'\n",
    "        )\n",
    "        for i in range(self.n_iter):\n",
    "            logging.info(f'[PERC] Iteration {i+1} of Percolator ...')\n",
    "            df = self._cv_score(df)\n",
    "            df = self._estimate_fdr(df, 'psm')\n",
    "            logging.info(\n",
    "                f'[PERC] {len(df[(df.fdr<=self.fdr) & (df.decoy==0)])} '\n",
    "                f'target PSMs at {self.fdr} psm-level FDR'\n",
    "            )\n",
    "        df = self._estimate_fdr(df)\n",
    "        logging.info(\n",
    "            f'{len(df[(df.fdr<=self.fdr) & (df.decoy==0)])} '\n",
    "            f'target PSMs at {self.fdr} {self.fdr_level}-level FDR'\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    def run(self,\n",
    "        psm_df:pd.DataFrame, ms2_file_dict:dict, ms2_file_type:str\n",
    "    )->pd.DataFrame:\n",
    "        df = self.extract_features(\n",
    "            psm_df, ms2_file_dict, ms2_file_type\n",
    "        )\n",
    "        return self.re_score(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cos',\n",
       " 'sa',\n",
       " 'spc',\n",
       " 'cos_bion',\n",
       " 'sa_bion',\n",
       " 'spc_bion',\n",
       " 'cos_yion',\n",
       " 'sa_yion',\n",
       " 'spc_yion',\n",
       " 'frag_ratio',\n",
       " 'frag_ratio_bion',\n",
       " 'frag_ratio_yion',\n",
       " 'rt_delta_abs',\n",
       " 'mobility_delta_abs',\n",
       " 'score',\n",
       " 'nAA',\n",
       " 'charge',\n",
       " 'ml_score']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "Percolator().feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a3b27e141e49c996c9b863f8707e97aabd49c4a7e8445b9b783b34e4a21a9b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
