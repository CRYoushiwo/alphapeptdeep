{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---#| default_exp pipeline_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module provides high-level APIs for different pipelines such as transfer learning, library geneartion, and rescoring (percolator). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning pipeline\n",
    "\n",
    "Transfer learning pipeline includes:\n",
    "1. Loading PSM files of the search engine results.\n",
    "2. Matching PSMs against the MS files.\n",
    "3. Loading pre-trained models and refining RT/CCS(/MS2) models.\n",
    "\n",
    "The refined models will be saved in the path pointed by \"PEPTDEEP_HOME\" in `peptdeep.settings.global_settings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peptdeep.pipeline_api import global_settings\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test library generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-20 09:28:27> Platform information:\n",
      "2023-01-20 09:28:27> system        - Darwin\n",
      "2023-01-20 09:28:27> release       - 20.6.0\n",
      "2023-01-20 09:28:27> version       - 10.16\n",
      "2023-01-20 09:28:27> machine       - x86_64\n",
      "2023-01-20 09:28:27> processor     - i386\n",
      "2023-01-20 09:28:27> cpu count     - 8\n",
      "2023-01-20 09:28:27> ram           - 10.8/32.0 Gb (available/total)\n",
      "2023-01-20 09:28:27> \n",
      "2023-01-20 09:28:28> Python information:\n",
      "2023-01-20 09:28:28> alphabase        - 1.0.0\n",
      "2023-01-20 09:28:28> biopython        - 1.78\n",
      "2023-01-20 09:28:28> click            - 8.1.3\n",
      "2023-01-20 09:28:28> lxml             - 4.6.2\n",
      "2023-01-20 09:28:28> numba            - 0.54.0\n",
      "2023-01-20 09:28:28> numpy            - 1.19.4\n",
      "2023-01-20 09:28:28> pandas           - 1.3.5\n",
      "2023-01-20 09:28:28> peptdeep         - 1.0.1\n",
      "2023-01-20 09:28:28> psutil           - 5.8.0\n",
      "2023-01-20 09:28:28> python           - 3.8.3\n",
      "2023-01-20 09:28:28> scikit-learn     - 1.1.1\n",
      "2023-01-20 09:28:28> streamlit        - 1.16.0\n",
      "2023-01-20 09:28:28> streamlit-aggrid - 0.2.1\n",
      "2023-01-20 09:28:28> torch            - 1.7.1\n",
      "2023-01-20 09:28:28> tqdm             - 4.56.0\n",
      "2023-01-20 09:28:28> transformers     - 4.25.1\n",
      "2023-01-20 09:28:28> \n",
      "2023-01-20 09:28:38> Generating the spectral library ...\n",
      "2023-01-20 09:28:40> Predicting RT/IM/MS2 for 156 precursors ...\n",
      "2023-01-20 09:28:40> Predicting RT ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 46.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-20 09:28:41> Predicting mobility ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 67.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-20 09:28:41> Predicting MS2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 19.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-20 09:28:41> End predicting RT/IM/MS2\n",
      "2023-01-20 09:28:41> Predicting the spectral library with 156 precursors and 0.01M fragments used 0.3971 GB memory\n",
      "2023-01-20 09:28:41> Saving HDF library to /Users/zengwenfeng/peptdeep/spec_libs/predict.speclib.hdf ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-20 09:28:42> Library generated!!\n"
     ]
    }
   ],
   "source": [
    "from peptdeep.pipeline_api import generate_library\n",
    "\n",
    "fasta = os.path.expanduser('~/Workspace/Data/fasta/irtfusion.fasta')\n",
    "lib_settings = global_settings['library']\n",
    "lib_settings['infile_type'] = 'fasta'\n",
    "lib_settings['infiles'] = [fasta]\n",
    "lib_settings['fasta']['add_contaminants'] = False\n",
    "\n",
    "if os.path.isfile(fasta):\n",
    "    generate_library()\n",
    "else:\n",
    "    print(\"`pipeline_api.generate_library()` will be not tested\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-20 09:28:42> Platform information:\n",
      "2023-01-20 09:28:42> system        - Darwin\n",
      "2023-01-20 09:28:42> release       - 20.6.0\n",
      "2023-01-20 09:28:42> version       - 10.16\n",
      "2023-01-20 09:28:42> machine       - x86_64\n",
      "2023-01-20 09:28:42> processor     - i386\n",
      "2023-01-20 09:28:42> cpu count     - 8\n",
      "2023-01-20 09:28:42> ram           - 10.7/32.0 Gb (available/total)\n",
      "2023-01-20 09:28:42> \n",
      "2023-01-20 09:28:42> Python information:\n",
      "2023-01-20 09:28:42> alphabase        - 1.0.0\n",
      "2023-01-20 09:28:42> biopython        - 1.78\n",
      "2023-01-20 09:28:42> click            - 8.1.3\n",
      "2023-01-20 09:28:42> lxml             - 4.6.2\n",
      "2023-01-20 09:28:42> numba            - 0.54.0\n",
      "2023-01-20 09:28:42> numpy            - 1.19.4\n",
      "2023-01-20 09:28:42> pandas           - 1.3.5\n",
      "2023-01-20 09:28:42> peptdeep         - 1.0.1\n",
      "2023-01-20 09:28:42> psutil           - 5.8.0\n",
      "2023-01-20 09:28:42> python           - 3.8.3\n",
      "2023-01-20 09:28:42> scikit-learn     - 1.1.1\n",
      "2023-01-20 09:28:42> streamlit        - 1.16.0\n",
      "2023-01-20 09:28:42> streamlit-aggrid - 0.2.1\n",
      "2023-01-20 09:28:42> torch            - 1.7.1\n",
      "2023-01-20 09:28:42> tqdm             - 4.56.0\n",
      "2023-01-20 09:28:42> transformers     - 4.25.1\n",
      "2023-01-20 09:28:42> \n",
      "2023-01-20 09:28:46> Loading PSMs and extracting fragments ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-20 09:28:54> Training CCS model ...\n",
      "2023-01-20 09:28:54> Finished training CCS model\n",
      "2023-01-20 09:28:54> Training RT model ...\n",
      "2023-01-20 09:28:54> 10 PSMs for RT model training/transfer learning\n",
      "2023-01-20 09:28:54> Training with fixed sequence length: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] Epoch=1, lr=5e-05, loss=0.23635914623737336\n",
      "[Training] Epoch=2, lr=0.0001, loss=0.23305423259735109\n",
      "[Training] Epoch=3, lr=7.500000000000001e-05, loss=0.22809805870056152\n",
      "[Training] Epoch=4, lr=2.500000000000001e-05, loss=0.22056499421596526\n",
      "[Training] Epoch=5, lr=0.0, loss=0.21937111914157867\n",
      "2023-01-20 09:28:55> Finished training RT model\n",
      "2023-01-20 09:28:55> Training MS2 model ...\n",
      "2023-01-20 09:28:55> 14 PSMs for MS2 model training/transfer learning\n",
      "2023-01-20 09:28:55> Training with fixed sequence length: 0\n",
      "[Training] Epoch=1, lr=5e-05, loss=0.023086506687104703\n",
      "[Training] Epoch=2, lr=0.0001, loss=0.023529775300994517\n",
      "[Training] Epoch=3, lr=7.500000000000001e-05, loss=0.020745731191709638\n",
      "[Training] Epoch=4, lr=2.500000000000001e-05, loss=0.019724564673379064\n",
      "[Training] Epoch=5, lr=0.0, loss=0.01900430452078581\n",
      "2023-01-20 09:28:57> Finished training MS2 model\n",
      "2023-01-20 09:28:57> Models were saved in /Users/zengwenfeng/peptdeep/refined_models\n"
     ]
    }
   ],
   "source": [
    "from peptdeep.pipeline_api import transfer_learn\n",
    "\n",
    "alphapept_hdf = os.path.expanduser('~/Workspace/Data/Thermo_iRT/iRT.ms_data.hdf')\n",
    "mgr_settings = global_settings['model_mgr']\n",
    "mgr_settings['transfer']['psm_files'] = [alphapept_hdf]\n",
    "mgr_settings['transfer']['psm_type'] = 'alphapept'\n",
    "mgr_settings['transfer']['ms_file_type'] = 'alphapept_hdf'\n",
    "mgr_settings['transfer']['ms_files'] = [alphapept_hdf]\n",
    "mgr_settings['transfer']['epoch_ms2'] = 5\n",
    "mgr_settings['transfer']['warmup_epoch_ms2'] = 2\n",
    "mgr_settings['transfer']['epoch_rt_ccs'] = 5\n",
    "mgr_settings['transfer']['warmup_epoch_rt_ccs'] = 2\n",
    "\n",
    "if os.path.isfile(alphapept_hdf):\n",
    "    transfer_learn()\n",
    "else:\n",
    "    print(\"`pipeline_api.transfer_learn()` will be not tested\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test rescore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`pipeline_api.rescore()` will be not tested\n"
     ]
    }
   ],
   "source": [
    "from peptdeep.pipeline_api import rescore\n",
    "\n",
    "alphapept_hdf = os.path.expanduser('~/Workspace/Data/HeLa_500ng/20201207_tims03_Evo03_PS_SA_HeLa_200ng_EvoSep_prot_DDA_21min_8cm_S1-C10_1_22476.ms_data.hdf')\n",
    "perc_settings = global_settings['percolator']\n",
    "perc_settings['input_files']['psm_files'] = [alphapept_hdf]\n",
    "perc_settings['input_files']['psm_type'] = 'alphapept'\n",
    "perc_settings['input_files']['ms_file_type'] = 'alphapept_hdf'\n",
    "perc_settings['input_files']['ms_files'] = [alphapept_hdf]\n",
    "perc_settings['require_model_tuning'] = False\n",
    "perc_settings['percolator_iter_num'] = 1\n",
    "perc_settings['multiprocessing'] = False\n",
    "\n",
    "if False and os.path.isfile(alphapept_hdf):\n",
    "    rescore()\n",
    "else:\n",
    "    print(\"`pipeline_api.rescore()` will be not tested\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
