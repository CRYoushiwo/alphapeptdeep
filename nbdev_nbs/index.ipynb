{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaPeptDeep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/MannLabs/alphapeptdeep/workflows/Default%20installation%20and%20tests/badge.svg\" alt=\"Pip Installation\">\n",
    "    <img src=\"https://github.com/MannLabs/alphapeptdeep/workflows/Default%20installation%20and%20tests/badge.svg\" /></a>\n",
    "<a href=\"https://github.com/MannLabs/alphapeptdeep/workflows/Publish%20on%20PyPi%20and%20release%20on%20GitHub/badge.svg\" alt=\"GUI and PyPi releases\">\n",
    "    <img src=\"https://github.com/MannLabs/alphapeptdeep/workflows/Publish%20on%20PyPi%20and%20release%20on%20GitHub/badge.svg\"/></a>\n",
    "<a href=\"https://pypi.org/project/peptdeep\" alt=\"pypi\">\n",
    "    <img src=\"https://img.shields.io/pypi/v/peptdeep\" /></a>\n",
    "<a href=\"https://github.com/MannLabs/alphapeptdeep/releases\" alt=\"release\">\n",
    "    <img src=\"https://img.shields.io/github/v/release/mannlabs/alphapeptdeep?display_name=tag\" /></a>\n",
    "<a href=\"https://github.com/MannLabs/alphapeptdeep/releases\" alt=\"release\">\n",
    "    <img src=\"https://img.shields.io/github/downloads/mannlabs/alphapeptdeep/total?label=github%20downloads\" /></a>\n",
    "<a href=\"https://github.com/MannLabs/alphapeptdeep/releases/tag/pre-trained-models\" alt=\"release\">\n",
    "    <img src=\"https://img.shields.io/github/downloads/mannlabs/alphapeptdeep/pre-trained-models/total\" /></a>\n",
    "<a href=\"https://pypi.org/project/peptdeep\" alt=\"release\">\n",
    "    <img src=\"https://img.shields.io/pypi/dm/peptdeep?color=blue&label=pip%20downloads\"/></a>\n",
    "<img src=\"https://img.shields.io/pypi/pyversions/peptdeep\"/>\n",
    "<img src=\"https://img.shields.io/github/languages/code-size/mannlabs/alphapeptdeep\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [**About**](#about)\n",
    "* [**License**](#license)\n",
    "* [**Installation**](#installation)\n",
    "  * [**One-click GUI**](#one-click-gui)\n",
    "  * [**Pip installer**](#pip)\n",
    "  * [**Use GPU**](#use-gpu)\n",
    "  * [**Developer installer**](#developer)\n",
    "* [**Usage**](#usage)\n",
    "  * [**GUI**](#gui)\n",
    "  * [**CLI**](#cli)\n",
    "  * [**Python and jupyter notebooks**](#python-and-jupyter-notebooks)\n",
    "* [**Troubleshooting**](#troubleshooting)\n",
    "* [**Citations**](#citations)\n",
    "* [**How to contribute**](#how-to-contribute)\n",
    "* [**Changelog**](#changelog)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "AlphaPeptDeep (`peptdeep` for short) aims to easily build new deep learning models for shotgun proteomics studies. Transfer learning is also easy to apply using AlphaPeptDeep.\n",
    "\n",
    "It contains some built-in models such as retention time (RT), collision cross section (CCS), and tandem mass spectrum (MS2) prediction for given peptides. With these models, one can easily generate a predicted library from fasta files.\n",
    "\n",
    "For details, check out our [publications](#citations). \n",
    "\n",
    "For documentation, see [GitHub pages](https://mannlabs.github.io/alphapeptdeep/).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "AlphaPeptDeep was developed by the [Mann Labs at the Max Planck Institute of Biochemistry](https://www.biochem.mpg.de/mann) and the [University of Copenhagen](https://www.cpr.ku.dk/research/proteomics/mann/) and is freely available with an [Apache License](LICENSE.txt). External Python packages (available in the [requirements](requirements) folder) have their own licenses, which can be consulted on their respective websites.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "AlphaPeptDeep can be installed and used on all major operating systems (Windows, macOS and Linux).\n",
    "\n",
    "There are three different types of installation possible:\n",
    "\n",
    "* [**One-click GUI installer:**](#one-click-gui) Choose this installation if you only want the GUI and/or keep things as simple as possible.\n",
    "* [**Pip installer:**](#pip) Choose this installation if you want to use peptdeep as a Python package in an existing Python (recommended Python 3.8) environment (e.g. a Jupyter notebook). If needed, the GUI and CLI can be installed with pip as well.\n",
    "* [**Developer installer:**](#developer) Choose this installation if you are familiar with CLI tools, [conda](https://docs.conda.io/en/latest/) and Python. This installation allows access to all available features of peptdeep and even allows to modify its source code directly. Generally, the developer version of peptdeep outperforms the precompiled versions which makes this the installation of choice for high-throughput experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-click GUI\n",
    "\n",
    "The GUI of peptdeep is a completely stand-alone tool that requires no knowledge of Python or CLI tools. Click on one of the links below to download the latest release for:\n",
    "\n",
    "* [**Windows**](https://github.com/MannLabs/alphapeptdeep/releases/latest/download/peptdeep_gui_installer_windows.exe)\n",
    "* [**macOS**](https://github.com/MannLabs/alphapeptdeep/releases/latest/download/peptdeep_gui_installer_macos.pkg)\n",
    "* [**Linux**](https://github.com/MannLabs/alphapeptdeep/releases/latest/download/peptdeep_gui_installer_linux.deb)\n",
    "\n",
    "Older releases remain available on the [release page](https://github.com/MannLabs/alphapeptdeep/releases), but no backwards compatibility is guaranteed.\n",
    "\n",
    "Note that these installers do not have GPU supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pip\n",
    "\n",
    "peptdeep can be installed in an existing Python 3.8 environment with a single `bash` command. *This `bash` command can also be run directly from within a Jupyter notebook by prepending it with a `!`*:\n",
    "\n",
    "```bash\n",
    "pip install peptdeep\n",
    "```\n",
    "\n",
    "Installing peptdeep like this avoids conflicts when integrating it in other tools, as this does not enforce strict versioning of dependancies. However, if new versions of dependancies are released, they are not guaranteed to be fully compatible with peptdeep. This should only occur in rare cases where dependencies are not backwards compatible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **TODO** You can always force peptdeep to use dependancy versions which are known to be compatible with:\n",
    "> ```bash\n",
    "> pip install \"peptdeep[stable]\"\n",
    "> ```\n",
    "> NOTE: You might need to run `pip install pip` before installing peptdeep like this. Also note the double quotes `\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those who are really adventurous, it is also possible to directly install any branch (e.g. `@development`) with any extras (e.g. `#egg=peptdeep[stable,development-stable]`) from GitHub with e.g.\n",
    "\n",
    "```bash\n",
    "pip install \"git+https://github.com/MannLabs/alphapeptdeep.git@development#egg=peptdeep[stable,development-stable]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GPU\n",
    "\n",
    "To enable GPU, GPU version of PyTorch is required, it can be installed with:\n",
    "\n",
    "```bash\n",
    "pip install torch --extra-index-url https://download.pytorch.org/whl/cu116 --upgrade\n",
    "```\n",
    "\n",
    "Note that this may depend on your NVIDIA driver version. Run the command to check your NVIDIA driver:\n",
    "\n",
    "```bash\n",
    "nvidia-smi\n",
    "```\n",
    "\n",
    "See [pytorch.org](https://pytorch.org/get-started/locally/) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developer\n",
    "\n",
    "peptdeep can also be installed in editable (i.e. developer) mode with a few `bash` commands. This allows to fully customize the software and even modify the source code to your specific needs. When an editable Python package is installed, its source code is stored in a transparent location of your choice. While optional, it is advised to first (create and) navigate to e.g. a general software folder:\n",
    "\n",
    "```bash\n",
    "mkdir ~/alphapeptdeep/project/folder\n",
    "cd ~/alphapeptdeep/project/folder\n",
    "```\n",
    "\n",
    "***The following commands assume you do not perform any additional `cd` commands anymore***.\n",
    "\n",
    "Next, download the peptdeep repository from GitHub either directly or with a `git` command. This creates a new peptdeep subfolder in your current directory.\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/MannLabs/alphapeptdeep.git\n",
    "```\n",
    "\n",
    "For any Python package, it is highly recommended to use a separate [conda virtual environment](https://docs.conda.io/en/latest/), as otherwise *dependancy conflicts can occur with already existing packages*.\n",
    "\n",
    "```bash\n",
    "conda create --name peptdeep python=3.8 -y\n",
    "conda activate peptdeep\n",
    "```\n",
    "\n",
    "Finally, peptdeep and all its [dependancies](requirements) need to be installed. To take advantage of all features and allow development (with the `-e` flag), this is best done by also installing the [development dependencies](requirements/requirements_development.txt) instead of only the [core dependencies](requirements/requirements.txt):\n",
    "\n",
    "```bash\n",
    "pip install -e \".[development]\"\n",
    "```\n",
    "\n",
    "By default this installs loose dependancies (no explicit versioning), although it is also possible to use stable dependencies (e.g. `pip install -e \".[stable,development-stable]\"`).\n",
    "\n",
    "***By using the editable flag `-e`, all modifications to the [peptdeep source code folder](peptdeep) are directly reflected when running peptdeep. Note that the peptdeep folder cannot be moved and/or renamed if an editable version is installed. In case of confusion, you can always retrieve the location of any Python module with e.g. the command `import module` followed by `module.__file__`.***\n",
    "\n",
    "We used [nbdev v2](https://nbdev.fast.ai/) for developers to build Python source code and docs smoothly from Python notebooks, so please do not edit .py files directly, edit .ipynb in `nbdev_nbs` folder instead. After installing nbdev, cd to alphapeptdeep project folder and run:\n",
    "```bash\n",
    "nbdev_install_hooks\n",
    "```\n",
    "to init gitconfig for nbdev. After editing the source code in .ipynb files, using `nbdev_export` to build python source code and `nbdev_test` to run all .ipynb files in `nbdev_nbs` for testing. Check [nbdev docs](https://nbdev.fast.ai/) for more information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "There are three ways to use peptdeep:\n",
    "\n",
    "* [**GUI**](#gui)\n",
    "* [**CLI**](#cli)\n",
    "* [**Python**](#python-and-jupyter-notebooks)\n",
    "\n",
    "NOTE: The first time you use a fresh installation of peptdeep, it is often quite slow because some functions might still need compilation on your local operating system and architecture. Subsequent use should be a lot faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GUI\n",
    "\n",
    "If the GUI was not installed through a one-click GUI installer, it can be activate with the following `bash` command:\n",
    "\n",
    "```bash\n",
    "peptdeep gui\n",
    "```\n",
    "This command will start a web server and automatically open the default browser:\n",
    "![](https://user-images.githubusercontent.com/4646029/189301730-ac1f92cc-0e9d-4ba3-be1d-07c4d66032cd.jpg)\n",
    "\n",
    "There are several options in the GUI (left panel):\n",
    "* Server: Start/stop the task server, check tasks in the task queue\n",
    "* Settings: Configure common settings, load/save current settings\n",
    "* Model: Configure DL models for prediction or transfer learning \n",
    "* Transfer: Refine the model\n",
    "* Library: Predict a library\n",
    "* Rescore: Perform ML feature extraction and Percolator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLI\n",
    "\n",
    "The CLI can be run with the following command (after activating the `conda` environment with `conda activate peptdeep` or if an alias was set to the peptdeep executable):\n",
    "\n",
    "```bash\n",
    "peptdeep -h\n",
    "```\n",
    "\n",
    "It is possible to get help about each function and their (required) parameters by using the `-h` flag. AlphaPeptDeep provides several commands for CLI uses:\n",
    "\n",
    "* [**export-settings**](#export-settings)\n",
    "* [**library**](#library)\n",
    "* [**transfer**](#transfer) \n",
    "* [**rescore**](#rescore)\n",
    "* [**install-models**](#install-models)\n",
    "* [**gui**](#gui)\n",
    "\n",
    "Run a command to check usages:\n",
    "```bash\n",
    "peptdeep $command -h\n",
    "```\n",
    "For example:\n",
    "```bash\n",
    "peptdeep library -h\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### export-settings\n",
    "\n",
    "```bash\n",
    "peptdeep export-settings yaml_file\n",
    "```\n",
    "\n",
    "This command will export the default settings into the `yaml_file` as a template, users can edit the yaml file to run other commands.\n",
    "\n",
    "The common settings in the yaml file are:\n",
    "\n",
    "```\n",
    "model_url: \"https://github.com/MannLabs/alphapeptdeep/releases/download/pre-trained-models/pretrained_models.zip\"\n",
    "\n",
    "thread_num: 8\n",
    "torch_device:\n",
    "  name: gpu\n",
    "  ids: []\n",
    "  name_choices:\n",
    "    - gpu\n",
    "    - cpu\n",
    "    - mps\n",
    "\n",
    "log_level: info\n",
    "log_level_choices:\n",
    "  - debug\n",
    "  - info\n",
    "  - warning\n",
    "  - error\n",
    "  - critical\n",
    "\n",
    "common:\n",
    "  modloss_importance_level: 1.0\n",
    "\n",
    "peak_matching:\n",
    "  ms2_ppm: True\n",
    "  ms2_tol_value: 20.0\n",
    "  ms1_ppm: True\n",
    "  ms1_tol_value: 20.0\n",
    "\n",
    "model_mgr:\n",
    "  default_nce: 30.0\n",
    "  default_instrument: Lumos\n",
    "  mask_modloss: True\n",
    "  model_type: generic\n",
    "  model_choices:\n",
    "  - generic\n",
    "  - phos\n",
    "  - hla # same as generic\n",
    "  - digly\n",
    "  external_ms2_model: ''\n",
    "  external_rt_model: ''\n",
    "  external_ccs_model: ''\n",
    "  instrument_group:\n",
    "    Lumos: Lumos\n",
    "    QE: QE\n",
    "    timsTOF: timsTOF\n",
    "    SciexTOF: SciexTOF\n",
    "    Fusion: Lumos\n",
    "    Eclipse: Lumos\n",
    "    Velos: Lumos # not important\n",
    "    Elite: Lumos # not important\n",
    "    OrbitrapTribrid: Lumos\n",
    "    ThermoTribrid: Lumos\n",
    "    QE+: QE\n",
    "    QEHF: QE\n",
    "    QEHFX: QE\n",
    "    Exploris: QE\n",
    "    Exploris480: QE\n",
    "  predict:\n",
    "    batch_size_ms2: 512\n",
    "    batch_size_rt_ccs: 1024\n",
    "    verbose: True\n",
    "    multiprocessing: True\n",
    "```\n",
    "\n",
    "The `model_mgr` section in the yaml defines the common settings for MS2/RT/CCS prediction.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### library\n",
    "\n",
    "```bash\n",
    "peptdeep library settings_yaml\n",
    "```\n",
    "\n",
    "This command will predict a spectral library for given settings_yaml file (exported by [export-settings](#export-settings)). All the essential settings are in the `library` section in the settings_yaml file:\n",
    "\n",
    "```\n",
    "library:\n",
    "  input:\n",
    "    infile_type: fasta\n",
    "    infile_type_choices:\n",
    "    - fasta\n",
    "    - sequence_table\n",
    "    - peptide_table\n",
    "    - precursor_table\n",
    "    infiles: \n",
    "    - xxx.fasta\n",
    "    fasta:\n",
    "      protease: '([KR])'\n",
    "      protease_choices:\n",
    "      - 'trypsin/P'\n",
    "      - '([KR])'\n",
    "      - 'trypsin'\n",
    "      - '([KR](?=[^P]))'\n",
    "      - 'lys-c'\n",
    "      - 'K'\n",
    "      - 'lys-n'\n",
    "      - '\\w(?=K)'\n",
    "      - 'chymotrypsin'\n",
    "      max_miss_cleave: 2\n",
    "    fix_mods: \n",
    "    - Carbamidomethyl@C\n",
    "    var_mods:\n",
    "    - Acetyl@Protein N-term\n",
    "    - Oxidation@M\n",
    "    min_var_mod_num: 0\n",
    "    max_var_mod_num: 2\n",
    "    min_precursor_charge: 2\n",
    "    max_precursor_charge: 4\n",
    "    min_peptide_len: 7\n",
    "    max_peptide_len: 35\n",
    "    min_precursor_mz: 200.0\n",
    "    max_precursor_mz: 2000.0\n",
    "    decoy: pseudo_reverse\n",
    "    decoy_choices:\n",
    "    - pseudo_reverse\n",
    "    - diann\n",
    "    - None\n",
    "    max_frag_charge: 2\n",
    "    frag_types:\n",
    "    - b\n",
    "    - y\n",
    "  output_folder: \"{PEPTDEEP_HOME}/spec_libs\"\n",
    "  output_tsv:\n",
    "    enabled: False\n",
    "    min_fragment_mz: 200\n",
    "    max_fragment_mz: 2000\n",
    "    min_relative_intensity: 0.01\n",
    "    keep_higest_k_peaks: 12\n",
    "    translate_batch_size: 1000000\n",
    "    translate_mod_to_unimod_id: False\n",
    "```\n",
    "\n",
    "peptdeep will load sequence data based on `library:input:infile_type` and `library:input:infiles` for library prediction. `library:input:infiles` contains the list of files with `library:input:infile_type` defined in `library:input:infile_type_choices`:\n",
    "\n",
    "* fasta: Protein fasta files. \n",
    "* sequence_table: Tab/comma-delimited txt/tsv/csv (text) files which contain the column `sequence`.\n",
    "* peptide_table: Tab/comma-delimited txt/tsv/csv (text) files which contain the columns `sequence`, `mods`, and `mod_sites`. peptdeep will not add modifications for this file type.\n",
    "* precursor_table: Tab/comma-delimited txt/tsv/csv (text) files which contain the columns `sequence`, `mods`, `mod_sites`, and `charge`. peptdeep will not add modifications and charge states for this file type.\n",
    "\n",
    ">Columns of `proteins` and `genes` are optional for these txt/tsv/csv files.\n",
    "\n",
    "For example, a precursor DataFrame looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>charge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACDEFGHIK</td>\n",
       "      <td>Carbamidomethyl@C</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LMNPQRSTVK</td>\n",
       "      <td>Acetyl@Protein N-term;Phospho@S</td>\n",
       "      <td>0;7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WYVSTR</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sequence                             mods mod_sites  charge\n",
       "0   ACDEFGHIK                Carbamidomethyl@C         2       2\n",
       "1  LMNPQRSTVK  Acetyl@Protein N-term;Phospho@S       0;7       3\n",
       "2      WYVSTR                                                  1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame({\n",
    "    'sequence': ['ACDEFGHIK','LMNPQRSTVK','WYVSTR'],\n",
    "    'mods': ['Carbamidomethyl@C','Acetyl@Protein N-term;Phospho@S',''],\n",
    "    'mod_sites': ['2','0;7',''],\n",
    "    'charge': [2,3,1],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "peptdeep supports multiple files for library prediction, for example (in the yaml file):\n",
    "```\n",
    "library:\n",
    "  input:\n",
    "    ...\n",
    "    infile_type: fasta\n",
    "    iifiles:\n",
    "    - /path/to/fasta/human.fasta\n",
    "    - /path/to/fasta/yeast.fasta\n",
    "    ...\n",
    "```\n",
    "\n",
    "The library in HDF5 (.hdf) format will be saved into `library:output_folder`. If `library:output_tsv:enabled` is True, a TSV spectral library that can be processed by DIA-NN and Spectronaut will also be saved into `library:output_folder`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### transfer\n",
    "\n",
    "```bash\n",
    "peptdeep transfer settings_yaml\n",
    "```\n",
    "\n",
    "This command will apply transfer learning to refine RT/CCS/MS2 models based on `model_mgr:transfer:psm_files` and `model_mgr:transfer:psm_type`. All yaml settings (exported by [export-settings](#export-settings)) related to this command are:\n",
    "\n",
    "```\n",
    "model_mgr:\n",
    "  transfer:\n",
    "    model_output_folder: \"{PEPTDEEP_HOME}/refined_models\"\n",
    "    epoch_ms2: 20\n",
    "    warmup_epoch_ms2: 10\n",
    "    batch_size_ms2: 512\n",
    "    lr_ms2: 0.0001\n",
    "    epoch_rt_ccs: 40\n",
    "    warmup_epoch_rt_ccs: 10\n",
    "    batch_size_rt_ccs: 1024\n",
    "    lr_rt_ccs: 0.0001\n",
    "    verbose: False\n",
    "    grid_nce_search: True\n",
    "    grid_nce_first: 15.0\n",
    "    grid_nce_last: 45.0\n",
    "    grid_nce_step: 3.0\n",
    "    grid_instrument: ['Lumos']\n",
    "    psm_type: alphapept\n",
    "    psm_type_choices:\n",
    "      - alphapept\n",
    "      - pfind\n",
    "      - maxquant\n",
    "      - diann\n",
    "      - speclib_tsv\n",
    "    psm_files: []\n",
    "    ms_file_type: alphapept_hdf\n",
    "    ms_file_type_choices:\n",
    "      - alphapept_hdf\n",
    "      - thermo_raw\n",
    "      - mgf\n",
    "      - mzml\n",
    "    ms_files: []\n",
    "    psm_num_to_train_ms2: 100000000\n",
    "    psm_num_per_mod_to_train_ms2: 50\n",
    "    psm_num_to_train_rt_ccs: 100000000\n",
    "    psm_num_per_mod_to_train_rt_ccs: 50\n",
    "    top_n_mods_to_train: 10\n",
    "```\n",
    "\n",
    "For DDA data, peptdeep can also extract MS2 intensities from the spectrum files from `model_mgr:transfer:ms_files` and `model_mgr:transfer:ms_file_type` for all PSMs. This will enable the transfer learning of the MS2 model.\n",
    "\n",
    "For DIA data, only RT and CCS (if timsTOF) models will be refined.\n",
    "\n",
    "For example of the settings yaml:\n",
    "```\n",
    "model_mgr:\n",
    "  transfer:\n",
    "    ...\n",
    "    psm_type: pfind\n",
    "    psm_files:\n",
    "    - /path/to/pFind.spectra\n",
    "    - /path/to/other/pFind.spectra\n",
    "\n",
    "    ms_file_type: thermo_raw\n",
    "    ms_files:\n",
    "    - /path/to/raw1.raw\n",
    "    - /path/to/raw2.raw\n",
    "    ...\n",
    "```\n",
    "\n",
    "The refined models will be saved in `model_mgr:transfer:model_output_folder`. After transfer learning, users can apply the new models by replacing `model_mgr:external_ms2_model`, `model_mgr:external_rt_model` and `model_mgr:external_ccs_model` with the saved `ms2.pth`, `rt.pth` and `ccs.pth` in `model_mgr:transfer:model_output_folder`. This is useful to perform sample-specific library prediction.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rescore\n",
    "\n",
    "This command will apply Percolator to rescore DDA PSMs in `percolator:input_files:psm_files` and `percolator:input_files:psm_type`. All yaml settings (exported by [export-settings](#export-settings)) related to this command are:\n",
    "\n",
    "```\n",
    "percolator:\n",
    "  require_model_tuning: True\n",
    "  raw_num_to_tune: 8\n",
    "\n",
    "  require_raw_specific_tuning: True\n",
    "  raw_specific_ms2_tuning: False\n",
    "  psm_num_per_raw_to_tune: 200\n",
    "  epoch_per_raw_to_tune: 5\n",
    "\n",
    "  multiprocessing: True\n",
    "\n",
    "  top_k_frags_to_calc_spc: 10\n",
    "  calibrate_frag_mass_error: False\n",
    "  max_perc_train_sample: 1000000\n",
    "  min_perc_train_sample: 100\n",
    "\n",
    "  percolator_backend: sklearn\n",
    "  percolator_backend_choices:\n",
    "    - sklearn\n",
    "    - pytorch\n",
    "  percolator_model: linear\n",
    "  percolator_model_choices:\n",
    "    pytorch_as_backend:\n",
    "      - linear # not fully tested, performance may be unstable\n",
    "      - mlp # not implemented yet\n",
    "    sklearn_as_backend:\n",
    "      - linear # logistic regression\n",
    "      - random_forest\n",
    "  lr_percolator_torch_model: 0.1 # learning rate, only used when percolator_backend==pytorch \n",
    "  percolator_iter_num: 5 # percolator iteration number\n",
    "  cv_fold: 1\n",
    "  fdr: 0.01\n",
    "  fdr_level: psm\n",
    "  fdr_level_choices:\n",
    "    - psm\n",
    "    - precursor\n",
    "    - peptide\n",
    "    - sequence\n",
    "  use_fdr_for_each_raw: False\n",
    "  frag_types: ['b_z1','b_z2','y_z1','y_z2']\n",
    "  input_files:\n",
    "    psm_type: alphapept\n",
    "    psm_type_choices:\n",
    "      - alphapept\n",
    "      - pfind\n",
    "      - maxquant\n",
    "    psm_files: []\n",
    "    ms_file_type: alphapept_hdf\n",
    "    ms_file_type_choices:\n",
    "      - hdf\n",
    "      - thermo_raw\n",
    "      - mgf\n",
    "      - mzml\n",
    "    ms_files: []\n",
    "    other_score_column_mapping:\n",
    "      alphapept: {}\n",
    "      pfind: \n",
    "        raw_score: Raw_Score\n",
    "      msfragger:\n",
    "        hyperscore: hyperscore\n",
    "        nextscore: nextscore\n",
    "      maxquant: {}\n",
    "  output_folder: \"{PEPTDEEP_HOME}/rescore\"\n",
    "```\n",
    "\n",
    "Transfer learning will be applied if `percolator:require_model_tuning` is True.\n",
    "\n",
    "The corresponding MS files (`percolator:input_files:ms_files` and `percolator:input_files:ms_file_type`) must be provided to extract experimental fragment intensities.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### install-models\n",
    "\n",
    "```bash\n",
    "peptdeep install-models --model-file url_or_local_model_zip --overwrite True\n",
    "```\n",
    "\n",
    "Running peptdeep for the first time, it will download and install models from [models on github](https://github.com/MannLabs/alphapeptdeep/releases/download/pre-trained-models/pretrained_models.zip) defined in 'model_url' in the default yaml settings. This command will update `pretrained_models.zip` from `--model-file url_or_local_model_zip`. \n",
    "\n",
    "It is also possible to use other models instead of the pretrained_models by providing `model_mgr:external_ms2_model`, `model_mgr:external_rt_model` and `model_mgr:external_ccs_model`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python and Jupyter notebooks\n",
    "\n",
    "Using peptdeep from Python script or notebook provides the most flexible way to access all features in peptdeep.\n",
    "\n",
    "We will introduce several usages of peptdeep via Python notebook:\n",
    "\n",
    "* [**global_settings**](#global_settings)\n",
    "* [**Pipeline APIs**](#pipeline-apis)\n",
    "* [**ModelManager**](#modelmanager)\n",
    "* [**Library Prediction**](#library-prediction)\n",
    "* [**DDA Rescoring**](#dda-rescoring)\n",
    "* [**HLA Peptide Prediction**](#hla-peptide-prediction)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### global_settings\n",
    "\n",
    "Most of the default parameters and attributes peptdeep functions and classes are controlled by `peptdeep.settings.global_settings` which is a `dict`. \n",
    "\n",
    "```Python\n",
    "from peptdeep.settings import global_settings\n",
    "```\n",
    "\n",
    "The default values of `global_settings` is defined in [default_settings.yaml](https://github.com/MannLabs/alphapeptdeep/blob/main/peptdeep/constants/default_settings.yaml)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline APIs\n",
    "\n",
    "Pipeline APIs provides the same functionalities with [CLI](#cli), including [library prediction](#library), [transfer learning](#transfer), and [rescoring](#rescore)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from peptdeep.pipeline_api import (\n",
    "    generate_library,\n",
    "    transfer_learn, \n",
    "    rescore,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these functionalities take a `settings_dict` as the inputs, the dict structure is the same as the settings yaml file. See the documatation of `generate_library`, `transfer_learn`, and `rescore`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from peptdeep.pretrained_models import ModelManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ModelManager` class is the main entry to access MS2/RT/CCS models. It provides functionalities to train/refine the models and then use the new models to predict the data.\n",
    "\n",
    "Check out [tutorial_model_manager.ipynb](https://github.com/MannLabs/alphapeptdeep/blob/main/nbs/tutorial_model_manager.ipynb) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from peptdeep.protein.fasta import PredictFastaSpecLib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PredictFastaSpecLib` class provides functionalities to deal with fasta files or protein sequences and spectral libraries.\n",
    "\n",
    "Check out [tutorial_speclib_from_fasta.ipynb](https://github.com/MannLabs/alphapeptdeep/blob/main/nbs/tutorial_speclib_from_fasta.ipynb) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DDA Rescoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from peptdeep.rescore.percolator import Percolator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Percolator` class provides functionalities to rescore DDA PSMs search by `pFind` and `AlphaPept`, (and `MaxQuant` if output FDR=100%), ...\n",
    "\n",
    "Check out [test_percolator.ipynb](https://github.com/MannLabs/alphapeptdeep/blob/main/nbs_tests/test_percolator.ipynb) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HLA Peptide Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from peptdeep.model.model_interface import ModelInterface\n",
    "import peptdeep.model.generic_property_prediction # model shop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building new DL models for peptide property prediction is one of the key features of AlphaPeptDeep. The key functionalities are `ModelInterface` and the pre-designed models and model interfaces in the model shop (module `peptdeep.model.generic_property_prediction`).\n",
    "\n",
    "For example, we can built a HLA classifier that distinguishes HLA peptides from non-HLA peptides, see [HLA_peptide_prediction.ipynb](https://github.com/MannLabs/alphapeptdeep/blob/main/nbs/HLA_peptide_prediction.ipynb) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "In case of issues, check out the following:\n",
    "\n",
    "* [Issues](https://github.com/MannLabs/alphapeptdeep/issues). Try a few different search terms to find out if a similar problem has been encountered before.\n",
    "\n",
    "* [Discussions](https://github.com/MannLabs/alphapeptdeep/discussions). Check if your problem or feature requests has been discussed before.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "Wen-Feng Zeng, Xie-Xuan Zhou, Sander Willems, Constantin Ammar, Maria Wahle, Isabell Bludau, Eugenia Voytik, Maximillian T. Strauss, Matthias Mann. [BioRxiv](https://www.biorxiv.org/content/10.1101/2022.07.14.499992v1).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to contribute\n",
    "\n",
    "If you like this software, you can give us a [star](https://github.com/MannLabs/alphapeptdeep/stargazers) to boost our visibility! All direct contributions are also welcome. Feel free to post a new [issue](https://github.com/MannLabs/alphapeptdeep/issues) or clone the repository and create a [pull request](https://github.com/MannLabs/alphapeptdeep/pulls) with a new branch. For an even more interactive participation, check out the [discussions](https://github.com/MannLabs/alphapeptdeep/discussions) and the [the Contributors License Agreement](misc/CLA.md).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changelog\n",
    "\n",
    "See the [HISTORY.md](HISTORY.md) for a full overview of the changes made in each version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
