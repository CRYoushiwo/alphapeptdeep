{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp pretrained_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated functionalities for MS2/RT/CCS models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`peptdeep.pretrained_models` handles the pretrained models, including downloading, installing, and loading the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Downloading and installing the models\n",
    "For continuous model deployment, we uploaded several pretrained models (compressed as a ZIP file) onto a net disk. peptdeep will automatically download the ZIP file into `global_settings['PEPTDEEP_HOME']/pretrained_models/pretrained_models.zip` when importing peptdeep.pretrained_models. The models will be downloaded only once, if we would like to update them to the latest models, we can call `download_models(overwrite=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import pathlib\n",
    "import io\n",
    "import pandas as pd\n",
    "import torch\n",
    "import urllib\n",
    "import socket\n",
    "import logging\n",
    "import shutil\n",
    "import ssl\n",
    "from pickle import UnpicklingError\n",
    "import torch.multiprocessing as mp\n",
    "from typing import Dict\n",
    "from zipfile import ZipFile\n",
    "from tarfile import TarFile\n",
    "from typing import Tuple\n",
    "\n",
    "from alphabase.peptide.fragment import (\n",
    "    create_fragment_mz_dataframe,\n",
    "    get_charged_frag_types,\n",
    "    concat_precursor_fragment_dataframes\n",
    ")\n",
    "from alphabase.peptide.precursor import (\n",
    "    refine_precursor_df,\n",
    "    update_precursor_mz\n",
    ")\n",
    "from alphabase.peptide.mobility import (\n",
    "    mobility_to_ccs_for_df,\n",
    "    ccs_to_mobility_for_df\n",
    ")\n",
    "\n",
    "from peptdeep.settings import global_settings\n",
    "from peptdeep.utils import logging, process_bar\n",
    "from peptdeep.settings import global_settings\n",
    "\n",
    "from peptdeep.model.ms2 import (\n",
    "    pDeepModel, normalize_training_intensities\n",
    ")\n",
    "from peptdeep.model.rt import AlphaRTModel\n",
    "from peptdeep.model.ccs import AlphaCCSModel\n",
    "from peptdeep.utils import uniform_sampling\n",
    "\n",
    "from peptdeep.settings import global_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "pretrain_dir = os.path.join(\n",
    "    os.path.join(\n",
    "        os.path.expanduser(\n",
    "            global_settings['PEPTDEEP_HOME']\n",
    "        ),\n",
    "        \"pretrained_models\"\n",
    "    )\n",
    ")\n",
    "\n",
    "if not os.path.exists(pretrain_dir):\n",
    "    os.makedirs(pretrain_dir)\n",
    "\n",
    "model_zip_name = global_settings['local_model_zip_name']\n",
    "model_url = global_settings['model_url']\n",
    "\n",
    "model_zip = os.path.join(\n",
    "    pretrain_dir, model_zip_name\n",
    ")\n",
    "\n",
    "def is_model_zip(downloaded_zip):\n",
    "    with ZipFile(downloaded_zip) as zip:\n",
    "        return any(x=='generic/ms2.pth' for x in zip.namelist())\n",
    "\n",
    "def download_models(\n",
    "    url:str=model_url, overwrite=True\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str, optional\n",
    "        Remote or local path. \n",
    "        Defaults to `peptdeep.pretrained_models.model_url`\n",
    "\n",
    "    overwrite : bool, optional\n",
    "        overwirte old model files. \n",
    "        Defaults to True.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    FileNotFoundError\n",
    "        If remote url is not accessible.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(url):\n",
    "        logging.info(f'Downloading {model_zip_name} ...')\n",
    "        try:\n",
    "            context = ssl._create_unverified_context()\n",
    "            requests = urllib.request.urlopen(url, context=context, timeout=10)\n",
    "            with open(model_zip, 'wb') as f:\n",
    "                f.write(requests.read())\n",
    "        except (\n",
    "            socket.timeout, \n",
    "            urllib.error.URLError, \n",
    "            urllib.error.HTTPError\n",
    "        ) as e:\n",
    "            raise FileNotFoundError(\n",
    "                'Downloading model failed! Please download the '\n",
    "                f'zip or tar file by yourself from \"{url}\",'\n",
    "                ' and use \\n'\n",
    "                f'\"peptdeep --install-model /path/to/{model_zip_name}.zip\"\\n'\n",
    "                ' to install the models'\n",
    "            )\n",
    "    else:\n",
    "        shutil.copy(\n",
    "            url, model_zip\n",
    "        )\n",
    "    logging.info(f'The pretrained models had been downloaded in {model_zip}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if not os.path.exists(model_zip):\n",
    "    download_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "assert is_model_zip(model_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the models\n",
    "peptdeep provides a convenient APIs to load models from ZIP files. \n",
    "\n",
    "`load_models()` will load the generic models for unmodified peptides, `load_phos_models()` will load the phospho models. Note that MS2/CCS prediction models are the same for generic and phospho models because this model was trained on both generic and phospho peptides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "model_mgr_settings = global_settings['model_mgr']\n",
    "\n",
    "def count_mods(psm_df)->pd.DataFrame:\n",
    "    mods = psm_df[\n",
    "        psm_df.mods.str.len()>0\n",
    "    ].mods.apply(lambda x: x.split(';'))\n",
    "    mod_dict = {}\n",
    "    mod_dict['mutation'] = {}\n",
    "    mod_dict['mutation']['spec_count'] = 0\n",
    "    for one_mods in mods.values:\n",
    "        for mod in set(one_mods):\n",
    "            items = mod.split('->')\n",
    "            if (\n",
    "                len(items)==2 \n",
    "                and len(items[0])==3 \n",
    "                and len(items[1])==5\n",
    "            ):\n",
    "                mod_dict['mutation']['spec_count'] += 1\n",
    "            elif mod not in mod_dict:\n",
    "                mod_dict[mod] = {}\n",
    "                mod_dict[mod]['spec_count'] = 1\n",
    "            else:\n",
    "                mod_dict[mod]['spec_count'] += 1\n",
    "    return pd.DataFrame().from_dict(\n",
    "            mod_dict, orient='index'\n",
    "        ).reset_index(drop=False).rename(\n",
    "            columns={'index':'mod'}\n",
    "        ).sort_values(\n",
    "            'spec_count',ascending=False\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "def psm_sampling_with_important_mods(\n",
    "    psm_df, n_sample, \n",
    "    top_n_mods = 10,\n",
    "    n_sample_each_mod = 0, \n",
    "    uniform_sampling_column = None,\n",
    "    random_state=1337,\n",
    "):\n",
    "    psm_df_list = []\n",
    "    if uniform_sampling_column is None:\n",
    "        def _sample(psm_df, n):\n",
    "            if n < len(psm_df):\n",
    "                return psm_df.sample(\n",
    "                    n, replace=False,\n",
    "                    random_state=random_state\n",
    "                ).copy()\n",
    "            else:\n",
    "                return psm_df.copy()\n",
    "    else:\n",
    "        def _sample(psm_df, n):\n",
    "            return uniform_sampling(\n",
    "                psm_df, target=uniform_sampling_column,\n",
    "                n_train = n, random_state=random_state\n",
    "            )\n",
    "\n",
    "    psm_df_list.append(_sample(psm_df, n_sample))\n",
    "    if n_sample_each_mod > 0:\n",
    "        mod_df = count_mods(psm_df)\n",
    "        mod_df = mod_df[mod_df['mod']!='mutation']\n",
    "\n",
    "        if len(mod_df) > top_n_mods:\n",
    "            mod_df = mod_df.iloc[:top_n_mods,:]\n",
    "        for mod in mod_df['mod'].values:\n",
    "            psm_df_list.append(\n",
    "                _sample(\n",
    "                    psm_df[psm_df.mods.str.contains(mod, regex=False)],\n",
    "                    n_sample_each_mod,\n",
    "                )\n",
    "            )\n",
    "    if len(psm_df_list) > 0:\n",
    "        return pd.concat(psm_df_list, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_phos_models(mask_modloss=True):\n",
    "    ms2_model = pDeepModel(mask_modloss=mask_modloss)\n",
    "    ms2_model.load(model_zip, model_path_in_zip='phospho/ms2_phos.pth')\n",
    "    rt_model = AlphaRTModel()\n",
    "    rt_model.load(model_zip, model_path_in_zip='phospho/rt_phos.pth')\n",
    "    ccs_model = AlphaCCSModel()\n",
    "    ccs_model.load(model_zip, model_path_in_zip='generic/ccs.pth')\n",
    "    return ms2_model, rt_model, ccs_model\n",
    "\n",
    "def load_models(mask_modloss=True):\n",
    "    ms2_model = pDeepModel(mask_modloss=mask_modloss)\n",
    "    ms2_model.load(model_zip, model_path_in_zip='generic/ms2.pth')\n",
    "    rt_model = AlphaRTModel()\n",
    "    rt_model.load(model_zip, model_path_in_zip='generic/rt.pth')\n",
    "    ccs_model = AlphaCCSModel()\n",
    "    ccs_model.load(model_zip, model_path_in_zip='generic/ccs.pth')\n",
    "    return ms2_model, rt_model, ccs_model\n",
    "\n",
    "def load_models_by_model_type_in_zip(model_type_in_zip:str, mask_modloss=True):\n",
    "    ms2_model = pDeepModel(mask_modloss=mask_modloss)\n",
    "    ms2_model.load(model_zip, model_path_in_zip=f'{model_type_in_zip}/ms2.pth')\n",
    "    rt_model = AlphaRTModel()\n",
    "    rt_model.load(model_zip, model_path_in_zip=f'{model_type_in_zip}/rt.pth')\n",
    "    ccs_model = AlphaCCSModel()\n",
    "    ccs_model.load(model_zip, model_path_in_zip=f'{model_type_in_zip}/ccs.pth')\n",
    "    return ms2_model, rt_model, ccs_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using `ModelManager`\n",
    "\n",
    "For users, `ModelManager` class is the only thing we need to manage models (loading, transfer learning, etc). According to different arguments, `ModelManager::load_installed_models()` will call `load_models()` or `load_phos_models()`. For external models, `ModelManager::load_external_models()` will load them by file path or file stream. Here is an example:\n",
    "\n",
    "```\n",
    "from zipfile import ZipFile\n",
    "\n",
    "admodel = ModelManager()\n",
    "ext_zip = 'external_models.zip' # model compressed in ZIP\n",
    "rt_model_path = '/path/to/rt.pth' # model as file path\n",
    "with ZipFile(ext_zip) as model_zip:\n",
    "    with model_zip.open('generic/ms2.pth','r') as ms2_file:\n",
    "        admodel.load_external_models(ms2_model_file=ms2_file, rt_model_file=rt_model_path)\n",
    "```\n",
    "\n",
    "Transfer learning for different models could also be done in `ModelManager` by using the given training dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def clear_error_modloss_intensities(\n",
    "    fragment_mz_df, fragment_intensity_df\n",
    "):\n",
    "    # clear error modloss intensities\n",
    "    for col in fragment_mz_df.columns.values:\n",
    "        if 'modloss' in col:\n",
    "            fragment_intensity_df.loc[\n",
    "                fragment_mz_df[col]==0,col\n",
    "            ] = 0\n",
    "\n",
    "class ModelManager(object):\n",
    "    def __init__(self, \n",
    "        mask_modloss:bool=model_mgr_settings['mask_modloss'],\n",
    "        device:str='gpu',\n",
    "        mgr_settings:dict=model_mgr_settings,\n",
    "    ):\n",
    "        \"\"\" The manager class to access MS2/RT/CCS models.\n",
    "\n",
    "        Args:\n",
    "            mask_modloss (bool, optional): If modloss ions are masked to zeros\n",
    "                in the ms2 model. `modloss` ions are mostly useful for phospho \n",
    "                MS2 prediciton model. \n",
    "                Defaults to :py:data:`global_settings`['model_mgr']['mask_modloss'].\n",
    "            device (str, optional): Device for DL models, could be 'gpu' ('cuda') or 'cpu'.\n",
    "                if device=='gpu' but no GPUs are detected, it will automatically switch to 'cpu'.\n",
    "                Defaults to 'gpu'.\n",
    "                \n",
    "        Attributes:\n",
    "            ms2_model (:py:class:`peptdeep.model.ms2.pDeepModel`): The MS2 \n",
    "                prediction model.\n",
    "            rt_model (:py:class:`peptdeep.model.rt.AlphaRTModel`): The RT prediction model.\n",
    "            ccs_model (:py:class:`peptdeep.model.ccs.AlphaCCSModel`): The CCS prediciton model.\n",
    "            psm_num_to_train_ms2 (int): Number of PSMs to train the MS2 model. \n",
    "                Defaults to global_settings['model_mgr']['transfer']['psm_num_to_train_ms2'].\n",
    "            epoch_to_train_ms2 (int): Number of epoches to train the MS2 model. \n",
    "                Defaults to global_settings['model_mgr']['transfer']['epoch_ms2'].\n",
    "            psm_num_to_train_rt_ccs (int): Number of PSMs to train RT/CCS model. \n",
    "                Defaults to global_settings['model_mgr']['transfer']['psm_num_to_train_rt_ccs'].\n",
    "            epoch_to_train_rt_ccs (int): Number of epoches to train RT/CCS model. \n",
    "                Defaults to global_settings['model_mgr']['transfer']['epoch_rt_ccs'].\n",
    "            nce (float): Default NCE value for a precursor_df without the 'nce' column.\n",
    "                Defaults to global_settings['model_mgr']['default_nce'].\n",
    "            instrument (str): Default instrument type for a precursor_df without the 'instrument' column.\n",
    "                Defaults to global_settings['model_mgr']['default_instrument'].\n",
    "            use_grid_nce_search (bool): If self.ms2_model uses \n",
    "                :py:meth:`peptdeep.model.ms2.pDeepModel.grid_nce_search` to determine optimal\n",
    "                NCE and instrument type. This will change `self.nce` and `self.instrument` values.\n",
    "                Defaults to global_settings['model_mgr']['transfer']['grid_nce_search'].\n",
    "        \"\"\"\n",
    "        self.mgr_settings = mgr_settings\n",
    "\n",
    "        self.ms2_model:pDeepModel = pDeepModel(mask_modloss=mask_modloss, device=device)\n",
    "        self.rt_model:AlphaRTModel = AlphaRTModel(device=device)\n",
    "        self.ccs_model:AlphaCCSModel = AlphaCCSModel(device=device)\n",
    "\n",
    "        self.load_installed_models(mgr_settings['model_type'])\n",
    "        self.load_external_models(\n",
    "            ms2_model_file = mgr_settings['external_ms2_model'],\n",
    "            rt_model_file = mgr_settings['external_rt_model'],\n",
    "            ccs_model_file = mgr_settings['external_ccs_model'],\n",
    "        )\n",
    "\n",
    "        self.use_grid_nce_search = mgr_settings[\n",
    "            'transfer'\n",
    "        ]['grid_nce_search']\n",
    "\n",
    "        self.psm_num_to_train_ms2 = mgr_settings[\n",
    "            \"transfer\"\n",
    "        ][\"psm_num_to_train_ms2\"]\n",
    "        self.epoch_to_train_ms2 = mgr_settings[\n",
    "            'transfer'\n",
    "        ]['epoch_ms2']\n",
    "        self.warmup_epoch_to_train_ms2 = mgr_settings[\n",
    "            'transfer'\n",
    "        ]['warmup_epoch_ms2']\n",
    "        self.batch_size_to_train_ms2 = mgr_settings[\n",
    "            'transfer'\n",
    "        ]['batch_size_ms2']\n",
    "        self.lr_to_train_ms2 = float(\n",
    "            mgr_settings[\n",
    "                'transfer'\n",
    "            ]['lr_ms2']\n",
    "        )\n",
    "\n",
    "        self.psm_num_to_train_rt_ccs = mgr_settings[\n",
    "            \"transfer\"\n",
    "        ][\"psm_num_to_train_rt_ccs\"]\n",
    "        self.epoch_to_train_rt_ccs = mgr_settings[\n",
    "            'transfer'\n",
    "        ]['epoch_rt_ccs']\n",
    "        self.warmup_epoch_to_train_rt_ccs = mgr_settings[\n",
    "            'transfer'\n",
    "        ]['warmup_epoch_rt_ccs']\n",
    "        self.batch_size_to_train_rt_ccs = mgr_settings[\n",
    "            'transfer'\n",
    "        ]['batch_size_rt_ccs']\n",
    "        self.lr_to_train_rt_ccs = float(\n",
    "            mgr_settings[\n",
    "                'transfer'\n",
    "            ]['lr_rt_ccs']\n",
    "        )\n",
    "\n",
    "        self.psm_num_per_mod_to_train_ms2 = mgr_settings[\n",
    "            'transfer'\n",
    "        ][\"psm_num_per_mod_to_train_ms2\"]\n",
    "        self.psm_num_per_mod_to_train_rt_ccs = mgr_settings[\n",
    "            'transfer'\n",
    "        ][\"psm_num_per_mod_to_train_rt_ccs\"]\n",
    "        self.top_n_mods_to_train = mgr_settings[\n",
    "            'transfer'\n",
    "        ][\"top_n_mods_to_train\"]\n",
    "\n",
    "        self.nce = mgr_settings['default_nce']\n",
    "        self.instrument = mgr_settings['default_instrument']\n",
    "        self.verbose = mgr_settings['predict']['verbose']\n",
    "        self.train_verbose = mgr_settings['transfer']['verbose']\n",
    "\n",
    "\n",
    "    @property\n",
    "    def instrument(self):\n",
    "        return self._instrument\n",
    "    @instrument.setter\n",
    "    def instrument(self, instrument_name:str):\n",
    "        instrument_name = instrument_name.upper()\n",
    "        if instrument_name in self.mgr_settings[\n",
    "            'instrument_group'\n",
    "        ]:\n",
    "            self._instrument = self.mgr_settings[\n",
    "                'instrument_group'\n",
    "            ][instrument_name]\n",
    "        else:\n",
    "            self._instrument = 'Lumos'\n",
    "\n",
    "    def set_default_nce_instrument(self, df):\n",
    "        if 'nce' not in df.columns and 'instrument' not in df.columns:\n",
    "            df['nce'] = self.nce\n",
    "            df['instrument'] = self.instrument\n",
    "        elif 'nce' not in df.columns:\n",
    "            df['nce'] = self.nce\n",
    "        elif 'instrument' not in df.columns:\n",
    "            df['instrument'] = self.instrument\n",
    "\n",
    "    def set_default_nce(self, df):\n",
    "        self.set_default_nce_instrument(df)\n",
    "\n",
    "    def load_installed_models(self, \n",
    "        model_type:str=model_mgr_settings['model_type']\n",
    "    ):\n",
    "        \"\"\" Load built-in MS2/CCS/RT models.\n",
    "        Args:\n",
    "            model_type (str, optional): To load the installed MS2/RT/CCS models \n",
    "                or phos MS2/RT/CCS models. It could be 'digly', 'phospho', 'HLA', or 'generic'.\n",
    "                Defaults to `global_settings['model_mgr']['model_type']` ('generic').\n",
    "        \"\"\"\n",
    "        if model_type.lower() in [\n",
    "            'phospho','phos','phosphorylation'\n",
    "        ]:\n",
    "            self.ms2_model.load(\n",
    "                model_zip,\n",
    "                model_path_in_zip='generic/ms2.pth'\n",
    "            )\n",
    "            self.rt_model.load(\n",
    "                model_zip, \n",
    "                model_path_in_zip='phospho/rt_phos.pth'\n",
    "            )\n",
    "            self.ccs_model.load(\n",
    "                model_zip, \n",
    "                model_path_in_zip='generic/ccs.pth'\n",
    "            )\n",
    "        elif model_type.lower() in [\n",
    "            'digly','glygly','ubiquitylation', \n",
    "            'ubiquitination','ubiquitinylation'\n",
    "        ]:\n",
    "            self.ms2_model.load(\n",
    "                model_zip,\n",
    "                model_path_in_zip='generic/ms2.pth'\n",
    "            )\n",
    "            self.rt_model.load(\n",
    "                model_zip, \n",
    "                model_path_in_zip='digly/rt_digly.pth'\n",
    "            )\n",
    "            self.ccs_model.load(\n",
    "                model_zip, \n",
    "                model_path_in_zip='generic/ccs.pth'\n",
    "            )\n",
    "        elif model_type.lower() in ['regular','common','generic']:\n",
    "            self.ms2_model.load(\n",
    "                model_zip, model_path_in_zip='generic/ms2.pth'\n",
    "            )\n",
    "            self.rt_model.load(\n",
    "                model_zip, model_path_in_zip='generic/rt.pth'\n",
    "            )\n",
    "            self.ccs_model.load(\n",
    "                model_zip, model_path_in_zip='generic/ccs.pth'\n",
    "            )\n",
    "        elif model_type.lower() in [\n",
    "            'hla','unspecific','non-specific', 'nonspecific'\n",
    "        ]:\n",
    "            self.load_installed_models(model_type=\"generic\")\n",
    "        else:\n",
    "            logging.warning(\n",
    "                f\"model_type='{model_type}' is not supported, use 'generic' instead.\"\n",
    "            )\n",
    "            self.load_installed_models(model_type=\"generic\")\n",
    "\n",
    "    def load_external_models(self,\n",
    "        *,\n",
    "        ms2_model_file: Tuple[str, io.BytesIO]=model_mgr_settings['external_ms2_model'],\n",
    "        rt_model_file: Tuple[str, io.BytesIO]=model_mgr_settings['external_rt_model'],\n",
    "        ccs_model_file: Tuple[str, io.BytesIO]=model_mgr_settings['external_ccs_model'],\n",
    "    ):\n",
    "        \"\"\"Load external MS2/RT/CCS models.\n",
    "\n",
    "        Args:\n",
    "            ms2_model_file (Tuple[str, io.BytesIO], optional): ms2 model file or stream.\n",
    "                Do nothing if the value is ''. Defaults to global_settings['model_mgr']['external_ms2_model'].\n",
    "            rt_model_file (Tuple[str, io.BytesIO], optional): rt model file or stream.\n",
    "                Do nothing if the value is ''. Defaults to global_settings['model_mgr']['external_rt_model'].\n",
    "            ccs_model_file (Tuple[str, io.BytesIO], optional): ccs model or stream.\n",
    "                Do nothing if the value is ''. Defaults to global_settings['model_mgr']['external_ccs_model'].\n",
    "        \"\"\"\n",
    "\n",
    "        def _load_file(model, model_file):\n",
    "            try:\n",
    "                if isinstance(model_file, str):\n",
    "                    if os.path.isfile(model_file):\n",
    "                        model.load(model_file)\n",
    "                    else:\n",
    "                        return\n",
    "                model.load(model_file)\n",
    "            except UnpicklingError as e:\n",
    "                logging.info(f\"Cannot load {model_file} as {model.__class__} model, peptdeep will use the pretrained model instead.\")\n",
    "\n",
    "        _load_file(self.ms2_model, ms2_model_file)\n",
    "        _load_file(self.rt_model, rt_model_file)\n",
    "        _load_file(self.ccs_model, ccs_model_file)\n",
    "\n",
    "    def train_rt_model(self,\n",
    "        psm_df:pd.DataFrame,\n",
    "    ):\n",
    "        \"\"\" Train/fine-tune the RT model. The fine-tuning will be skipped \n",
    "            if `self.psm_num_to_train_rt_ccs` is zero.\n",
    "\n",
    "        Args:\n",
    "            psm_df (pd.DataFrame): training psm_df which contains 'rt_norm' column.\n",
    "        \"\"\"\n",
    "        if self.psm_num_to_train_rt_ccs > 0:\n",
    "            if self.psm_num_per_mod_to_train_rt_ccs < len(psm_df):\n",
    "                tr_df = psm_sampling_with_important_mods(\n",
    "                    psm_df, self.psm_num_to_train_rt_ccs,\n",
    "                    self.top_n_mods_to_train,\n",
    "                    self.psm_num_per_mod_to_train_rt_ccs,\n",
    "                    uniform_sampling_column='rt_norm'\n",
    "                )\n",
    "            else:\n",
    "                tr_df = psm_df\n",
    "            if len(tr_df) > 0:\n",
    "                self.rt_model.train(tr_df, \n",
    "                    batch_size=self.batch_size_to_train_rt_ccs,\n",
    "                    epoch=self.epoch_to_train_rt_ccs,\n",
    "                    warmup_epoch=self.warmup_epoch_to_train_rt_ccs,\n",
    "                    lr=self.lr_to_train_rt_ccs,\n",
    "                    verbose=self.train_verbose,\n",
    "                )\n",
    "\n",
    "    def train_ccs_model(self,\n",
    "        psm_df:pd.DataFrame,\n",
    "    ):\n",
    "        \"\"\" Train/fine-tune the CCS model. The fine-tuning will be skipped\n",
    "            if `self.psm_num_to_train_rt_ccs` is zero.\n",
    "\n",
    "        Args:\n",
    "            psm_df (pd.DataFrame): training psm_df which contains \n",
    "            'ccs' or 'mobility' column.\n",
    "        \"\"\"\n",
    "\n",
    "        if 'mobility' not in psm_df.columns or 'ccs' not in psm_df.columns:\n",
    "            return\n",
    "        elif 'ccs' not in psm_df.columns:\n",
    "            psm_df['ccs'] = mobility_to_ccs_for_df(\n",
    "                psm_df, 'mobility'\n",
    "            )\n",
    "        elif 'mobility' not in psm_df.columns:\n",
    "            psm_df['mobility'] = ccs_to_mobility_for_df(\n",
    "                psm_df, 'ccs'\n",
    "            )\n",
    "\n",
    "        if self.psm_num_to_train_rt_ccs > 0:\n",
    "            if self.psm_num_per_mod_to_train_rt_ccs < len(psm_df):\n",
    "                tr_df = psm_sampling_with_important_mods(\n",
    "                    psm_df, self.psm_num_to_train_rt_ccs,\n",
    "                    self.top_n_mods_to_train,\n",
    "                    self.psm_num_per_mod_to_train_rt_ccs,\n",
    "                    uniform_sampling_column='ccs'\n",
    "                )\n",
    "            else:\n",
    "                tr_df = psm_df\n",
    "            if len(tr_df) > 0:\n",
    "                self.ccs_model.train(tr_df, \n",
    "                    batch_size=self.batch_size_to_train_rt_ccs,\n",
    "                    epoch=self.epoch_to_train_rt_ccs,\n",
    "                    warmup_epoch=self.warmup_epoch_to_train_rt_ccs,\n",
    "                    lr=self.lr_to_train_rt_ccs,\n",
    "                    verbose=self.train_verbose,\n",
    "                )\n",
    "\n",
    "    def train_ms2_model(self,\n",
    "        psm_df: pd.DataFrame,\n",
    "        matched_intensity_df: pd.DataFrame,\n",
    "    ):\n",
    "        \"\"\"Using matched_intensity_df to train/fine-tune the ms2 model. \n",
    "        1. It will sample `n=self.psm_num_to_train_ms2` PSMs into training dataframe (`tr_df`) to for fine-tuning.\n",
    "        2. This method will also consider some important PTMs (`n=self.top_n_mods_to_train`) into `tr_df` for fine-tuning. \n",
    "        3. If `self.use_grid_nce_search==True`, this method will call `self.ms2_model.grid_nce_search` to find the best NCE and instrument.\n",
    "\n",
    "        Args:\n",
    "            psm_df (pd.DataFrame): PSM dataframe for fine-tuning.\n",
    "            matched_intensity_df (pd.DataFrame): The matched fragment intensities for `psm_df`.\n",
    "        \"\"\"\n",
    "        if self.psm_num_to_train_ms2 > 0:\n",
    "            if self.psm_num_to_train_ms2 < len(psm_df):\n",
    "                tr_df = psm_sampling_with_important_mods(\n",
    "                    psm_df, self.psm_num_to_train_ms2,\n",
    "                    self.top_n_mods_to_train,\n",
    "                    self.psm_num_per_mod_to_train_ms2\n",
    "                )\n",
    "            else:\n",
    "                tr_df = psm_df\n",
    "            if len(tr_df) > 0:\n",
    "                tr_df, frag_df = normalize_training_intensities(\n",
    "                    tr_df, matched_intensity_df\n",
    "                )\n",
    "                tr_inten_df = pd.DataFrame()\n",
    "                for frag_type in self.ms2_model.charged_frag_types:\n",
    "                    if frag_type in frag_df.columns:\n",
    "                        tr_inten_df[frag_type] = frag_df[frag_type]\n",
    "                    else:\n",
    "                        tr_inten_df[frag_type] = 0\n",
    "\n",
    "                if self.use_grid_nce_search:\n",
    "                    self.nce, self.instrument = self.ms2_model.grid_nce_search(\n",
    "                        tr_df, tr_inten_df,\n",
    "                        nce_first=self.mgr_settings['transfer'][\n",
    "                            'grid_nce_first'\n",
    "                        ],\n",
    "                        nce_last=self.mgr_settings['transfer'][\n",
    "                            'grid_nce_last'\n",
    "                        ],\n",
    "                        nce_step=self.mgr_settings['transfer'][\n",
    "                            'grid_nce_step'\n",
    "                        ],\n",
    "                        search_instruments=self.mgr_settings['transfer'][\n",
    "                            'grid_instrument'\n",
    "                        ],\n",
    "                    )\n",
    "                    tr_df['nce'] = self.nce\n",
    "                    tr_df['instrument'] = self.instrument\n",
    "                else:\n",
    "                    self.set_default_nce_instrument(tr_df)\n",
    "\n",
    "                self.ms2_model.train(tr_df, \n",
    "                    fragment_intensity_df=tr_inten_df,\n",
    "                    batch_size=self.batch_size_to_train_ms2,\n",
    "                    epoch=self.epoch_to_train_ms2,\n",
    "                    warmup_epoch=self.warmup_epoch_to_train_ms2,\n",
    "                    lr=self.lr_to_train_ms2,\n",
    "                    verbose=self.train_verbose,\n",
    "                )\n",
    "\n",
    "    def predict_ms2(self, precursor_df:pd.DataFrame, \n",
    "        *, \n",
    "        batch_size:int=model_mgr_settings[\n",
    "            'predict'\n",
    "        ]['batch_size_ms2'],\n",
    "        reference_frag_df:pd.DataFrame = None,\n",
    "    )->pd.DataFrame:\n",
    "        \"\"\"Predict MS2 for the given precursor_df\n",
    "\n",
    "        Args:\n",
    "            precursor_df (pd.DataFrame): precursor dataframe for MS2 prediction.\n",
    "            batch_size (int, optional): Batch size for prediction. \n",
    "              Defaults to mgr_settings[ 'predict' ]['batch_size_ms2'].\n",
    "            reference_frag_df (pd.DataFrame, optional): \n",
    "              If precursor_df has 'frag_start_idx' pointing to reference_frag_df. \n",
    "              Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: predicted fragment intensity dataframe. \n",
    "              If there are no such two columns in precursor_df, \n",
    "              it will insert 'frag_start_idx' and `frag_end_idx` in \n",
    "              precursor_df pointing to this predicted fragment dataframe.\n",
    "        \"\"\"\n",
    "        self.set_default_nce_instrument(precursor_df)\n",
    "        if self.verbose:\n",
    "            logging.info('Predicting MS2 ...')\n",
    "        return self.ms2_model.predict(precursor_df, \n",
    "            batch_size=batch_size,\n",
    "            reference_frag_df=reference_frag_df,\n",
    "            verbose=self.verbose\n",
    "        )\n",
    "\n",
    "    def predict_rt(self, precursor_df:pd.DataFrame,\n",
    "        *, \n",
    "        batch_size:int=model_mgr_settings[\n",
    "            'predict'\n",
    "        ]['batch_size_rt_ccs']\n",
    "    )->pd.DataFrame:\n",
    "        \"\"\" Predict RT ('rt_pred') inplace into `precursor_df`.\n",
    "\n",
    "        Args:\n",
    "            precursor_df (pd.DataFrame): precursor_df for RT prediction\n",
    "            batch_size (int, optional): Batch size for prediction. \n",
    "              Defaults to mgr_settings[ 'predict' ]['batch_size_rt_ccs']. \n",
    "              mgr_settings=peptdeep.settings.global_settings['model_mgr'].\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: df with 'rt_pred' and 'rt_norm_pred' columns.\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            logging.info(\"Predicting RT ...\")\n",
    "        df = self.rt_model.predict(precursor_df, \n",
    "            batch_size=batch_size, verbose=self.verbose\n",
    "        )\n",
    "        df['rt_norm_pred'] = df.rt_pred\n",
    "        return df\n",
    "\n",
    "    def predict_mobility(self, precursor_df:pd.DataFrame,\n",
    "        *, \n",
    "        batch_size:int=model_mgr_settings[\n",
    "            'predict'\n",
    "        ]['batch_size_rt_ccs']\n",
    "    )->pd.DataFrame:\n",
    "        \"\"\" Predict mobility ('ccs_pred' and `mobility_pred`) inplace into `precursor_df`.\n",
    "\n",
    "        Args:\n",
    "            precursor_df (pd.DataFrame): precursor_df for CCS/mobility prediction\n",
    "            batch_size (int, optional): Batch size for prediction. \n",
    "              Defaults to mgr_settings[ 'predict' ]['batch_size_rt_ccs']. \n",
    "              mgr_settings=peptdeep.settings.global_settings['model_mgr'].\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: df with 'ccs_pred' and 'mobility_pred' columns.\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            logging.info(\"Predicting mobility ...\")\n",
    "        precursor_df = self.ccs_model.predict(precursor_df,\n",
    "            batch_size=batch_size, verbose=self.verbose\n",
    "        )\n",
    "        return self.ccs_model.ccs_to_mobility_pred(\n",
    "            precursor_df\n",
    "        )\n",
    "\n",
    "    def _predict_all_for_mp(self, arg_dict):\n",
    "        \"\"\"Internal function, for multiprocessing\"\"\"\n",
    "        return self.predict_all(\n",
    "            multiprocessing=False, **arg_dict\n",
    "        )\n",
    "\n",
    "    def predict_all(self, precursor_df:pd.DataFrame,\n",
    "        *, \n",
    "        predict_items:list = [\n",
    "            'rt' ,'mobility' ,'ms2'\n",
    "        ], \n",
    "        frag_types:list =  None,\n",
    "        multiprocessing:bool = model_mgr_settings['predict']['multiprocessing'],\n",
    "        min_required_precursor_num_for_mp:int = 3000,\n",
    "        process_num:int = global_settings['thread_num'],\n",
    "        mp_batch_size:int = 100000,\n",
    "    )->Dict[str, pd.DataFrame]:\n",
    "        \"\"\" predict all items defined by `predict_items`, \n",
    "        which may include rt, mobility, fragment_mz \n",
    "        and fragment_intensity.\n",
    "\n",
    "        Args:\n",
    "            precursor_df (pd.DataFrame): precursor dataframe contains \n",
    "              `sequence`, `mods`, `mod_sites`, `charge` ... columns. \n",
    "            predict_items (list, optional): items ('rt', 'mobility', \n",
    "              'ms2') to predict.\n",
    "              Defaults to ['rt' ,'mobility' ,'ms2'].\n",
    "            frag_types (list, optional): fragment types to predict. If it is None,\n",
    "            it then depends on `self.ms2_model.charged_frag_types` and \n",
    "            `self.ms2_model.model._mask_modloss`.\n",
    "              Defaults to None.\n",
    "            multiprocessing (bool, optional): if use multiprocessing.\n",
    "              Defaults to True.\n",
    "            process_num (int, optional): Defaults to global_settings['thread_num']\n",
    "            min_required_precursor_num_for_mp (int, optional): It will not use \n",
    "              multiprocessing when the number of precursors in precursor_df \n",
    "              is lower than this value. Defaults to 3000.\n",
    "            mp_batch_size (int, optional): Splitting data into batches \n",
    "                for multiprocessing. Defaults to 100000.\n",
    "              \n",
    "        Returns:\n",
    "            Dict[str, pd.DataFrame]: {'precursor_df': precursor_df}\n",
    "              if 'ms2' in predict_items, it also contains:\n",
    "              {\n",
    "                  'fragment_mz_df': fragment_mz_df,\n",
    "                  'fragment_intensity_df': fragment_intensity_df\n",
    "              }\n",
    "        \"\"\"\n",
    "        def refine_df(df):\n",
    "            if 'ms2' in predict_items:\n",
    "                refine_precursor_df(df)\n",
    "            else:\n",
    "                refine_precursor_df(df, drop_frag_idx=False)\n",
    "\n",
    "        if frag_types is None:\n",
    "            if self.ms2_model.model._mask_modloss:\n",
    "                frag_types = [\n",
    "                    frag for frag in self.ms2_model.charged_frag_types\n",
    "                    if 'modloss' not in frag\n",
    "                ]\n",
    "            else:\n",
    "                frag_types = self.ms2_model.charged_frag_types\n",
    "\n",
    "        if 'precursor_mz' not in precursor_df.columns:\n",
    "            update_precursor_mz(precursor_df)\n",
    "\n",
    "        if (\n",
    "            self.ms2_model.device_type!='cpu' or not multiprocessing\n",
    "            or len(precursor_df) < min_required_precursor_num_for_mp\n",
    "        ):\n",
    "            refine_df(precursor_df)\n",
    "            if 'rt' in predict_items:\n",
    "                self.predict_rt(precursor_df)\n",
    "            if 'mobility' in predict_items:\n",
    "                self.predict_mobility(precursor_df)\n",
    "            if 'ms2' in predict_items:\n",
    "                fragment_mz_df = create_fragment_mz_dataframe(\n",
    "                    precursor_df, frag_types\n",
    "                )\n",
    "\n",
    "                precursor_df.drop(\n",
    "                    columns=['frag_start_idx'], inplace=True\n",
    "                )\n",
    "                \n",
    "                fragment_intensity_df = self.predict_ms2(\n",
    "                    precursor_df\n",
    "                )\n",
    "\n",
    "                fragment_intensity_df.drop(\n",
    "                    columns=[\n",
    "                        col for col in fragment_intensity_df.columns\n",
    "                        if col not in frag_types\n",
    "                    ], inplace=True\n",
    "                )\n",
    "\n",
    "                clear_error_modloss_intensities(\n",
    "                    fragment_mz_df, fragment_intensity_df\n",
    "                )\n",
    "\n",
    "                return {\n",
    "                    'precursor_df': precursor_df, \n",
    "                    'fragment_mz_df': fragment_mz_df,\n",
    "                    'fragment_intensity_df': fragment_intensity_df, \n",
    "                }\n",
    "            else:\n",
    "                return {'precursor_df': precursor_df}\n",
    "        else:\n",
    "            logging.info(\"Using multiprocessing ...\")\n",
    "            self.ms2_model.model.share_memory()\n",
    "            self.rt_model.model.share_memory()\n",
    "            self.ccs_model.model.share_memory()\n",
    "\n",
    "            df_groupby = precursor_df.groupby('nAA')\n",
    "\n",
    "            def get_batch_num_mp(df_groupby):\n",
    "                batch_num = 0\n",
    "                for group_len in df_groupby.size().values:\n",
    "                    for i in range(0, group_len, mp_batch_size):\n",
    "                        batch_num += 1\n",
    "                return batch_num\n",
    "\n",
    "            def mp_param_generator(df_groupby):\n",
    "                for nAA, df in df_groupby:\n",
    "                    for i in range(0, len(df), mp_batch_size):\n",
    "                        yield {\n",
    "                            'precursor_df': df.iloc[i:i+mp_batch_size,:],\n",
    "                            'predict_items': predict_items,\n",
    "                            'frag_types': frag_types,\n",
    "                        }\n",
    "\n",
    "            precursor_df_list = []\n",
    "            if 'ms2' in predict_items:\n",
    "                fragment_mz_df_list = []\n",
    "                fragment_intensity_df_list = []\n",
    "            else:\n",
    "                fragment_mz_df_list = None\n",
    "\n",
    "            if self.verbose:\n",
    "                logging.info(\n",
    "                    f'Predicting {\",\".join(predict_items)} ...'\n",
    "                )\n",
    "            verbose_bak = self.verbose\n",
    "            self.verbose = False\n",
    "\n",
    "            with mp.Pool(process_num) as p:\n",
    "                for ret_dict in process_bar(\n",
    "                    p.imap_unordered(\n",
    "                        self._predict_all_for_mp, \n",
    "                        mp_param_generator(df_groupby)\n",
    "                    ), \n",
    "                    get_batch_num_mp(df_groupby)\n",
    "                ):\n",
    "                    precursor_df_list.append(ret_dict['precursor_df'])\n",
    "                    if fragment_mz_df_list is not None:\n",
    "                        fragment_mz_df_list.append(\n",
    "                            ret_dict['fragment_mz_df']\n",
    "                        )\n",
    "                        fragment_intensity_df_list.append(\n",
    "                            ret_dict['fragment_intensity_df']\n",
    "                        )\n",
    "            self.verbose = verbose_bak\n",
    "\n",
    "            if fragment_mz_df_list is not None:\n",
    "                (\n",
    "                    precursor_df, fragment_mz_df, fragment_intensity_df\n",
    "                ) = concat_precursor_fragment_dataframes(\n",
    "                    precursor_df_list,\n",
    "                    fragment_mz_df_list,\n",
    "                    fragment_intensity_df_list,\n",
    "                )\n",
    "                \n",
    "                return {\n",
    "                    'precursor_df': precursor_df, \n",
    "                    'fragment_mz_df': fragment_mz_df,\n",
    "                    'fragment_intensity_df': fragment_intensity_df, \n",
    "                }\n",
    "            else:\n",
    "                precursor_df = pd.concat(precursor_df_list)\n",
    "                precursor_df.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "                return {'precursor_df': precursor_df} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "assert os.path.isfile(model_zip)\n",
    "with ZipFile(model_zip) as _zip:\n",
    "    with _zip.open('generic/ms2.pth'):\n",
    "        pass\n",
    "    with _zip.open('generic/rt.pth'):\n",
    "        pass\n",
    "    with _zip.open('generic/ccs.pth'):\n",
    "        pass\n",
    "    with _zip.open('digly/rt_digly.pth'):\n",
    "        pass\n",
    "    with _zip.open('phospho/rt_phos.pth'):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "matched_df = pd.read_csv(\n",
    "    StringIO(',b_z1,b_z2,y_z1,y_z2,b_modloss_z1,b_modloss_z2,y_modloss_z1,y_modloss_z2\\r\\n'\n",
    "        '0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\\r\\n1,0.13171915994341352,0.0,0.0,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '2,0.09560456716002332,0.0,0.0,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '3,0.032392355556351476,0.0,0.0,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '4,0.06267661211925589,0.0,0.0,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '5,0.10733421416437268,0.0,0.0,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '6,0.07955175724673087,0.0,0.0,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '7,0.08283861204882843,0.0,0.03294760940125559,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '8,0.0914959582993716,0.0,0.09471333271745186,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '9,0.10283525167783934,0.0,0.29624251030302834,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '10,0.02220051360812495,0.0272619351931404,0.8077539764174795,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '11,0.0,0.02411148245999131,0.851474013001872,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '12,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0\\r\\n13,0.0,0.0,0.22244818653184315,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '14,0.0,0.0,0.21824010319946407,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '15,0.0,0.0,0.16690493688692923,0.0,0.0,0.0,0.0,0.0\\r\\n'),\n",
    "    index_col=0\n",
    ")\n",
    "\n",
    "model_mgr = ModelManager(mask_modloss=True)\n",
    "model_mgr.verbose=False\n",
    "def pred_one(seq, mods, mod_sites, charge):\n",
    "    df = pd.DataFrame()\n",
    "    df[\"sequence\"] = [seq]\n",
    "    df[\"mods\"] = [mods]\n",
    "    df[\"mod_sites\"] = [mod_sites]\n",
    "    df[\"charge\"] = charge\n",
    "    df[\"nce\"] = 35\n",
    "    df[\"instrument\"] = \"Lumos\"\n",
    "    predict_dict = model_mgr.predict_all(\n",
    "        df, predict_items=['mobility','rt','ms2'],\n",
    "        multiprocessing=False\n",
    "    )\n",
    "    return predict_dict['fragment_intensity_df']\n",
    "\n",
    "pred_df = pred_one('ANEKTESSSAQQVAVSR', '', '', 3)\n",
    "\n",
    "def get_pcc(matched_df, pred_df):\n",
    "    matched_df = matched_df[pred_df.columns.values]\n",
    "    return torch.nn.functional.cosine_similarity(\n",
    "        torch.tensor((pred_df.values   -pred_df.values.mean()).reshape(-1)), \n",
    "        torch.tensor((matched_df.values-matched_df.values.mean()).reshape(-1)), \n",
    "        dim=0\n",
    "    )\n",
    "assert get_pcc(matched_df, pred_df) > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>rt_pred</th>\n",
       "      <th>rt_norm_pred</th>\n",
       "      <th>irt_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.184235</td>\n",
       "      <td>0.184235</td>\n",
       "      <td>-26.123537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.250092</td>\n",
       "      <td>0.250092</td>\n",
       "      <td>4.238100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.266133</td>\n",
       "      <td>0.266133</td>\n",
       "      <td>11.633120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.290495</td>\n",
       "      <td>0.290495</td>\n",
       "      <td>22.864811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.303847</td>\n",
       "      <td>0.303847</td>\n",
       "      <td>29.020259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.316514</td>\n",
       "      <td>0.316514</td>\n",
       "      <td>34.860122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.324423</td>\n",
       "      <td>0.324423</td>\n",
       "      <td>38.506308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.345197</td>\n",
       "      <td>0.345197</td>\n",
       "      <td>48.083890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.394248</td>\n",
       "      <td>0.394248</td>\n",
       "      <td>70.697474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.434775</td>\n",
       "      <td>0.434775</td>\n",
       "      <td>89.381150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.459583</td>\n",
       "      <td>0.459583</td>\n",
       "      <td>100.818303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA   rt_pred  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9  0.184235   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14  0.250092   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13  0.266133   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10  0.290495   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12  0.303847   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12  0.316514   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13  0.324423   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13  0.345197   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12  0.394248   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12  0.434775   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14  0.459583   \n",
       "\n",
       "    rt_norm_pred    irt_pred  \n",
       "0       0.184235  -26.123537  \n",
       "1       0.250092    4.238100  \n",
       "2       0.266133   11.633120  \n",
       "3       0.290495   22.864811  \n",
       "4       0.303847   29.020259  \n",
       "5       0.316514   34.860122  \n",
       "6       0.324423   38.506308  \n",
       "7       0.345197   48.083890  \n",
       "8       0.394248   70.697474  \n",
       "9       0.434775   89.381150  \n",
       "10      0.459583  100.818303  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_mgr = ModelManager(mask_modloss=False)\n",
    "model_mgr.load_installed_models('phos')\n",
    "model_mgr.predict_rt(IRT_PEPTIDE_DF)\n",
    "model_mgr.rt_model.add_irt_column_to_precursor_df(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "model_mgr.verbose=False\n",
    "def pred_one(seq, mods, mod_sites, charge):\n",
    "    df = pd.DataFrame()\n",
    "    df[\"sequence\"] = [seq]\n",
    "    df[\"mods\"] = [mods]\n",
    "    df[\"mod_sites\"] = [mod_sites]\n",
    "    df[\"charge\"] = charge\n",
    "    df[\"nce\"] = 30\n",
    "    df[\"instrument\"] = \"Lumos\"\n",
    "    predict_dict = model_mgr.predict_all(\n",
    "        df, predict_items=['mobility','rt','ms2'],\n",
    "        multiprocessing=False\n",
    "    )\n",
    "    return predict_dict['fragment_intensity_df']\n",
    "\n",
    "pred_df = pred_one('ANEKTESSSAQQVAVSR', 'Phospho@S', '9',2)\n",
    "assert (pred_df.y_modloss_z1.values>0.5).any()\n",
    "pred_df = pred_one('ANEKTESSTAQQVAVSR', 'Phospho@T', '9',2)\n",
    "assert (pred_df.y_modloss_z1.values>0.5).any()\n",
    "pred_df = pred_one('ANEKTESSSAQQVAVSR', 'Phospho@S', '16',2)\n",
    "assert (pred_df.y_modloss_z1.values>0.5).any()\n",
    "pred_df = pred_one('ANEKTESSYAQQVAVSR', 'Phospho@Y', '9',2)\n",
    "assert (pred_df.y_modloss_z1.values<=0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "IRT_PEPTIDE_DF['rt_norm'] = IRT_PEPTIDE_DF['irt']\n",
    "IRT_PEPTIDE_DF['ccs'] = IRT_PEPTIDE_DF['irt']\n",
    "model_mgr.epoch_to_train_rt_ccs = 1\n",
    "model_mgr.train_rt_model(IRT_PEPTIDE_DF)\n",
    "model_mgr.train_ccs_model(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
