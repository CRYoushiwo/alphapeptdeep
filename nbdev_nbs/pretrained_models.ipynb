{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp pretrained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import peptdeep.pretrained_models\n",
    "__file__ = peptdeep.pretrained_models.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`peptdeep.pretrained_models` handles the pretrained models, including downloading, installing, and loading the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Downloading and installing the models\n",
    "For continuous model deployment, we uploaded several pretrained models (compressed as a ZIP file) onto a net disk. peptdeep will automatically download the ZIP file as `sandbox/installed_models/pretrained_models.zip` when importing peptdeep.pretrained_models. The models will be downloaded only once, if we would like to update them to the latest models, we can call `download_models(overwrite=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "from tarfile import TarFile\n",
    "from typing import Tuple\n",
    "import torch\n",
    "import urllib\n",
    "import socket\n",
    "import logging\n",
    "import shutil\n",
    "from pickle import UnpicklingError\n",
    "\n",
    "from peptdeep.settings import global_settings\n",
    "\n",
    "sandbox_dir = os.path.join(\n",
    "    os.path.dirname(\n",
    "        os.path.abspath(__file__)\n",
    "    ),\n",
    "    \"installed_models\"\n",
    ")\n",
    "\n",
    "if not os.path.exists(sandbox_dir):\n",
    "    os.makedirs(sandbox_dir)\n",
    "\n",
    "model_name = global_settings['local_model_zip_name']\n",
    "model_url = global_settings['model_url']\n",
    "url_zip_name = global_settings['model_url_zip_name']\n",
    "\n",
    "model_zip = os.path.join(\n",
    "    sandbox_dir, model_name\n",
    ")\n",
    "\n",
    "def is_model_zip(downloaded_zip):\n",
    "    with ZipFile(downloaded_zip) as zip:\n",
    "        return any(x=='regular/ms2.pth' for x in zip.namelist())\n",
    "\n",
    "def download_models(\n",
    "    url:str=model_url, overwrite=True\n",
    "):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        url (str, optional): remote or local path. \n",
    "          Defaults to peptdeep.pretrained_models.model_url.\n",
    "        overwrite (bool, optional): overwirte old model files. \n",
    "          Defaults to True.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If remote url is not accessible.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(url):\n",
    "        downloaded_zip = os.path.join(\n",
    "            sandbox_dir,f'{url_zip_name}.zip'\n",
    "        )\n",
    "        if os.path.exists(model_zip):\n",
    "            if overwrite:\n",
    "                os.remove(model_zip)\n",
    "            else:\n",
    "                return\n",
    "        \n",
    "        logging.info(f'Downloading {model_name} ...')\n",
    "        try:\n",
    "            import ssl\n",
    "            context = ssl._create_unverified_context()\n",
    "            requests = urllib.request.urlopen(url, context=context, timeout=10)\n",
    "            with open(downloaded_zip, 'wb') as f:\n",
    "                f.write(requests.read())\n",
    "        except (\n",
    "            socket.timeout, \n",
    "            urllib.error.URLError, \n",
    "            urllib.error.HTTPError\n",
    "        ) as e:\n",
    "            raise FileNotFoundError(\n",
    "                'Downloading model failed! Please download the '\n",
    "                f'zip or tar file by yourself from \"{url}\",'\n",
    "                ' and use \\n'\n",
    "                f'\"peptdeep --install-model /path/to/{url_zip_name}.tar (or .zip)\"\\n'\n",
    "                ' to install the models'\n",
    "            )\n",
    "    else:\n",
    "        downloaded_zip = url\n",
    "    install_models(downloaded_zip, overwrite=overwrite)\n",
    "    os.remove(downloaded_zip)\n",
    "\n",
    "def install_models(downloaded_zip:str, overwrite=True):\n",
    "    \"\"\" Install the model zip file. Note that if the `downloaded_zip` \n",
    "    is downloaded using download_models(), it is a zip file; if it is \n",
    "    downloaded using a browser, it will be a tar file.\n",
    "\n",
    "    Args:\n",
    "        downloaded_zip (str): path to the downloaded file\n",
    "        overwrite (bool, optional): Overwrite the existing model. \n",
    "          Defaults to True.\n",
    "    \"\"\"\n",
    "    if os.path.exists(model_zip):\n",
    "        if overwrite:\n",
    "            os.remove(model_zip)\n",
    "        else:\n",
    "            return\n",
    "    if is_model_zip(downloaded_zip):\n",
    "        shutil.copy(\n",
    "            downloaded_zip, model_zip\n",
    "        )\n",
    "        return\n",
    "    _zip = ZipFile(downloaded_zip)\n",
    "    try:\n",
    "        _zip.extract(\n",
    "            f'{url_zip_name}/{model_name}', \n",
    "            sandbox_dir\n",
    "        )\n",
    "        shutil.move(\n",
    "            os.path.join(sandbox_dir, f'{url_zip_name}/{model_name}'),\n",
    "            os.path.join(sandbox_dir, model_name)\n",
    "        )\n",
    "        os.rmdir(os.path.join(sandbox_dir, url_zip_name))\n",
    "    except KeyError:\n",
    "        tar = TarFile(downloaded_zip)\n",
    "        with open(os.path.join(sandbox_dir, model_name), 'wb') as f:\n",
    "            f.write(tar.extractfile(\n",
    "                f'{url_zip_name}/{model_name}'\n",
    "            ).read())\n",
    "        tar.close()\n",
    "    _zip.close()\n",
    "    logging.info(f'Installed {model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "if not os.path.exists(model_zip):\n",
    "    download_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert is_model_zip(model_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the models\n",
    "peptdeep provides a convenient APIs to load models from ZIP files. \n",
    "\n",
    "`load_models()` will load the regular models for unmodified peptides, `load_phos_models()` will load the phospho models. Note that CCS/mobility prediction models are the same for regular and phospho models because this model was trained on both regular and phospho peptides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from peptdeep.model.ms2 import (\n",
    "    pDeepModel, normalize_training_intensities\n",
    ")\n",
    "from peptdeep.model.rt import AlphaRTModel\n",
    "from peptdeep.model.ccs import AlphaCCSModel\n",
    "from peptdeep.utils import uniform_sampling\n",
    "\n",
    "from peptdeep.settings import global_settings\n",
    "mgr_settings = global_settings['model_mgr']\n",
    "\n",
    "def count_mods(psm_df)->pd.DataFrame:\n",
    "    mods = psm_df[\n",
    "        psm_df.mods.str.len()>0\n",
    "    ].mods.apply(lambda x: x.split(';'))\n",
    "    mod_dict = {}\n",
    "    mod_dict['mutation'] = {}\n",
    "    mod_dict['mutation']['spec_count'] = 0\n",
    "    for one_mods in mods.values:\n",
    "        for mod in set(one_mods):\n",
    "            items = mod.split('->')\n",
    "            if (\n",
    "                len(items)==2 \n",
    "                and len(items[0])==3 \n",
    "                and len(items[1])==5\n",
    "            ):\n",
    "                mod_dict['mutation']['spec_count'] += 1\n",
    "            elif mod not in mod_dict:\n",
    "                mod_dict[mod] = {}\n",
    "                mod_dict[mod]['spec_count'] = 1\n",
    "            else:\n",
    "                mod_dict[mod]['spec_count'] += 1\n",
    "    return pd.DataFrame().from_dict(\n",
    "            mod_dict, orient='index'\n",
    "        ).reset_index(drop=False).rename(\n",
    "            columns={'index':'mod'}\n",
    "        ).sort_values(\n",
    "            'spec_count',ascending=False\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "def psm_sampling_with_important_mods(\n",
    "    psm_df, n_sample, \n",
    "    top_n_mods = 10,\n",
    "    n_sample_each_mod = 0, \n",
    "    uniform_sampling_column = None,\n",
    "    random_state=1337,\n",
    "):\n",
    "    psm_df_list = []\n",
    "    if uniform_sampling_column is None:\n",
    "        def _sample(psm_df, n):\n",
    "            if n < len(psm_df):\n",
    "                return psm_df.sample(\n",
    "                    n, replace=False,\n",
    "                    random_state=random_state\n",
    "                ).copy()\n",
    "            else:\n",
    "                return psm_df.copy()\n",
    "    else:\n",
    "        def _sample(psm_df, n):\n",
    "            return uniform_sampling(\n",
    "                psm_df, target=uniform_sampling_column,\n",
    "                n_train = n, random_state=random_state\n",
    "            )\n",
    "\n",
    "    psm_df_list.append(_sample(psm_df, n_sample))\n",
    "    if n_sample_each_mod > 0:\n",
    "        mod_df = count_mods(psm_df)\n",
    "        mod_df = mod_df[mod_df['mod']!='mutation']\n",
    "\n",
    "        if len(mod_df) > top_n_mods:\n",
    "            mod_df = mod_df.iloc[:top_n_mods,:]\n",
    "        for mod in mod_df['mod'].values:\n",
    "            psm_df_list.append(\n",
    "                _sample(\n",
    "                    psm_df[psm_df.mods.str.contains(mod, regex=False)],\n",
    "                    n_sample_each_mod,\n",
    "                )\n",
    "            )\n",
    "    if len(psm_df_list) > 0:\n",
    "        return pd.concat(psm_df_list, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_phos_models(mask_modloss=True):\n",
    "    ms2_model = pDeepModel(mask_modloss=mask_modloss)\n",
    "    ms2_model.load(model_zip, model_path_in_zip='phospho/ms2_phos.pth')\n",
    "    rt_model = AlphaRTModel()\n",
    "    rt_model.load(model_zip, model_path_in_zip='phospho/rt_phos.pth')\n",
    "    ccs_model = AlphaCCSModel()\n",
    "    ccs_model.load(model_zip, model_path_in_zip='regular/ccs.pth')\n",
    "    return ms2_model, rt_model, ccs_model\n",
    "\n",
    "def load_models(mask_modloss=True):\n",
    "    ms2_model = pDeepModel(mask_modloss=mask_modloss)\n",
    "    ms2_model.load(model_zip, model_path_in_zip='regular/ms2.pth')\n",
    "    rt_model = AlphaRTModel()\n",
    "    rt_model.load(model_zip, model_path_in_zip='regular/rt.pth')\n",
    "    ccs_model = AlphaCCSModel()\n",
    "    ccs_model.load(model_zip, model_path_in_zip='regular/ccs.pth')\n",
    "    return ms2_model, rt_model, ccs_model\n",
    "\n",
    "def load_models_by_model_type_in_zip(model_type_in_zip:str, mask_modloss=True):\n",
    "    ms2_model = pDeepModel(mask_modloss=mask_modloss)\n",
    "    ms2_model.load(model_zip, model_path_in_zip=f'{model_type_in_zip}/ms2.pth')\n",
    "    rt_model = AlphaRTModel()\n",
    "    rt_model.load(model_zip, model_path_in_zip=f'{model_type_in_zip}/rt.pth')\n",
    "    ccs_model = AlphaCCSModel()\n",
    "    ccs_model.load(model_zip, model_path_in_zip=f'{model_type_in_zip}/ccs.pth')\n",
    "    return ms2_model, rt_model, ccs_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using `ModelManager`\n",
    "\n",
    "For users, `ModelManager` class is the only thing we need to manage models (loading, transfer learning, etc). According to different arguments, `ModelManager::load_installed_models()` will call `load_models()` or `load_phos_models()`. For external models, `ModelManager::load_external_models()` will load them by file path or file stream. Here is an example:\n",
    "\n",
    "```\n",
    "from zipfile import ZipFile\n",
    "\n",
    "admodel = ModelManager()\n",
    "ext_zip = 'external_models.zip' # model compressed in ZIP\n",
    "rt_model_path = '/path/to/rt.pth' # model as file path\n",
    "with ZipFile(ext_zip) as model_zip:\n",
    "    with model_zip.open('regular/ms2.pth','r') as ms2_file:\n",
    "        admodel.load_external_models(ms2_model_file=ms2_file, rt_model_file=rt_model_path)\n",
    "```\n",
    "\n",
    "Transfer learning for different models could also be done in `ModelManager` by using the given training dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from alphabase.peptide.fragment import (\n",
    "    create_fragment_mz_dataframe,\n",
    "    get_charged_frag_types,\n",
    "    concat_precursor_fragment_dataframes\n",
    ")\n",
    "from alphabase.peptide.precursor import (\n",
    "    refine_precursor_df,\n",
    "    update_precursor_mz\n",
    ")\n",
    "from alphabase.peptide.mobility import (\n",
    "    mobility_to_ccs_for_df\n",
    ")\n",
    "\n",
    "from peptdeep.settings import global_settings\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "from typing import Dict\n",
    "from peptdeep.utils import logging, process_bar\n",
    "\n",
    "def clear_error_modloss_intensities(\n",
    "    fragment_mz_df, fragment_intensity_df\n",
    "):\n",
    "    # clear error modloss intensities\n",
    "    for col in fragment_mz_df.columns.values:\n",
    "        if 'modloss' in col:\n",
    "            fragment_intensity_df.loc[\n",
    "                fragment_mz_df[col]==0,col\n",
    "            ] = 0\n",
    "\n",
    "class ModelManager(object):\n",
    "    def __init__(self, \n",
    "        mask_modloss:bool=mgr_settings['mask_modloss'],\n",
    "        device:str='gpu',\n",
    "    ):\n",
    "        \"\"\" The manager class to access MS2/RT/CCS models.\n",
    "\n",
    "        Args:\n",
    "            mask_modloss (bool, optional): If modloss ions are masked to zeros\n",
    "                in the ms2 model. `modloss` ions are mostly useful for phospho \n",
    "                MS2 prediciton model. \n",
    "                Defaults to :py:data:`global_settings`['model_mgr']['mask_modloss'].\n",
    "            device (str, optional): Device for DL models, could be 'gpu' ('cuda') or 'cpu'.\n",
    "                if device=='gpu' but no GPUs are detected, it will automatically switch to 'cpu'.\n",
    "                Defaults to 'gpu'.\n",
    "                \n",
    "        Attributes:\n",
    "            ms2_model (:py:class:`peptdeep.model.ms2.pDeepModel`): The MS2 (pDeep) \n",
    "                prediction.\n",
    "            rt_model (:py:class:`peptdeep.model.rt.AlphaRTModel`): The RT prediction model.\n",
    "            ccs_model (:py:class:`peptdeep.model.ccs.AlphaCCSModel`): The CCS prediciton model.\n",
    "            psm_num_to_tune_ms2 (int): Number of PSMs to fine-tune the MS2 model. \n",
    "                Defaults to 5000.\n",
    "            epoch_to_tune_ms2 (int): Number of epoches to fine-tune the MS2 model. \n",
    "                Defaults to global_settings['model_mgr']['fine_tune']['epoch_ms2'].\n",
    "            psm_num_to_tune_rt_ccs (int): Number of PSMs to fine-tune RT/CCS model. \n",
    "                Defaults to 3000.\n",
    "            epoch_to_tune_rt_ccs (int): Number of epoches to fine-tune RT/CCS model. \n",
    "                Defaults to global_settings['model_mgr']['fine_tune']['epoch_rt_ccs'].\n",
    "            nce (float): Default NCE value for a precursor_df without the 'nce' column.\n",
    "                Defaults to global_settings['model_mgr']['predict']['default_nce'].\n",
    "            instrument (str): Default instrument type for a precursor_df without the 'instrument' column.\n",
    "                Defaults to global_settings['model_mgr']['predict']['default_instrument'].\n",
    "            use_grid_nce_search (bool): If self.ms2_model uses \n",
    "                :py:meth:`peptdeep.model.ms2.pDeepModel.grid_nce_search` to determine optimal\n",
    "                NCE and instrument type. This will change `self.nce` and `self.instrument` values.\n",
    "                Defaults to global_settings['model_mgr']['fine_tune']['grid_nce_search'].\n",
    "        \"\"\"\n",
    "        self.ms2_model:pDeepModel = pDeepModel(mask_modloss=mask_modloss, device=device)\n",
    "        self.rt_model:AlphaRTModel = AlphaRTModel(device=device)\n",
    "        self.ccs_model:AlphaCCSModel = AlphaCCSModel(device=device)\n",
    "\n",
    "        self.load_installed_models()\n",
    "        self.load_external_models()\n",
    "\n",
    "        self.use_grid_nce_search = mgr_settings[\n",
    "            'fine_tune'\n",
    "        ]['grid_nce_search']\n",
    "\n",
    "        self.psm_num_to_tune_ms2 = 5000\n",
    "        self.psm_num_per_mod_to_tune_ms2 = 0\n",
    "        self.epoch_to_tune_ms2 = mgr_settings[\n",
    "            'fine_tune'\n",
    "        ]['epoch_ms2']\n",
    "        self.batch_size_to_tune_ms2 = 512\n",
    "\n",
    "        self.psm_num_to_tune_rt_ccs = 3000\n",
    "        self.psm_num_per_mod_to_tune_rt_ccs = 0\n",
    "        self.epoch_to_tune_rt_ccs = mgr_settings[\n",
    "            'fine_tune'\n",
    "        ]['epoch_rt_ccs']\n",
    "        self.batch_size_to_tune_rt_ccs = 1024\n",
    "\n",
    "        self.top_n_mods_to_tune = 10\n",
    "\n",
    "        self.nce = mgr_settings[\n",
    "            'predict'\n",
    "        ]['default_nce']\n",
    "        self.instrument = mgr_settings[\n",
    "            'predict'\n",
    "        ]['default_instrument']\n",
    "        self.verbose = mgr_settings[\n",
    "            'predict'\n",
    "        ]['verbose']\n",
    "\n",
    "    def set_default_nce_instrument(self, df):\n",
    "        if 'nce' not in df.columns and 'instrument' not in df.columns:\n",
    "            df['nce'] = self.nce\n",
    "            df['instrument'] = self.instrument\n",
    "        elif 'nce' not in df.columns:\n",
    "            df['nce'] = self.nce\n",
    "        elif 'instrument' not in df.columns:\n",
    "            df['instrument'] = self.instrument\n",
    "\n",
    "    def set_default_nce(self, df):\n",
    "        self.set_default_nce_instrument(df)\n",
    "\n",
    "    def load_installed_models(self, \n",
    "        model_type:str=mgr_settings['model_type']\n",
    "    ):\n",
    "        \"\"\" Load built-in MS2/CCS/RT models.\n",
    "        Args:\n",
    "            model_type (str, optional): To load the installed MS2/RT/CCS models \n",
    "                or phos MS2/RT/CCS models. It could be 'phospho', 'HLA', or 'regular'.\n",
    "                Currently, HLA and regular share the same models.\n",
    "                Defaults to `global_settings['model_mgr']['model_type']` ('regular').\n",
    "        \"\"\"\n",
    "        if model_type.lower() in [\n",
    "            'phospho','phos','phosphorylation'\n",
    "        ]:\n",
    "            self.ms2_model.load(\n",
    "                model_zip,\n",
    "                model_path_in_zip='phospho/ms2_phos.pth'\n",
    "            )\n",
    "            self.rt_model.load(\n",
    "                model_zip, \n",
    "                model_path_in_zip='phospho/rt_phos.pth'\n",
    "            )\n",
    "            self.ccs_model.load(\n",
    "                model_zip, \n",
    "                model_path_in_zip='regular/ccs.pth'\n",
    "            )\n",
    "        elif model_type.lower() in [\n",
    "            'digly','glygly','ubiquitylation', \n",
    "            'ubiquitination','ubiquitinylation'\n",
    "        ]:\n",
    "            self.ms2_model.load(\n",
    "                model_zip,\n",
    "                model_path_in_zip='digly/ms2_digly.pth'\n",
    "            )\n",
    "            self.rt_model.load(\n",
    "                model_zip, \n",
    "                model_path_in_zip='digly/rt_digly.pth'\n",
    "            )\n",
    "            self.ccs_model.load(\n",
    "                model_zip, \n",
    "                model_path_in_zip='regular/ccs.pth'\n",
    "            )\n",
    "        elif model_type.lower() in ['regular','common']:\n",
    "            self.ms2_model.load(\n",
    "                model_zip, model_path_in_zip='regular/ms2.pth'\n",
    "            )\n",
    "            self.rt_model.load(\n",
    "                model_zip, model_path_in_zip='regular/rt.pth'\n",
    "            )\n",
    "            self.ccs_model.load(\n",
    "                model_zip, model_path_in_zip='regular/ccs.pth'\n",
    "            )\n",
    "        elif model_type.lower() in [\n",
    "            'hla','unspecific','non-specific', 'nonspecific'\n",
    "        ]:\n",
    "            self.load_installed_models(model_type=\"regular\")\n",
    "        else:\n",
    "            logging.warning(\n",
    "                f\"model_type='{model_type}' is not supported, use 'regular' instead.\"\n",
    "            )\n",
    "            self.load_installed_models(model_type=\"regular\")\n",
    "\n",
    "    def load_external_models(self,\n",
    "        *,\n",
    "        ms2_model_file: Tuple[str, io.BytesIO]=mgr_settings['external_ms2_model'],\n",
    "        rt_model_file: Tuple[str, io.BytesIO]=mgr_settings['external_rt_model'],\n",
    "        ccs_model_file: Tuple[str, io.BytesIO]=mgr_settings['external_ccs_model'],\n",
    "    ):\n",
    "        \"\"\"Load external MS2/RT/CCS models.\n",
    "\n",
    "        Args:\n",
    "            ms2_model_file (Tuple[str, io.BytesIO], optional): ms2 model file or stream.\n",
    "                Do nothing if the value is ''. Defaults to global_settings['model_mgr']['external_ms2_model'].\n",
    "            rt_model_file (Tuple[str, io.BytesIO], optional): rt model file or stream.\n",
    "                Do nothing if the value is ''. Defaults to global_settings['model_mgr']['external_rt_model'].\n",
    "            ccs_model_file (Tuple[str, io.BytesIO], optional): ccs model or stream.\n",
    "                Do nothing if the value is ''. Defaults to global_settings['model_mgr']['external_ccs_model'].\n",
    "        \"\"\"\n",
    "\n",
    "        def _load_file(model, model_file):\n",
    "            try:\n",
    "                if isinstance(model_file, str):\n",
    "                    if os.path.isfile(model_file):\n",
    "                        model.load(model_file)\n",
    "                    else:\n",
    "                        return\n",
    "                model.load(model_file)\n",
    "            except UnpicklingError as e:\n",
    "                logging.info(f\"Cannot load {model_file} as {model.__class__} model, peptdeep will use the pretrained model instead.\")\n",
    "\n",
    "        _load_file(self.ms2_model, ms2_model_file)\n",
    "        _load_file(self.rt_model, rt_model_file)\n",
    "        _load_file(self.ccs_model, ccs_model_file)\n",
    "\n",
    "    def fine_tune_rt_model(self,\n",
    "        psm_df:pd.DataFrame,\n",
    "    ):\n",
    "        \"\"\" Fine-tune the RT model. The fine-tuning will be skipped \n",
    "            if `self.psm_num_to_tune_rt_ccs` is zero.\n",
    "\n",
    "        Args:\n",
    "            psm_df (pd.DataFrame): training psm_df which contains 'rt_norm' column.\n",
    "        \"\"\"\n",
    "        if self.psm_num_to_tune_rt_ccs > 0:\n",
    "            tr_df = psm_sampling_with_important_mods(\n",
    "                psm_df, self.psm_num_to_tune_rt_ccs,\n",
    "                self.top_n_mods_to_tune,\n",
    "                self.psm_num_per_mod_to_tune_rt_ccs,\n",
    "                uniform_sampling_column='rt_norm'\n",
    "            )\n",
    "            if len(tr_df) > 0:\n",
    "                self.rt_model.train_with_warmup(tr_df, \n",
    "                    batch_size=self.batch_size_to_tune_rt_ccs,\n",
    "                    epoch=self.epoch_to_tune_rt_ccs,\n",
    "                    warmup_epoch=self.epoch_to_tune_rt_ccs//2,\n",
    "                )\n",
    "\n",
    "    def fine_tune_ccs_model(self,\n",
    "        psm_df:pd.DataFrame,\n",
    "    ):\n",
    "        \"\"\" Fine-tune the CCS model. The fine-tuning will be skipped \n",
    "            if `self.psm_num_to_tune_rt_ccs` is zero.\n",
    "\n",
    "        Args:\n",
    "            psm_df (pd.DataFrame): training psm_df which contains 'ccs' column.\n",
    "        \"\"\"\n",
    "\n",
    "        if 'mobility' not in psm_df.columns:\n",
    "            return\n",
    "        if 'ccs' not in psm_df.columns:\n",
    "            psm_df['ccs'] = mobility_to_ccs_for_df(\n",
    "                psm_df, 'mobility'\n",
    "            )\n",
    "\n",
    "        if self.psm_num_to_tune_rt_ccs > 0:\n",
    "            tr_df = psm_sampling_with_important_mods(\n",
    "                psm_df, self.psm_num_to_tune_rt_ccs,\n",
    "                self.top_n_mods_to_tune,\n",
    "                self.psm_num_per_mod_to_tune_rt_ccs,\n",
    "                uniform_sampling_column='ccs'\n",
    "            )\n",
    "            if len(tr_df) > 0:\n",
    "                self.ccs_model.train_with_warmup(tr_df, \n",
    "                    batch_size=self.batch_size_to_tune_rt_ccs,\n",
    "                    epoch=self.epoch_to_tune_rt_ccs,\n",
    "                    warmup_epoch=self.epoch_to_tune_rt_ccs//2,\n",
    "                )\n",
    "\n",
    "    def fine_tune_ms2_model(self,\n",
    "        psm_df: pd.DataFrame,\n",
    "        matched_intensity_df: pd.DataFrame,\n",
    "    ):\n",
    "        \"\"\"Using matched_intensity_df to fine-tune the ms2 model. \n",
    "        1. It will sample `n=self.psm_num_to_tune_ms2` PSMs into training dataframe (`tr_df`) to for fine-tuning.\n",
    "        2. This method will also consider some important PTMs (`n=self.top_n_mods_to_tune`) into `tr_df` for fine-tuning. \n",
    "        3. If `self.use_grid_nce_search==True`, this method will call `self.ms2_model.grid_nce_search` to find the best NCE and instrument.\n",
    "\n",
    "        Args:\n",
    "            psm_df (pd.DataFrame): PSM dataframe for fine-tuning.\n",
    "            matched_intensity_df (pd.DataFrame): The matched fragment intensities for `psm_df`.\n",
    "        \"\"\"\n",
    "        if self.psm_num_to_tune_ms2 > 0:\n",
    "            tr_df = psm_sampling_with_important_mods(\n",
    "                psm_df, self.psm_num_to_tune_ms2,\n",
    "                self.top_n_mods_to_tune,\n",
    "                self.psm_num_per_mod_to_tune_ms2\n",
    "            )\n",
    "            if len(tr_df) > 0:\n",
    "                tr_df, frag_df = normalize_training_intensities(\n",
    "                    tr_df, matched_intensity_df\n",
    "                )\n",
    "                tr_inten_df = pd.DataFrame()\n",
    "                for frag_type in self.ms2_model.charged_frag_types:\n",
    "                    if frag_type in frag_df.columns:\n",
    "                        tr_inten_df[frag_type] = frag_df[frag_type]\n",
    "                    else:\n",
    "                        tr_inten_df[frag_type] = 0\n",
    "\n",
    "                if self.use_grid_nce_search:\n",
    "                    self.nce, self.instrument = self.ms2_model.grid_nce_search(\n",
    "                        tr_df, tr_inten_df,\n",
    "                        nce_first=mgr_settings['fine_tune'][\n",
    "                            'grid_nce_first'\n",
    "                        ],\n",
    "                        nce_last=mgr_settings['fine_tune'][\n",
    "                            'grid_nce_last'\n",
    "                        ],\n",
    "                        nce_step=mgr_settings['fine_tune'][\n",
    "                            'grid_nce_step'\n",
    "                        ],\n",
    "                        search_instruments=mgr_settings['fine_tune'][\n",
    "                            'grid_instrument'\n",
    "                        ],\n",
    "                    )\n",
    "                    tr_df['nce'] = self.nce\n",
    "                    tr_df['instrument'] = self.instrument\n",
    "                else:\n",
    "                    self.set_default_nce_instrument(tr_df)\n",
    "\n",
    "                self.ms2_model.train_with_warmup(tr_df, \n",
    "                    fragment_intensity_df=tr_inten_df,\n",
    "                    batch_size=self.batch_size_to_tune_ms2,\n",
    "                    epoch=self.epoch_to_tune_ms2,\n",
    "                    warmup_epoch=self.epoch_to_tune_ms2//2,\n",
    "                )\n",
    "\n",
    "    def predict_ms2(self, precursor_df:pd.DataFrame, \n",
    "        *, \n",
    "        batch_size:int=mgr_settings[\n",
    "            'predict'\n",
    "        ]['batch_size_ms2'],\n",
    "        reference_frag_df:pd.DataFrame = None,\n",
    "    )->pd.DataFrame:\n",
    "        \"\"\"Predict MS2 for the given precursor_df\n",
    "\n",
    "        Args:\n",
    "            precursor_df (pd.DataFrame): precursor dataframe for MS2 prediction.\n",
    "            batch_size (int, optional): Batch size for prediction. \n",
    "              Defaults to mgr_settings[ 'predict' ]['batch_size_ms2'].\n",
    "            reference_frag_df (pd.DataFrame, optional): \n",
    "              If precursor_df has 'frag_start_idx' pointing to reference_frag_df. \n",
    "              Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: predicted fragment intensity dataframe. \n",
    "              If there are no such two columns in precursor_df, \n",
    "              it will insert 'frag_start_idx' and `frag_end_idx` in \n",
    "              precursor_df pointing to this predicted fragment dataframe.\n",
    "        \"\"\"\n",
    "        self.set_default_nce_instrument(precursor_df)\n",
    "        if self.verbose:\n",
    "            logging.info('Predicting MS2 ...')\n",
    "        return self.ms2_model.predict(precursor_df, \n",
    "            batch_size=batch_size,\n",
    "            reference_frag_df=reference_frag_df,\n",
    "            verbose=self.verbose\n",
    "        )\n",
    "\n",
    "    def predict_rt(self, precursor_df:pd.DataFrame,\n",
    "        *, \n",
    "        batch_size:int=mgr_settings[\n",
    "            'predict'\n",
    "        ]['batch_size_rt_ccs']\n",
    "    )->pd.DataFrame:\n",
    "        \"\"\" Predict RT ('rt_pred') inplace into `precursor_df`.\n",
    "\n",
    "        Args:\n",
    "            precursor_df (pd.DataFrame): precursor_df for RT prediction\n",
    "            batch_size (int, optional): Batch size for prediction. \n",
    "              Defaults to mgr_settings[ 'predict' ]['batch_size_rt_ccs']. \n",
    "              mgr_settings=peptdeep.settings.global_settings['model_mgr'].\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: df with 'rt_pred' and 'rt_norm_pred' columns.\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            logging.info(\"Predicting RT ...\")\n",
    "        df = self.rt_model.predict(precursor_df, \n",
    "            batch_size=batch_size, verbose=self.verbose\n",
    "        )\n",
    "        df['rt_norm_pred'] = df.rt_pred\n",
    "        return df\n",
    "\n",
    "    def predict_mobility(self, precursor_df:pd.DataFrame,\n",
    "        *, \n",
    "        batch_size:int=mgr_settings[\n",
    "            'predict'\n",
    "        ]['batch_size_rt_ccs']\n",
    "    )->pd.DataFrame:\n",
    "        \"\"\" Predict mobility ('ccs_pred' and `mobility_pred`) inplace into `precursor_df`.\n",
    "\n",
    "        Args:\n",
    "            precursor_df (pd.DataFrame): precursor_df for CCS/mobility prediction\n",
    "            batch_size (int, optional): Batch size for prediction. \n",
    "              Defaults to mgr_settings[ 'predict' ]['batch_size_rt_ccs']. \n",
    "              mgr_settings=peptdeep.settings.global_settings['model_mgr'].\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: df with 'ccs_pred' and 'mobility_pred' columns.\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            logging.info(\"Predicting mobility ...\")\n",
    "        precursor_df = self.ccs_model.predict(precursor_df,\n",
    "            batch_size=batch_size, verbose=self.verbose\n",
    "        )\n",
    "        return self.ccs_model.ccs_to_mobility_pred(\n",
    "            precursor_df\n",
    "        )\n",
    "\n",
    "    def _predict_all_for_mp(self, arg_dict):\n",
    "        \"\"\"Internal function, for multiprocessing\"\"\"\n",
    "        return self.predict_all(\n",
    "            multiprocessing=False, **arg_dict\n",
    "        )\n",
    "\n",
    "    def predict_all(self, precursor_df:pd.DataFrame,\n",
    "        *, \n",
    "        predict_items:list = [\n",
    "            'rt' ,'mobility' ,'ms2'\n",
    "        ], \n",
    "        frag_types:list =  None,\n",
    "        multiprocessing:bool = mgr_settings['predict']['multiprocessing'],\n",
    "        process_num:int = global_settings['thread_num'],\n",
    "        min_required_precursor_num_for_mp:int = 3000,\n",
    "        mp_batch_size:int = 500000,\n",
    "    )->Dict[str, pd.DataFrame]:\n",
    "        \"\"\" predict all items defined by `predict_items`, \n",
    "        which may include rt, mobility, fragment_mz \n",
    "        and fragment_intensity.\n",
    "\n",
    "        Args:\n",
    "            precursor_df (pd.DataFrame): precursor dataframe contains \n",
    "              `sequence`, `mods`, `mod_sites`, `charge` ... columns. \n",
    "            predict_items (list, optional): items ('rt', 'mobility', \n",
    "              'ms2') to predict.\n",
    "              Defaults to ['rt' ,'mobility' ,'ms2'].\n",
    "            frag_types (list, optional): fragment types to predict. If it is None,\n",
    "            it then depends on `self.ms2_model.charged_frag_types` and \n",
    "            `self.ms2_model.model._mask_modloss`.\n",
    "              Defaults to None.\n",
    "            multiprocessing (bool, optional): if use multiprocessing.\n",
    "              Defaults to True.\n",
    "            process_num (int, optional): Defaults to global_settings['thread_num']\n",
    "            min_required_precursor_num_for_mp (int, optional): It will not use \n",
    "              multiprocessing when the number of precursors in precursor_df \n",
    "              is lower than this value. Defaults to 5000.\n",
    "              \n",
    "        Returns:\n",
    "            Dict[str, pd.DataFrame]: {'precursor_df': precursor_df}\n",
    "              if 'ms2' in predict_items, it also contains:\n",
    "              {\n",
    "                  'fragment_mz_df': fragment_mz_df,\n",
    "                  'fragment_intensity_df': fragment_intensity_df\n",
    "              }\n",
    "        \"\"\"\n",
    "        def refine_df(df):\n",
    "            if 'ms2' in predict_items:\n",
    "                refine_precursor_df(df)\n",
    "            else:\n",
    "                refine_precursor_df(df, drop_frag_idx=False)\n",
    "\n",
    "        if frag_types is None:\n",
    "            if self.ms2_model.model._mask_modloss:\n",
    "                frag_types = [\n",
    "                    frag for frag in self.ms2_model.charged_frag_types\n",
    "                    if 'modloss' not in frag\n",
    "                ]\n",
    "            else:\n",
    "                frag_types = self.ms2_model.charged_frag_types\n",
    "\n",
    "        if 'precursor_mz' not in precursor_df.columns:\n",
    "            update_precursor_mz(precursor_df)\n",
    "\n",
    "        if (\n",
    "            torch.cuda.is_available() or not multiprocessing\n",
    "            or len(precursor_df) < min_required_precursor_num_for_mp\n",
    "        ):\n",
    "            refine_df(precursor_df)\n",
    "            if 'rt' in predict_items:\n",
    "                self.predict_rt(precursor_df)\n",
    "            if 'mobility' in predict_items:\n",
    "                self.predict_mobility(precursor_df)\n",
    "            if 'ms2' in predict_items:\n",
    "                fragment_mz_df = create_fragment_mz_dataframe(\n",
    "                    precursor_df, frag_types\n",
    "                )\n",
    "\n",
    "                precursor_df.drop(\n",
    "                    columns=['frag_start_idx'], inplace=True\n",
    "                )\n",
    "                \n",
    "                fragment_intensity_df = self.predict_ms2(\n",
    "                    precursor_df\n",
    "                )\n",
    "\n",
    "                fragment_intensity_df.drop(\n",
    "                    columns=[\n",
    "                        col for col in fragment_intensity_df.columns\n",
    "                        if col not in frag_types\n",
    "                    ], inplace=True\n",
    "                )\n",
    "\n",
    "                clear_error_modloss_intensities(\n",
    "                    fragment_mz_df, fragment_intensity_df\n",
    "                )\n",
    "\n",
    "                return {\n",
    "                    'precursor_df': precursor_df, \n",
    "                    'fragment_mz_df': fragment_mz_df,\n",
    "                    'fragment_intensity_df': fragment_intensity_df, \n",
    "                }\n",
    "            else:\n",
    "                return {'precursor_df': precursor_df}\n",
    "        else:\n",
    "            self.ms2_model.model.share_memory()\n",
    "            self.rt_model.model.share_memory()\n",
    "            self.ccs_model.model.share_memory()\n",
    "\n",
    "            df_groupby = precursor_df.groupby('nAA')\n",
    "\n",
    "            def get_batch_num_mp(df_groupby):\n",
    "                batch_num = 0\n",
    "                for group_len in df_groupby.size().values:\n",
    "                    for i in range(0, group_len, mp_batch_size):\n",
    "                        batch_num += 1\n",
    "                return batch_num\n",
    "\n",
    "            def mp_param_generator(df_groupby):\n",
    "                for nAA, df in df_groupby:\n",
    "                    for i in range(0, len(df), mp_batch_size):\n",
    "                        yield {\n",
    "                            'precursor_df': df.iloc[i:i+mp_batch_size,:],\n",
    "                            'predict_items': predict_items,\n",
    "                            'frag_types': frag_types,\n",
    "                        }\n",
    "\n",
    "            precursor_df_list = []\n",
    "            if 'ms2' in predict_items:\n",
    "                fragment_mz_df_list = []\n",
    "                fragment_intensity_df_list = []\n",
    "            else:\n",
    "                fragment_mz_df_list = None\n",
    "\n",
    "            if self.verbose:\n",
    "                logging.info(\n",
    "                    f'Predicting {\",\".join(predict_items)} ...'\n",
    "                )\n",
    "            verbose_bak = self.verbose\n",
    "            self.verbose = False\n",
    "\n",
    "            with mp.Pool(process_num) as p:\n",
    "                for ret_dict in process_bar(\n",
    "                    p.imap_unordered(\n",
    "                        self._predict_all_for_mp, \n",
    "                        mp_param_generator(df_groupby)\n",
    "                    ), \n",
    "                    get_batch_num_mp(df_groupby)\n",
    "                ):\n",
    "                    precursor_df_list.append(ret_dict['precursor_df'])\n",
    "                    if fragment_mz_df_list is not None:\n",
    "                        fragment_mz_df_list.append(\n",
    "                            ret_dict['fragment_mz_df']\n",
    "                        )\n",
    "                        fragment_intensity_df_list.append(\n",
    "                            ret_dict['fragment_intensity_df']\n",
    "                        )\n",
    "            self.verbose = verbose_bak\n",
    "\n",
    "            if fragment_mz_df_list is not None:\n",
    "                (\n",
    "                    precursor_df, fragment_mz_df, fragment_intensity_df\n",
    "                ) = concat_precursor_fragment_dataframes(\n",
    "                    precursor_df_list,\n",
    "                    fragment_mz_df_list,\n",
    "                    fragment_intensity_df_list,\n",
    "                )\n",
    "                \n",
    "                return {\n",
    "                    'precursor_df': precursor_df, \n",
    "                    'fragment_mz_df': fragment_mz_df,\n",
    "                    'fragment_intensity_df': fragment_intensity_df, \n",
    "                }\n",
    "            else:\n",
    "                precursor_df = pd.concat(precursor_df_list)\n",
    "                precursor_df.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "                return {'precursor_df': precursor_df} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert os.path.isfile(model_zip)\n",
    "with ZipFile(model_zip) as _zip:\n",
    "    with _zip.open('regular/ms2.pth'):\n",
    "        pass\n",
    "    with _zip.open('regular/rt.pth'):\n",
    "        pass\n",
    "    with _zip.open('regular/ccs.pth'):\n",
    "        pass\n",
    "    with _zip.open('phospho/ms2_phos.pth'):\n",
    "        pass\n",
    "    with _zip.open('phospho/rt_phos.pth'):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from io import StringIO\n",
    "\n",
    "matched_df = pd.read_csv(\n",
    "    StringIO(',b_z1,b_z2,y_z1,y_z2,b_modloss_z1,b_modloss_z2,y_modloss_z1,y_modloss_z2\\r\\n'\n",
    "        '0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\\r\\n1,0.13171915994341352,0.0,0.0,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '2,0.09560456716002332,0.0,0.0,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '3,0.032392355556351476,0.0,0.0,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '4,0.06267661211925589,0.0,0.0,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '5,0.10733421416437268,0.0,0.0,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '6,0.07955175724673087,0.0,0.0,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '7,0.08283861204882843,0.0,0.03294760940125559,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '8,0.0914959582993716,0.0,0.09471333271745186,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '9,0.10283525167783934,0.0,0.29624251030302834,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '10,0.02220051360812495,0.0272619351931404,0.8077539764174795,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '11,0.0,0.02411148245999131,0.851474013001872,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '12,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0\\r\\n13,0.0,0.0,0.22244818653184315,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '14,0.0,0.0,0.21824010319946407,0.0,0.0,0.0,0.0,0.0\\r\\n'\n",
    "        '15,0.0,0.0,0.16690493688692923,0.0,0.0,0.0,0.0,0.0\\r\\n'),\n",
    "    index_col=0\n",
    ")\n",
    "\n",
    "model_mgr = ModelManager(mask_modloss=True)\n",
    "model_mgr.verbose=False\n",
    "def pred_one(seq, mods, mod_sites, charge):\n",
    "    df = pd.DataFrame()\n",
    "    df[\"sequence\"] = [seq]\n",
    "    df[\"mods\"] = [mods]\n",
    "    df[\"mod_sites\"] = [mod_sites]\n",
    "    df[\"charge\"] = charge\n",
    "    df[\"nce\"] = 35\n",
    "    df[\"instrument\"] = \"Lumos\"\n",
    "    predict_dict = model_mgr.predict_all(\n",
    "        df, predict_items=['mobility','rt','ms2'],\n",
    "        multiprocessing=False\n",
    "    )\n",
    "    return predict_dict['fragment_intensity_df']\n",
    "\n",
    "pred_df = pred_one('ANEKTESSSAQQVAVSR', '', '', 3)\n",
    "\n",
    "def get_pcc(matched_df, pred_df):\n",
    "    matched_df = matched_df[pred_df.columns.values]\n",
    "    return torch.nn.functional.cosine_similarity(\n",
    "        torch.tensor((pred_df.values   -pred_df.values.mean()).reshape(-1)), \n",
    "        torch.tensor((matched_df.values-matched_df.values.mean()).reshape(-1)), \n",
    "        dim=0\n",
    "    )\n",
    "assert get_pcc(matched_df, pred_df) > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "model_mgr = ModelManager(mask_modloss=False)\n",
    "model_mgr.load_installed_models('phos')\n",
    "model_mgr.verbose=False\n",
    "def pred_one(seq, mods, mod_sites, charge):\n",
    "    df = pd.DataFrame()\n",
    "    df[\"sequence\"] = [seq]\n",
    "    df[\"mods\"] = [mods]\n",
    "    df[\"mod_sites\"] = [mod_sites]\n",
    "    df[\"charge\"] = charge\n",
    "    df[\"nce\"] = 30\n",
    "    df[\"instrument\"] = \"Lumos\"\n",
    "    predict_dict = model_mgr.predict_all(\n",
    "        df, predict_items=['mobility','rt','ms2'],\n",
    "        multiprocessing=False\n",
    "    )\n",
    "    return predict_dict['fragment_intensity_df']\n",
    "\n",
    "pred_df = pred_one('ANEKTESSSAQQVAVSR', 'Phospho@S', '9',2)\n",
    "assert (pred_df.y_modloss_z1.values>0.5).any()\n",
    "pred_df = pred_one('ANEKTESSTAQQVAVSR', 'Phospho@T', '9',2)\n",
    "assert (pred_df.y_modloss_z1.values>0.5).any()\n",
    "pred_df = pred_one('ANEKTESSSAQQVAVSR', 'Phospho@S', '16',2)\n",
    "assert (pred_df.y_modloss_z1.values>0.5).any()\n",
    "pred_df = pred_one('ANEKTESSYAQQVAVSR', 'Phospho@Y', '9',2)\n",
    "assert (pred_df.y_modloss_z1.values<=0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
