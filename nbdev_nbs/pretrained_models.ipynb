{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp pretrained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import peptdeep.pretrained_models\n",
    "__file__ = peptdeep.pretrained_models.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`peptdeep.pretrained_models` handles the pretrained models, including downloading, installing, and loading the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Downloading and installing the models\n",
    "For continuous model deployment, we uploaded several pretrained models (compressed as a ZIP file) onto a net disk. peptdeep will automatically download the ZIP file as `sandbox/installed_models/pretrained_models.zip` when importing peptdeep.pretrained_models. The models will be downloaded only once, if we would like to update them to the latest models, we can call `download_models(overwrite=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "from tarfile import TarFile\n",
    "from typing import Tuple\n",
    "import torch\n",
    "import urllib\n",
    "import socket\n",
    "import logging\n",
    "import shutil\n",
    "\n",
    "from peptdeep.settings import global_settings\n",
    "\n",
    "sandbox_dir = os.path.join(\n",
    "    os.path.dirname(\n",
    "        os.path.abspath(__file__)\n",
    "    ),\n",
    "    \"installed_models\"\n",
    ")\n",
    "\n",
    "if not os.path.exists(sandbox_dir):\n",
    "    os.makedirs(sandbox_dir)\n",
    "\n",
    "model_name = global_settings['local_model_file_name']\n",
    "model_url = global_settings['model_url']\n",
    "url_zip_name = global_settings['model_url_zip_name']\n",
    "\n",
    "model_zip = os.path.join(\n",
    "    sandbox_dir, model_name\n",
    ")\n",
    "\n",
    "def is_model_zip(downloaded_zip):\n",
    "    with ZipFile(downloaded_zip) as zip:\n",
    "        return any(x=='regular/ms2.pth' for x in zip.namelist())\n",
    "\n",
    "def download_models(\n",
    "    url:str=model_url, overwrite=True\n",
    "):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        url (str, optional): remote or local path. \n",
    "          Defaults to peptdeep.pretrained_models.model_url.\n",
    "        overwrite (bool, optional): overwirte old model files. \n",
    "          Defaults to True.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If remote url is not accessible.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(url):\n",
    "        downloaded_zip = os.path.join(\n",
    "            sandbox_dir,f'{url_zip_name}.zip'\n",
    "        )\n",
    "        if os.path.exists(model_zip):\n",
    "            if overwrite:\n",
    "                os.remove(model_zip)\n",
    "            else:\n",
    "                return\n",
    "        \n",
    "        logging.info(f'Downloading {model_name} ...')\n",
    "        try:\n",
    "            requests = urllib.request.urlopen(url, timeout=10)\n",
    "            with open(downloaded_zip, 'wb') as f:\n",
    "                f.write(requests.read())\n",
    "        except (\n",
    "            socket.timeout, \n",
    "            urllib.error.URLError, \n",
    "            urllib.error.HTTPError\n",
    "        ) as e:\n",
    "            raise FileNotFoundError(\n",
    "                'Downloading model failed! Please download the '\n",
    "                f'zip or tar file by yourself from \"{url}\",'\n",
    "                ' and use \\n'\n",
    "                f'\"peptdeep --install-model /path/to/{url_zip_name}.tar (or .zip)\"\\n'\n",
    "                ' to install the models'\n",
    "            )\n",
    "    else:\n",
    "        downloaded_zip = url\n",
    "    install_models(downloaded_zip, overwrite=overwrite)\n",
    "    os.remove(downloaded_zip)\n",
    "\n",
    "def install_models(downloaded_zip:str, overwrite=True):\n",
    "    \"\"\" Install the model zip file. Note that if the `downloaded_zip` \n",
    "    is downloaded using download_models(), it is a zip file; if it is \n",
    "    downloaded using a browser, it will be a tar file.\n",
    "\n",
    "    Args:\n",
    "        downloaded_zip (str): path to the downloaded file\n",
    "        overwrite (bool, optional): Overwrite the existing model. \n",
    "          Defaults to True.\n",
    "    \"\"\"\n",
    "    if os.path.exists(model_zip):\n",
    "        if overwrite:\n",
    "            os.remove(model_zip)\n",
    "        else:\n",
    "            return\n",
    "    if is_model_zip(downloaded_zip):\n",
    "        shutil.copy(\n",
    "            downloaded_zip, model_zip\n",
    "        )\n",
    "        return\n",
    "    _zip = ZipFile(downloaded_zip)\n",
    "    try:\n",
    "        _zip.extract(\n",
    "            f'{url_zip_name}/{model_name}', \n",
    "            sandbox_dir\n",
    "        )\n",
    "        shutil.move(\n",
    "            os.path.join(sandbox_dir, f'{url_zip_name}/{model_name}'),\n",
    "            os.path.join(sandbox_dir, model_name)\n",
    "        )\n",
    "        os.rmdir(os.path.join(sandbox_dir, url_zip_name))\n",
    "    except KeyError:\n",
    "        tar = TarFile(downloaded_zip)\n",
    "        with open(os.path.join(sandbox_dir, model_name), 'wb') as f:\n",
    "            f.write(tar.extractfile(\n",
    "                f'{url_zip_name}/{model_name}'\n",
    "            ).read())\n",
    "        tar.close()\n",
    "    _zip.close()\n",
    "    logging.info(f'Installed {model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "if not os.path.exists(model_zip):\n",
    "    download_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert is_model_zip(model_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the models\n",
    "peptdeep provides a convenient APIs to load models from ZIP files. \n",
    "\n",
    "`load_models()` will load the regular models for unmodified peptides, `load_phos_models()` will load the phospho models. Note that CCS/mobility prediction models are the same for regular and phospho models because this model was trained on both regular and phospho peptides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from peptdeep.model.ms2 import (\n",
    "    pDeepModel, normalize_training_intensities\n",
    ")\n",
    "from peptdeep.model.rt import AlphaRTModel, uniform_sampling\n",
    "from peptdeep.model.ccs import AlphaCCSModel\n",
    "\n",
    "from peptdeep.settings import global_settings\n",
    "mgr_settings = global_settings['model_mgr']\n",
    "\n",
    "def count_mods(psm_df)->pd.DataFrame:\n",
    "    mods = psm_df[\n",
    "        psm_df.mods.str.len()>0\n",
    "    ].mods.apply(lambda x: x.split(';'))\n",
    "    mod_dict = {}\n",
    "    mod_dict['mutation'] = {}\n",
    "    mod_dict['mutation']['spec_count'] = 0\n",
    "    for one_mods in mods.values:\n",
    "        for mod in set(one_mods):\n",
    "            items = mod.split('->')\n",
    "            if (\n",
    "                len(items)==2 \n",
    "                and len(items[0])==3 \n",
    "                and len(items[1])==5\n",
    "            ):\n",
    "                mod_dict['mutation']['spec_count'] += 1\n",
    "            elif mod not in mod_dict:\n",
    "                mod_dict[mod] = {}\n",
    "                mod_dict[mod]['spec_count'] = 1\n",
    "            else:\n",
    "                mod_dict[mod]['spec_count'] += 1\n",
    "    return pd.DataFrame().from_dict(\n",
    "            mod_dict, orient='index'\n",
    "        ).reset_index(drop=False).rename(\n",
    "            columns={'index':'mod'}\n",
    "        ).sort_values(\n",
    "            'spec_count',ascending=False\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "def psm_sampling_with_important_mods(\n",
    "    psm_df, n_sample, \n",
    "    top_n_mods = 10,\n",
    "    n_sample_each_mod = 0, \n",
    "    uniform_sampling_column = None,\n",
    "    random_state=1337,\n",
    "):\n",
    "    psm_df_list = []\n",
    "    if uniform_sampling_column is None:\n",
    "        def _sample(psm_df, n):\n",
    "            if n < len(psm_df):\n",
    "                return psm_df.sample(\n",
    "                    n, replace=False,\n",
    "                    random_state=random_state\n",
    "                ).copy()\n",
    "            else:\n",
    "                return psm_df.copy()\n",
    "    else:\n",
    "        def _sample(psm_df, n):\n",
    "            return uniform_sampling(\n",
    "                psm_df, target=uniform_sampling_column,\n",
    "                n_train = n, random_state=random_state\n",
    "            )\n",
    "\n",
    "    psm_df_list.append(_sample(psm_df, n_sample))\n",
    "    if n_sample_each_mod > 0:\n",
    "        mod_df = count_mods(psm_df)\n",
    "        mod_df = mod_df[mod_df['mod']!='mutation']\n",
    "\n",
    "        if len(mod_df) > top_n_mods:\n",
    "            mod_df = mod_df.iloc[:top_n_mods,:]\n",
    "        for mod in mod_df['mod'].values:\n",
    "            psm_df_list.append(\n",
    "                _sample(\n",
    "                    psm_df[psm_df.mods.str.contains(mod, regex=False)],\n",
    "                    n_sample_each_mod,\n",
    "                )\n",
    "            )\n",
    "    if len(psm_df_list) > 0:\n",
    "        return pd.concat(psm_df_list).reset_index(drop=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_phos_models(mask_phos_modloss=False):\n",
    "    ms2_model = pDeepModel(mask_modloss=mask_phos_modloss)\n",
    "    ms2_model.load(model_zip, model_path_in_zip='phospho/ms2.pth')\n",
    "    rt_model = AlphaRTModel()\n",
    "    rt_model.load(model_zip, model_path_in_zip='phospho/rt.pth')\n",
    "    ccs_model = AlphaCCSModel()\n",
    "    ccs_model.load(model_zip, model_path_in_zip='regular/ccs.pth')\n",
    "    return ms2_model, rt_model, ccs_model\n",
    "\n",
    "def load_HLA_models():\n",
    "    ms2_model = pDeepModel(mask_modloss=True)\n",
    "    ms2_model.load(model_zip, model_path_in_zip='HLA/ms2.pth')\n",
    "    rt_model = AlphaRTModel()\n",
    "    rt_model.load(model_zip, model_path_in_zip='HLA/rt.pth')\n",
    "    ccs_model = AlphaCCSModel()\n",
    "    ccs_model.load(model_zip, model_path_in_zip='regular/ccs.pth')\n",
    "    return ms2_model, rt_model, ccs_model\n",
    "\n",
    "def load_models():\n",
    "    ms2_model = pDeepModel()\n",
    "    ms2_model.load(model_zip, model_path_in_zip='regular/ms2.pth')\n",
    "    rt_model = AlphaRTModel()\n",
    "    rt_model.load(model_zip, model_path_in_zip='regular/rt.pth')\n",
    "    ccs_model = AlphaCCSModel()\n",
    "    ccs_model.load(model_zip, model_path_in_zip='regular/ccs.pth')\n",
    "    return ms2_model, rt_model, ccs_model\n",
    "\n",
    "def load_models_by_model_type_in_zip(model_type_in_zip:str):\n",
    "    ms2_model = pDeepModel()\n",
    "    ms2_model.load(model_zip, model_path_in_zip=f'{model_type_in_zip}/ms2.pth')\n",
    "    rt_model = AlphaRTModel()\n",
    "    rt_model.load(model_zip, model_path_in_zip=f'{model_type_in_zip}/rt.pth')\n",
    "    ccs_model = AlphaCCSModel()\n",
    "    ccs_model.load(model_zip, model_path_in_zip=f'{model_type_in_zip}/ccs.pth')\n",
    "    return ms2_model, rt_model, ccs_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using `ModelManager`\n",
    "\n",
    "For users, `ModelManager` class is the only thing we need to manage models (loading, transfer learning, etc). According to different arguments, `ModelManager::load_installed_models()` will call `load_models()` or `load_phos_models()`. For external models, `ModelManager::load_external_models()` will load them by file path or file stream. Here is an example:\n",
    "\n",
    "```\n",
    "from zipfile import ZipFile\n",
    "\n",
    "admodel = ModelManager()\n",
    "ext_zip = 'external_models.zip' # model compressed in ZIP\n",
    "rt_model_path = '/path/to/rt.pth' # model as file path\n",
    "with ZipFile(ext_zip) as model_zip:\n",
    "    with model_zip.open('regular/ms2.pth','r') as ms2_file:\n",
    "        admodel.load_external_models(ms2_model_file=ms2_file, rt_model_file=rt_model_path)\n",
    "```\n",
    "\n",
    "Transfer learning for different models could also be done in `ModelManager` by using the given training dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from alphabase.peptide.fragment import (\n",
    "    create_fragment_mz_dataframe,\n",
    "    get_charged_frag_types,\n",
    "    concat_precursor_fragment_dataframes\n",
    ")\n",
    "from alphabase.peptide.precursor import (\n",
    "    refine_precursor_df,\n",
    "    update_precursor_mz\n",
    ")\n",
    "from alphabase.peptide.mobility import (\n",
    "    mobility_to_ccs_for_df\n",
    ")\n",
    "\n",
    "from peptdeep.settings import global_settings\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "from typing import Dict\n",
    "from peptdeep.utils import logging, process_bar\n",
    "\n",
    "class ModelManager(object):\n",
    "    def __init__(self):\n",
    "        self.ms2_model:pDeepModel = None\n",
    "        self.rt_model:AlphaRTModel = None\n",
    "        self.ccs_model:AlphaCCSModel = None\n",
    "\n",
    "        self.grid_nce_search = mgr_settings[\n",
    "            'fine_tune'\n",
    "        ]['grid_nce_search']\n",
    "\n",
    "        self.psm_num_to_tune_ms2 = 5000\n",
    "        self.psm_num_per_mod_to_tune_ms2 = 100\n",
    "        self.epoch_to_tune_ms2 = mgr_settings[\n",
    "            'fine_tune'\n",
    "        ]['epoch_ms2']\n",
    "        self.psm_num_to_tune_rt_ccs = 3000\n",
    "        self.psm_num_per_mod_to_tune_rt_ccs = 100\n",
    "        self.epoch_to_tune_rt_ccs = mgr_settings[\n",
    "            'fine_tune'\n",
    "        ]['epoch_rt_ccs']\n",
    "\n",
    "        self.top_n_mods_to_tune = 10\n",
    "\n",
    "        self.nce = mgr_settings[\n",
    "            'predict'\n",
    "        ]['default_nce']\n",
    "        self.instrument = mgr_settings[\n",
    "            'predict'\n",
    "        ]['default_instrument']\n",
    "        self.verbose = mgr_settings[\n",
    "            'predict'\n",
    "        ]['verbose']\n",
    "\n",
    "    def set_default_nce(self, df):\n",
    "        df['nce'] = self.nce\n",
    "        df['instrument'] = self.instrument\n",
    "\n",
    "    def load_installed_models(self, model_type='regular', mask_modloss=True):\n",
    "        \"\"\" Load built-in MS2/CCS/RT models.\n",
    "        Args:\n",
    "            model_type (str, optional): To load the installed MS2/RT/CCS models \n",
    "                or phos MS2/RT/CCS models. It could be 'phospho', 'HLA', 'regular', or \n",
    "                model_type (model sub-folder) in peptdeep_models.zip. \n",
    "                Defaults to 'regular'.\n",
    "            mask_modloss (bool, optional): If modloss ions are masked to zeros\n",
    "                in the ms2 model. `modloss` ions are mostly useful for phospho \n",
    "                MS2 prediciton model. Defaults to True.\n",
    "        \"\"\"\n",
    "        if model_type.lower() in ['phospho','phos']:\n",
    "            (\n",
    "                self.ms2_model, self.rt_model, self.ccs_model\n",
    "            ) = load_phos_models(mask_modloss)\n",
    "        elif model_type.lower() in ['regular','common']:\n",
    "            (\n",
    "                self.ms2_model, self.rt_model, self.ccs_model\n",
    "            ) = load_models()\n",
    "        elif model_type.lower() in [\n",
    "            'hla','unspecific','non-specific', 'nonspecific'\n",
    "        ]:\n",
    "            (\n",
    "                self.ms2_model, self.rt_model, self.ccs_model\n",
    "            ) = load_HLA_models()\n",
    "        else:\n",
    "            (\n",
    "                self.ms2_model, self.rt_model, self.ccs_model\n",
    "            ) = load_models_by_model_type_in_zip(model_type)\n",
    "\n",
    "    def load_external_models(self,\n",
    "        *,\n",
    "        ms2_model_file: Tuple[str, io.BytesIO]=None, \n",
    "        rt_model_file: Tuple[str, io.BytesIO]=None,\n",
    "        ccs_model_file: Tuple[str, io.BytesIO]=None,\n",
    "        mask_modloss=True\n",
    "    ):\n",
    "        \"\"\"Load external MS2/RT/CCS models \n",
    "\n",
    "        Args:\n",
    "            ms2_model_file (Tuple[str, io.BytesIO], optional): ms2 model file or stream.\n",
    "                It will load the installed model if the value is None. Defaults to None.\n",
    "            rt_model_file (Tuple[str, io.BytesIO], optional): rt model file or stream.\n",
    "                It will load the installed model if the value is None. Defaults to None.\n",
    "            ccs_model_file (Tuple[str, io.BytesIO], optional): ccs model or stream.\n",
    "                It will load the installed model if the value is None. Defaults to None.\n",
    "            mask_modloss (bool, optional): If modloss ions are masked to zeros\n",
    "                in the ms2 model. Defaults to True.\n",
    "        \"\"\"\n",
    "        self.ms2_model = pDeepModel(mask_modloss=mask_modloss)\n",
    "        self.rt_model = AlphaRTModel()\n",
    "        self.ccs_model = AlphaCCSModel()\n",
    "        \n",
    "        if ms2_model_file is not None:\n",
    "            self.ms2_model.load(ms2_model_file)\n",
    "        else:\n",
    "            self.ms2_model.load(model_zip, model_path_in_zip='regular/ms2.pth')\n",
    "        if rt_model_file is not None:\n",
    "            self.rt_model.load(rt_model_file)\n",
    "        else:\n",
    "            self.rt_model.load(model_zip, model_path_in_zip='regular/rt.pth')\n",
    "        if ccs_model_file is not None:\n",
    "            self.ccs_model.load(ccs_model_file)\n",
    "        else:\n",
    "            self.ccs_model.load(model_zip, model_path_in_zip='regular/ccs.pth')\n",
    "\n",
    "    def fine_tune_rt_model(self,\n",
    "        psm_df:pd.DataFrame,\n",
    "    ):\n",
    "        \"\"\" Fine-tune the RT model. The fine-tuning will be skipped \n",
    "            if `n_rt_ccs_tune` is zero.\n",
    "\n",
    "        Args:\n",
    "            psm_df (pd.DataFrame): training psm_df which contains 'rt_norm' column.\n",
    "        \"\"\"\n",
    "        if self.psm_num_to_tune_rt_ccs > 0:\n",
    "            tr_df = psm_sampling_with_important_mods(\n",
    "                psm_df, self.psm_num_to_tune_rt_ccs,\n",
    "                self.top_n_mods_to_tune,\n",
    "                self.psm_num_per_mod_to_tune_rt_ccs,\n",
    "                uniform_sampling_column='rt_norm'\n",
    "            )\n",
    "            if len(tr_df) > 0:\n",
    "                self.rt_model.train(tr_df, \n",
    "                    epoch=self.epoch_to_tune_rt_ccs\n",
    "                )\n",
    "\n",
    "    def fine_tune_ccs_model(self,\n",
    "        psm_df:pd.DataFrame,\n",
    "    ):\n",
    "        \"\"\" Fine-tune the CCS model. The fine-tuning will be skipped \n",
    "            if `n_rt_ccs_tune` is zero.\n",
    "\n",
    "        Args:\n",
    "            psm_df (pd.DataFrame): training psm_df which contains 'ccs' column.\n",
    "        \"\"\"\n",
    "\n",
    "        if 'mobility' not in psm_df.columns:\n",
    "            return\n",
    "        if 'ccs' not in psm_df.columns:\n",
    "            psm_df['ccs'] = mobility_to_ccs_for_df(\n",
    "                psm_df, 'mobility'\n",
    "            )\n",
    "\n",
    "        if self.psm_num_to_tune_rt_ccs > 0:\n",
    "            tr_df = psm_sampling_with_important_mods(\n",
    "                psm_df, self.psm_num_to_tune_rt_ccs,\n",
    "                self.top_n_mods_to_tune,\n",
    "                self.psm_num_per_mod_to_tune_rt_ccs,\n",
    "                uniform_sampling_column='ccs'\n",
    "            )\n",
    "            if len(tr_df) > 0:\n",
    "                self.ccs_model.train(tr_df, \n",
    "                    epoch=self.epoch_to_tune_rt_ccs\n",
    "                )\n",
    "\n",
    "    def fine_tune_ms2_model(self,\n",
    "        psm_df: pd.DataFrame,\n",
    "        matched_intensity_df: pd.DataFrame,\n",
    "    ):\n",
    "        if self.psm_num_to_tune_ms2 > 0:\n",
    "            tr_df = psm_sampling_with_important_mods(\n",
    "                psm_df, self.psm_num_to_tune_ms2,\n",
    "                self.top_n_mods_to_tune,\n",
    "                self.psm_num_per_mod_to_tune_ms2\n",
    "            )\n",
    "            if len(tr_df) > 0:\n",
    "                tr_df, frag_df = normalize_training_intensities(\n",
    "                    tr_df, matched_intensity_df\n",
    "                )\n",
    "                tr_inten_df = pd.DataFrame()\n",
    "                for frag_type in self.ms2_model.charged_frag_types:\n",
    "                    if frag_type in frag_df.columns:\n",
    "                        tr_inten_df[frag_type] = frag_df[frag_type]\n",
    "                    else:\n",
    "                        tr_inten_df[frag_type] = 0\n",
    "\n",
    "                if self.grid_nce_search:\n",
    "                    self.nce, self.instrument = self.ms2_model.grid_nce_search(\n",
    "                        tr_df, tr_inten_df,\n",
    "                        nce_first=mgr_settings['fine_tune'][\n",
    "                            'grid_nce_first'\n",
    "                        ],\n",
    "                        nce_last=mgr_settings['fine_tune'][\n",
    "                            'grid_nce_last'\n",
    "                        ],\n",
    "                        nce_step=mgr_settings['fine_tune'][\n",
    "                            'grid_nce_step'\n",
    "                        ],\n",
    "                        search_instruments=mgr_settings['fine_tune'][\n",
    "                            'grid_instrument'\n",
    "                        ],\n",
    "                    )\n",
    "                    tr_df['nce'] = self.nce\n",
    "                    tr_df['instrument'] = self.instrument\n",
    "                elif 'nce' not in tr_df.columns:\n",
    "                    self.set_default_nce(tr_df)\n",
    "\n",
    "                self.ms2_model.train(tr_df, \n",
    "                    fragment_intensity_df=tr_inten_df,\n",
    "                    epoch=self.epoch_to_tune_ms2\n",
    "                )\n",
    "\n",
    "    def predict_ms2(self, precursor_df:pd.DataFrame, \n",
    "        *, \n",
    "        batch_size=mgr_settings[\n",
    "            'predict'\n",
    "        ]['batch_size_ms2'],\n",
    "        reference_frag_df = None,\n",
    "    ):\n",
    "        if 'nce' not in precursor_df.columns:\n",
    "            self.set_default_nce(precursor_df)\n",
    "        if self.verbose:\n",
    "            logging.info('Predicting MS2 ...')\n",
    "        return self.ms2_model.predict(precursor_df, \n",
    "            batch_size=batch_size,\n",
    "            reference_frag_df=reference_frag_df,\n",
    "            verbose=self.verbose\n",
    "        )\n",
    "\n",
    "    def predict_rt(self, precursor_df:pd.DataFrame,\n",
    "        *, batch_size=mgr_settings[\n",
    "             'predict'\n",
    "           ]['batch_size_rt_ccs']\n",
    "    ):\n",
    "        if self.verbose:\n",
    "            logging.info(\"Predicting RT ...\")\n",
    "        df = self.rt_model.predict(precursor_df, \n",
    "            batch_size=batch_size, verbose=self.verbose\n",
    "        )\n",
    "        df['rt_norm_pred'] = df.rt_pred\n",
    "        return df\n",
    "\n",
    "    def predict_mobility(self, precursor_df:pd.DataFrame,\n",
    "        *, batch_size=mgr_settings[\n",
    "             'predict'\n",
    "           ]['batch_size_rt_ccs']\n",
    "    ):\n",
    "        if self.verbose:\n",
    "            logging.info(\"Predicting mobility ...\")\n",
    "        precursor_df = self.ccs_model.predict(precursor_df,\n",
    "            batch_size=batch_size, verbose=self.verbose\n",
    "        )\n",
    "        return self.ccs_model.ccs_to_mobility_pred(\n",
    "            precursor_df\n",
    "        )\n",
    "\n",
    "    def _predict_all_for_mp(self, arg_dict):\n",
    "        return self.predict_all(\n",
    "            multiprocessing=False, **arg_dict\n",
    "        )\n",
    "\n",
    "    def predict_all(self, precursor_df:pd.DataFrame,\n",
    "        *, \n",
    "        predict_items:list = [\n",
    "            'rt' #,'mobility' ,'ms2'\n",
    "        ], \n",
    "        frag_types:list = get_charged_frag_types(\n",
    "            ['b','y'],2\n",
    "        ),\n",
    "        multiprocessing:bool = True,\n",
    "        thread_num:int = global_settings['thread_num']\n",
    "    )->Dict[str, pd.DataFrame]:\n",
    "        \"\"\" predict all items defined by `predict_items`, \n",
    "        which may include rt, mobility, fragment_mz \n",
    "        and fragment_intensity.\n",
    "\n",
    "        Args:\n",
    "            precursor_df (pd.DataFrame): precursor dataframe contains \n",
    "              `sequence`, `mods`, `mod_sites`, `charge` ... columns. \n",
    "            predict_items (list, optional): items ('rt', 'mobility', \n",
    "              'ms2') to predict. \n",
    "              Defaults to [ 'rt' ].\n",
    "            frag_types (list, optional): fragment types to predict.\n",
    "              Defaults to ['b_z1','b_z2','y_z1','y_z2'].\n",
    "            multiprocessing (bool, optional): if use multiprocessing.\n",
    "              Defaults to True.\n",
    "            thread_num (int, optional): Defaults to global_settings['thread_num']\n",
    "        Returns:\n",
    "            Dict[str, pd.DataFrame]: {'precursor_df': precursor_df}\n",
    "              if 'ms2' in predict_items, it also contains:\n",
    "              {\n",
    "                  'fragment_mz_df': fragment_mz_df,\n",
    "                  'fragment_intensity_df': fragment_intensity_df\n",
    "              }\n",
    "            \n",
    "        \"\"\"\n",
    "        def refine_df(df):\n",
    "            if 'ms2' in predict_items:\n",
    "                refine_precursor_df(df)\n",
    "            else:\n",
    "                refine_precursor_df(df, drop_frag_idx=False)\n",
    "\n",
    "        if 'precursor_mz' not in precursor_df.columns:\n",
    "            update_precursor_mz(precursor_df)\n",
    "\n",
    "        if torch.cuda.is_available() or not multiprocessing:\n",
    "            refine_df(precursor_df)\n",
    "            if 'rt' in predict_items:\n",
    "                self.predict_rt(precursor_df)\n",
    "            if 'mobility' in predict_items:\n",
    "                self.predict_mobility(precursor_df)\n",
    "            if 'ms2' in predict_items:\n",
    "                fragment_intensity_df = self.predict_ms2(\n",
    "                    precursor_df\n",
    "                )\n",
    "\n",
    "                fragment_intensity_df.drop(\n",
    "                    columns=[\n",
    "                        col for col in fragment_intensity_df.columns\n",
    "                        if col not in frag_types\n",
    "                    ], inplace=True\n",
    "                )\n",
    "\n",
    "                precursor_df.drop(\n",
    "                    columns=['frag_start_idx'], inplace=True\n",
    "                )\n",
    "                fragment_mz_df = create_fragment_mz_dataframe(\n",
    "                    precursor_df, frag_types\n",
    "                )\n",
    "                fragment_mz_df.drop(\n",
    "                    columns=[\n",
    "                        col for col in fragment_mz_df.columns\n",
    "                        if col not in frag_types\n",
    "                    ], inplace=True\n",
    "                )\n",
    "\n",
    "                # clear error modloss intensities\n",
    "                for col in fragment_mz_df.columns.values:\n",
    "                    if 'modloss' in col:\n",
    "                        fragment_intensity_df.loc[\n",
    "                            fragment_mz_df[col]==0,col\n",
    "                        ] = 0\n",
    "\n",
    "                return {\n",
    "                    'precursor_df': precursor_df, \n",
    "                    'fragment_mz_df': fragment_mz_df,\n",
    "                    'fragment_intensity_df': fragment_intensity_df, \n",
    "                }\n",
    "            else:\n",
    "                return {'precursor_df': precursor_df}\n",
    "        else:\n",
    "            self.ms2_model.model.share_memory()\n",
    "            self.rt_model.model.share_memory()\n",
    "            self.ccs_model.model.share_memory()\n",
    "\n",
    "            df_groupby = precursor_df.groupby('nAA')\n",
    "\n",
    "            def param_generator(df_groupby):\n",
    "                for nAA, df in df_groupby:\n",
    "                    yield {\n",
    "                        'precursor_df': df,\n",
    "                        'predict_items': predict_items,\n",
    "                        'frag_types': frag_types,\n",
    "                    }\n",
    "\n",
    "            precursor_df_list = []\n",
    "            if 'ms2' in predict_items:\n",
    "                fragment_mz_df_list = []\n",
    "                fragment_intensity_df_list = []\n",
    "            else:\n",
    "                fragment_mz_df_list = None\n",
    "\n",
    "            if self.verbose:\n",
    "                logging.info(\n",
    "                    f'Predicting {\",\".join(predict_items)} ...'\n",
    "                )\n",
    "            verbose_bak = self.verbose\n",
    "            self.verbose = False\n",
    "\n",
    "            with mp.Pool(thread_num) as p:\n",
    "                for ret_dict in process_bar(\n",
    "                    p.imap_unordered(\n",
    "                        self._predict_all_for_mp, \n",
    "                        param_generator(df_groupby)\n",
    "                    ), df_groupby.ngroups\n",
    "                ):\n",
    "                    precursor_df_list.append(ret_dict['precursor_df'])\n",
    "                    if fragment_mz_df_list is not None:\n",
    "                        fragment_mz_df_list.append(\n",
    "                            ret_dict['fragment_mz_df']\n",
    "                        )\n",
    "                        fragment_intensity_df_list.append(\n",
    "                            ret_dict['fragment_intensity_df']\n",
    "                        )\n",
    "            self.verbose = verbose_bak\n",
    "\n",
    "            if fragment_mz_df_list is not None:\n",
    "                (\n",
    "                    precursor_df, fragment_mz_df, fragment_intensity_df\n",
    "                ) = concat_precursor_fragment_dataframes(\n",
    "                    precursor_df_list,\n",
    "                    fragment_mz_df_list,\n",
    "                    fragment_intensity_df_list,\n",
    "                )\n",
    "                \n",
    "                return {\n",
    "                    'precursor_df': precursor_df, \n",
    "                    'fragment_mz_df': fragment_mz_df,\n",
    "                    'fragment_intensity_df': fragment_intensity_df, \n",
    "                }\n",
    "            else:\n",
    "                precursor_df = pd.concat(precursor_df_list)\n",
    "                precursor_df.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "                return {'precursor_df': precursor_df} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert os.path.isfile(model_zip)\n",
    "with ZipFile(model_zip) as _zip:\n",
    "    with _zip.open('regular/ms2.pth'):\n",
    "        pass\n",
    "    with _zip.open('regular/rt.pth'):\n",
    "        pass\n",
    "    with _zip.open('regular/ccs.pth'):\n",
    "        pass\n",
    "    with _zip.open('phospho/ms2.pth'):\n",
    "        pass\n",
    "    with _zip.open('phospho/rt.pth'):\n",
    "        pass\n",
    "    with _zip.open('HLA/ms2.pth'):\n",
    "        pass\n",
    "    with _zip.open('HLA/rt.pth'):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
