{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp model.building_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "torch.set_num_threads(2)\n",
    "\n",
    "from alphadeep.settings import model_const\n",
    "from alphadeep.settings import global_settings as settings\n",
    "\n",
    "mod_feature_size = len(model_const['mod_elements'])\n",
    "max_instrument_num = model_const['max_instrument_num']\n",
    "frag_types = settings['model']['frag_types']\n",
    "max_frag_charge = settings['model']['max_frag_charge']\n",
    "num_ion_types = len(frag_types)*max_frag_charge\n",
    "aa_embedding_size = model_const['aa_embedding_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SeqCNN` or TextCNN extracts sequence features using `nn.Conv1D` with different kernel sizes (3,5,7), and then concatenates the outputs of these Conv1Ds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SeqCNN(torch.nn.Module):\n",
    "    def __init__(self, embedding_hidden):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn_short = torch.nn.Conv1d(\n",
    "            embedding_hidden, embedding_hidden,\n",
    "            kernel_size=3, padding=1\n",
    "        )\n",
    "        self.cnn_medium = torch.nn.Conv1d(\n",
    "            embedding_hidden, embedding_hidden,\n",
    "            kernel_size=5, padding=2\n",
    "        )\n",
    "        self.cnn_long = torch.nn.Conv1d(\n",
    "            embedding_hidden, embedding_hidden,\n",
    "            kernel_size=7, padding=3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x1 = self.cnn_short(x)\n",
    "        x2 = self.cnn_medium(x)\n",
    "        x3 = self.cnn_long(x)\n",
    "        return torch.cat((x, x1, x2, x3), dim=1).transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def aa_embedding(hidden_size):\n",
    "    return torch.nn.Embedding(aa_embedding_size, hidden_size, padding_idx=0)\n",
    "\n",
    "def aa_one_hot(aa_indices, *cat_others):\n",
    "    aa_x = torch.nn.functional.one_hot(\n",
    "        aa_indices, aa_embedding_size\n",
    "    )\n",
    "    return torch.cat((aa_x, *cat_others), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def zero_param(*shape):\n",
    "    return torch.nn.Parameter(torch.zeros(shape), requires_grad=False)\n",
    "\n",
    "def xavier_param(*shape):\n",
    "    x = torch.nn.Parameter(torch.empty(shape), requires_grad=False)\n",
    "    torch.nn.init.xavier_uniform_(x)\n",
    "    return x\n",
    "\n",
    "init_state = xavier_param\n",
    "\n",
    "class SeqLSTM(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, \n",
    "                 rnn_layer=2, bidirectional=True\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        if bidirectional:\n",
    "            if out_features%2 != 0:\n",
    "                raise ValueError(\"'out_features' must be able to be divided by 2\")\n",
    "            hidden = out_features//2\n",
    "        else:\n",
    "            hidden = out_features\n",
    "\n",
    "        self.rnn_h0 = init_state(\n",
    "            rnn_layer+rnn_layer*bidirectional,\n",
    "            1, hidden\n",
    "        )\n",
    "        self.rnn_c0 = init_state(\n",
    "            rnn_layer+rnn_layer*bidirectional,\n",
    "            1, hidden\n",
    "        )\n",
    "        self.rnn = torch.nn.LSTM(\n",
    "            input_size = in_features,\n",
    "            hidden_size = hidden,\n",
    "            num_layers = rnn_layer,\n",
    "            batch_first = True,\n",
    "            bidirectional = bidirectional,\n",
    "        )\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        h0 = self.rnn_h0.repeat(1, x.size(0), 1)\n",
    "        c0 = self.rnn_c0.repeat(1, x.size(0), 1)\n",
    "        x, _ = self.rnn(x, (h0,c0))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SeqGRU(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, \n",
    "                 rnn_layer=2, bidirectional=True\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        if bidirectional:\n",
    "            if out_features%2 != 0:\n",
    "                raise ValueError(\"'out_features' must be able to be divided by 2\")\n",
    "            # to make sure that output dim is out_features\n",
    "            # as `bidirectional` will cat forward and reverse RNNs\n",
    "            hidden = out_features//2\n",
    "        else:\n",
    "            hidden = out_features\n",
    "        \n",
    "        self.rnn_h0 = init_state(\n",
    "            rnn_layer+rnn_layer*bidirectional, \n",
    "            1, hidden\n",
    "        )\n",
    "        self.rnn = torch.nn.GRU(\n",
    "            input_size = in_features,\n",
    "            hidden_size = hidden,\n",
    "            num_layers = rnn_layer,\n",
    "            batch_first = True,\n",
    "            bidirectional = bidirectional,\n",
    "        )\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        h0 = self.rnn_h0.repeat(1, x.size(0), 1)\n",
    "        x, _ = self.rnn(x, h0)\n",
    "        return x\n",
    "\n",
    "class SeqTransformer(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        in_features,\n",
    "        hidden_features,\n",
    "        nhead=8,\n",
    "        nlayers=2,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        encoder_layers = torch.nn.TransformerEncoderLayer(\n",
    "            in_features, nhead, hidden_features, dropout\n",
    "        )\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(\n",
    "            encoder_layers, nlayers\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.transformer_encoder(x.permute(1,0,2)).permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SeqAttentionSum(torch.nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.attn = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features, 1, bias=False),\n",
    "            torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        attn = self.attn(x)\n",
    "        return torch.sum(torch.mul(x, attn), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InputMetaNet(torch.nn.Module):\n",
    "    # Meta = Charge, NCE and Instrument\n",
    "    def __init__(self,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.nn = torch.nn.Linear(\n",
    "            max_instrument_num+1, out_features-1\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "        charges, NCEs, instrument_indices,\n",
    "    ):\n",
    "        inst_x = torch.nn.functional.one_hot(\n",
    "            instrument_indices, max_instrument_num\n",
    "        )\n",
    "        meta_x = self.nn(torch.cat((inst_x, NCEs), 1))\n",
    "        meta_x = torch.cat((meta_x, charges), 1)\n",
    "        return meta_x\n",
    "\n",
    "class InputModNet(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.nn = torch.nn.Linear(\n",
    "            mod_feature_size, out_features,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "        mod_x,\n",
    "    ):\n",
    "        return self.nn(mod_x)\n",
    "\n",
    "class InputModNetFixFirstK(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.k = 6\n",
    "        self.nn = torch.nn.Linear(\n",
    "            mod_feature_size-self.k, out_features-self.k,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "        mod_x,\n",
    "    ):\n",
    "        return torch.cat((\n",
    "            mod_x[:,:,:self.k], \n",
    "            self.nn(mod_x[:,:,self.k:])\n",
    "        ), 2)\n",
    "        \n",
    "class InputAALSTM(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        mod_hidden = 8\n",
    "        self.mod_nn = InputModNetFixFirstK(mod_hidden)\n",
    "        self.lstm = SeqLSTM(\n",
    "            aa_embedding_size+mod_hidden,\n",
    "            out_features,\n",
    "            rnn_layer=1, bidirectional=True\n",
    "        )\n",
    "    def forward(self, aa_indices, mod_x):\n",
    "        mod_x = self.mod_nn(mod_x)\n",
    "        x = aa_one_hot(aa_indices, mod_x)\n",
    "        return self.lstm(x)\n",
    "\n",
    "class InputAALSTM_cat_Meta(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        meta_dim = 4\n",
    "        mod_hidden = 8\n",
    "        self.mod_nn = InputModNetFixFirstK(mod_hidden)\n",
    "        self.meta_nn = InputMetaNet(meta_dim)\n",
    "        self.nn = SeqLSTM(\n",
    "            aa_embedding_size+mod_hidden,\n",
    "            out_features-meta_dim,\n",
    "            rnn_layer=1, bidirectional=True\n",
    "        )\n",
    "        \n",
    "    def forward(self, \n",
    "        aa_indices, mod_x, charges, NCEs, instrument_indices\n",
    "    ):\n",
    "        mod_x = self.mod_nn(mod_x)\n",
    "        x = aa_one_hot(aa_indices, mod_x)\n",
    "        x = self.nn(x)\n",
    "        meta_x = self.meta_nn(\n",
    "            charges, NCEs, instrument_indices\n",
    "        ).unsqueeze(1).repeat(1, mod_x.size(1), 1)\n",
    "        return torch.cat((x, meta_x), 2)\n",
    "\n",
    "class InputAALSTM_cat_Charge(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.charge_dim = 2\n",
    "        mod_hidden = 8\n",
    "        self.mod_nn = InputModNetFixFirstK(mod_hidden)\n",
    "        self.nn = SeqLSTM(\n",
    "            aa_embedding_size+mod_hidden,\n",
    "            out_features-self.charge_dim,\n",
    "            rnn_layer=1, bidirectional=True\n",
    "        )\n",
    "        \n",
    "    def forward(self, aa_indices, mod_x, charges):\n",
    "        mod_x = self.mod_nn(mod_x)\n",
    "        x = aa_one_hot(aa_indices, mod_x)\n",
    "        x = self.nn(x)\n",
    "        charge_x = charges.unsqueeze(1).repeat(\n",
    "            1, mod_x.size(1), self.charge_dim\n",
    "        )\n",
    "        return torch.cat((x, charge_x), 2)\n",
    "\n",
    "class InputAAEmbedding(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.aa_embedding = aa_embedding(\n",
    "            out_features-mod_feature_size\n",
    "        )\n",
    "    def forward(self, aa_indices, mod_x):\n",
    "        aa_x = self.aa_embedding(aa_indices)\n",
    "        return torch.cat((aa_x, mod_x), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Input_AA_CNN_LSTM_Encoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Encode a peptide sequence into a single hidden representation\n",
    "    \"\"\"\n",
    "    def __init__(self, out_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        mod_hidden = 8\n",
    "        self.mod_nn = InputModNetFixFirstK(mod_hidden)\n",
    "\n",
    "        input_dim = aa_embedding_size+mod_hidden\n",
    "        self.input_cnn = SeqCNN(input_dim)\n",
    "        self.hidden_nn = SeqLSTM(\n",
    "            input_dim*4, out_features, rnn_layer=2\n",
    "        ) #SeqCNN outputs 4*input_dim\n",
    "        self.attn_sum = SeqAttentionSum(out_features)\n",
    "\n",
    "    def forward(self, aa_indices, mod_x):\n",
    "        mod_x = self.mod_nn(mod_x)\n",
    "        x = aa_one_hot(aa_indices, mod_x)\n",
    "        x = self.input_cnn(x)\n",
    "        x = self.hidden_nn(x)\n",
    "        x = self.attn_sum(x)\n",
    "        return x\n",
    "\n",
    "class Input_AA_CNN_Encoder(torch.nn.Module):\n",
    "    def __init__(self, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        mod_hidden = 8\n",
    "        self.mod_nn = InputModNetFixFirstK(mod_hidden)\n",
    "        input_dim = aa_embedding_size+mod_hidden\n",
    "        self.input_cnn = SeqCNN(input_dim)\n",
    "        self.hidden_nn = SeqLSTM(\n",
    "            input_dim*4, out_features, rnn_layer=1\n",
    "        ) #SeqCNN outputs 4*input_dim\n",
    "\n",
    "    def forward(self, aa_indices, mod_x):\n",
    "        mod_x = self.mod_nn(mod_x)\n",
    "        x = aa_one_hot(aa_indices, mod_x)\n",
    "        x = self.input_cnn(x)\n",
    "        x = self.hidden_nn(x)\n",
    "        return x\n",
    "\n",
    "class Input_AA_CNN_LSTM_cat_Charge_Encoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Encode a peptide sequence into a single hidden representation\n",
    "    \"\"\"\n",
    "    def __init__(self, out_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        mod_hidden = 8\n",
    "        self.mod_nn = InputModNetFixFirstK(mod_hidden)\n",
    "\n",
    "        input_dim = aa_embedding_size+mod_hidden+1\n",
    "        self.input_cnn = SeqCNN(input_dim)\n",
    "        self.hidden_nn = SeqLSTM(\n",
    "            input_dim*4, out_features, rnn_layer=2\n",
    "        ) #SeqCNN outputs 4*input_dim\n",
    "        self.attn_sum = SeqAttentionSum(out_features)\n",
    "\n",
    "    def forward(self, aa_indices, mod_x, charges):\n",
    "        mod_x = self.mod_nn(mod_x)\n",
    "        x = aa_one_hot(\n",
    "            aa_indices, mod_x, \n",
    "            charges.unsqueeze(1).repeat(1,mod_x.size(1),1)\n",
    "        )\n",
    "        x = self.input_cnn(x)\n",
    "        x = self.hidden_nn(x)\n",
    "        x = self.attn_sum(x)\n",
    "        return x\n",
    "\n",
    "class Input_AA_CNN_Encoder(torch.nn.Module):\n",
    "    def __init__(self, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        mod_hidden = 8\n",
    "        self.mod_nn = InputModNetFixFirstK(mod_hidden)\n",
    "        input_dim = aa_embedding_size+mod_hidden\n",
    "        self.input_cnn = SeqCNN(input_dim)\n",
    "        self.hidden_nn = SeqLSTM(\n",
    "            input_dim*4, out_features, rnn_layer=1\n",
    "        ) #SeqCNN outputs 4*input_dim\n",
    "\n",
    "    def forward(self, aa_indices, mod_x):\n",
    "        mod_x = self.mod_nn(mod_x)\n",
    "        x = aa_one_hot(aa_indices, mod_x)\n",
    "        x = self.input_cnn(x)\n",
    "        x = self.hidden_nn(x)\n",
    "        return x\n",
    "\n",
    "class Input_AA_LSTM_Encoder(torch.nn.Module):\n",
    "    def __init__(self, out_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_nn = InputAALSTM(out_features)\n",
    "        self.nn = SeqLSTM(\n",
    "            out_features, out_features, rnn_layer=1\n",
    "        )\n",
    "\n",
    "    def forward(self, aa_indices, mod_x):\n",
    "        x = self.input_nn(aa_indices, mod_x)\n",
    "        x = self.nn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SeqLSTMDecoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Decode hidden representation into the sequence\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden = 128\n",
    "        self.rnn = SeqLSTM(\n",
    "            in_features, out_features,\n",
    "            rnn_layer=1, bidirectional=False,\n",
    "        )\n",
    "\n",
    "        self.output_nn = torch.nn.Linear(\n",
    "            hidden, out_features, bias=False\n",
    "        )\n",
    "    \n",
    "    def forward(self, x:torch.tensor, output_len):\n",
    "        x = self.rnn(\n",
    "            x.unsqueeze(1).repeat(1,output_len,1)\n",
    "        )\n",
    "        x = self.output_nn(x)\n",
    "        return x\n",
    "\n",
    "class SeqGRUDecoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Decode hidden representation into the sequence\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden = 128\n",
    "        self.rnn = SeqGRU(\n",
    "            in_features, out_features,\n",
    "            rnn_layer=1, bidirectional=False,\n",
    "        )\n",
    "\n",
    "        self.output_nn = torch.nn.Linear(\n",
    "            hidden, out_features, bias=False\n",
    "        )\n",
    "    \n",
    "    def forward(self, x:torch.tensor, output_len):\n",
    "        x = self.rnn(\n",
    "            x.unsqueeze(1).repeat(1,output_len,1)\n",
    "        )\n",
    "        x = self.output_nn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OutputLSTM_cat_Meta(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        in_features,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        meta_dim = 4\n",
    "        self.meta_nn = InputMetaNet(meta_dim)\n",
    "        self.nn = SeqLSTM(\n",
    "            in_features+meta_dim,\n",
    "            out_features,\n",
    "            rnn_layer=1, bidirectional=False\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, charges, NCEs, instrument_indices):\n",
    "        meta_x = self.meta_nn(\n",
    "            charges, NCEs, instrument_indices\n",
    "        ).unsqueeze(1).repeat(1, x.size(1), 1)\n",
    "        return self.nn(torch.cat((x, meta_x), 2))\n",
    "\n",
    "    \n",
    "class OutputLinear_cat_Meta(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        in_features,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        meta_dim = 4\n",
    "        self.meta_nn = InputMetaNet(meta_dim)\n",
    "        self.nn = torch.nn.Linear(\n",
    "            in_features+meta_dim,\n",
    "            out_features,\n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, charges, NCEs, instrument_indices):\n",
    "        meta_x = self.meta_nn(\n",
    "            charges, NCEs, instrument_indices\n",
    "        ).unsqueeze(1).repeat(1, x.size(1), 1)\n",
    "        return self.nn(torch.cat((x, meta_x), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LinearDecoder(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.nn = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features, 64),\n",
    "            torch.nn.PReLU(),\n",
    "            torch.nn.Linear(64, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.nn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, out_features=128, max_len = 200):\n",
    "        super().__init__()\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(\n",
    "                0, out_features, 2\n",
    "            ) * (-np.log(max_len) / out_features)\n",
    "        )\n",
    "        pe = torch.zeros(1, max_len, out_features)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:,:x.size(1),:]\n",
    "\n",
    "class PositionalEmbedding(torch.nn.Module):\n",
    "    def __init__(self, out_features=128, max_len=200):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pos_emb = torch.nn.Embedding(\n",
    "            max_len, out_features\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pos_emb(torch.arange(\n",
    "            x.size(1), dtype=torch.long\n",
    "        ).unsqueeze(0))\n",
    "\n",
    "class AATransformerEncoding(torch.nn.Module):\n",
    "    def __init__(self, out_features, max_len=200):\n",
    "        super().__init__()\n",
    "        mod_hidden = 8\n",
    "        self.mod_nn = InputModNetFixFirstK(mod_hidden)\n",
    "        self.aa_emb = aa_embedding(\n",
    "            out_features-mod_hidden\n",
    "        )\n",
    "        self.pos_encoder = PositionalEmbedding(\n",
    "            out_features, max_len\n",
    "        )\n",
    "        \n",
    "    def forward(self, \n",
    "        aa_indices, mod_x\n",
    "    ):\n",
    "        mod_x = self.mod_nn(mod_x)\n",
    "        x = self.aa_emb(aa_indices)\n",
    "        return self.pos_encoder(torch.cat((x, mod_x), 2))\n",
    "\n",
    "class HiddenTransformer(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        hidden, hidden_expand=4,\n",
    "        nhead=8, nlayers=2, dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.transormer = SeqTransformer(\n",
    "            hidden, hidden*hidden_expand, nhead=nhead, \n",
    "            nlayers=nlayers, dropout=dropout\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.transormer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
