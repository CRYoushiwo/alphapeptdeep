{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp model.building_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "The building block module specifies the architectures of the core neural networks used in AlphaPeptDeep.\n",
    "\n",
    "All networks are based on the [PyTorch]('https://pytorch.org/') package by subclassing `torch.nn.Module`, which is the base class for all neural networks. To implement the Transformer-network, the HuggingFace [transformers]('https://huggingface.co/docs/transformers/') package is used, which allows to specify transformer networks in Pytorch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/constantin/opt/anaconda3/envs/alphapeptdeep/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import torch\n",
    "torch.set_num_threads(2)\n",
    "\n",
    "from peptdeep.settings import model_const\n",
    "from peptdeep.settings import global_settings as settings\n",
    "\n",
    "mod_feature_size = len(model_const['mod_elements'])\n",
    "max_instrument_num = model_const['max_instrument_num']\n",
    "frag_types = settings['model']['frag_types']\n",
    "max_frag_charge = settings['model']['max_frag_charge']\n",
    "num_ion_types = len(frag_types)*max_frag_charge\n",
    "aa_embedding_size = model_const['aa_embedding_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "Basic embeddings or encodings of inputs such as AA sequence or modification state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def aa_embedding(hidden_size):\n",
    "    return torch.nn.Embedding(aa_embedding_size, hidden_size, padding_idx=0)\n",
    "\n",
    "def ascii_embedding(hidden_size):\n",
    "    return torch.nn.Embedding(128, hidden_size, padding_idx=0)\n",
    "\n",
    "def aa_one_hot(aa_indices, *cat_others):\n",
    "    aa_x = torch.nn.functional.one_hot(\n",
    "        aa_indices, aa_embedding_size\n",
    "    )\n",
    "    return torch.cat((aa_x, *cat_others), 2)\n",
    "\n",
    "def instrument_embedding(hidden_size):\n",
    "    return torch.nn.Embedding(max_instrument_num, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial states\n",
    "Generates tensors defining the initial (hidden) states of the elements in the input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def zero_param(*shape):\n",
    "    return torch.nn.Parameter(torch.zeros(shape), requires_grad=False)\n",
    "\n",
    "def xavier_param(*shape):\n",
    "    x = torch.nn.Parameter(torch.empty(shape), requires_grad=False)\n",
    "    torch.nn.init.xavier_uniform_(x)\n",
    "    return x\n",
    "\n",
    "init_state = xavier_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Networks\n",
    "The 'Input' classes represent the input layers of the networks, meaning they interact directly with the (formatted) features such as the peptide sequence, the charge state, the modifications or the collision energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear input transformations\n",
    "Performing linear operations on the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Input_AA_MOD_Embed(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    concatenates the AA embedding with the modifcation vector\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.aa_embedding = aa_embedding(\n",
    "            out_features-mod_feature_size\n",
    "        )\n",
    "    def forward(self, aa_indices, mod_x):\n",
    "        aa_x = self.aa_embedding(aa_indices)\n",
    "        return torch.cat((aa_x, mod_x), 2)\n",
    "#legacy\n",
    "InputEmbedAAwithMod = Input_AA_MOD_Embed\n",
    "\n",
    "\n",
    "class Input_META_Linear(torch.nn.Module):\n",
    "    # Meta = Charge, NCE and Instrument\n",
    "    \"\"\"Encodes Charge state, Normalized Collision Energy (NCE) and Instrument for a given spectrum \n",
    "    into a 'meta' single layer network\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.nn = torch.nn.Linear(\n",
    "            max_instrument_num+1, out_features-1\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "        charges, NCEs, instrument_indices,\n",
    "    ):\n",
    "        inst_x = torch.nn.functional.one_hot(\n",
    "            instrument_indices, max_instrument_num\n",
    "        )\n",
    "        meta_x = self.nn(torch.cat((inst_x, NCEs), 1))\n",
    "        meta_x = torch.cat((meta_x, charges), 1)\n",
    "        return meta_x\n",
    "#legacy\n",
    "InputMetaNet = Input_META_Linear\n",
    "\n",
    "\n",
    "class Input_MOD_LinearFixFirstK(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Encodes the modification vector in a single layer feed forward network, but not transforming the first k features\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.k = 6\n",
    "        self.nn = torch.nn.Linear(\n",
    "            mod_feature_size-self.k, out_features-self.k,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "        mod_x,\n",
    "    ):\n",
    "        return torch.cat((\n",
    "            mod_x[:,:,:self.k], \n",
    "            self.nn(mod_x[:,:,self.k:])\n",
    "        ), 2)\n",
    "#legacy\n",
    "InputModNetFixFirstK = Input_MOD_LinearFixFirstK\n",
    "\n",
    "class Input_MOD_Linear(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Encodes the modification vector in a single layer feed forward network\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.nn = torch.nn.Linear(\n",
    "            mod_feature_size, out_features,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "        mod_x,\n",
    "    ):\n",
    "        return self.nn(mod_x)\n",
    "#legacy\n",
    "InputModNet = Input_MOD_Linear\n",
    "\n",
    "class Input_AA_Mod_Transformer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Encodes AA and modification vector\n",
    "    \"\"\"\n",
    "    def __init__(self, out_features, max_len=200):\n",
    "        super().__init__()\n",
    "        mod_hidden = 8\n",
    "        self.mod_nn = InputModNetFixFirstK(mod_hidden)\n",
    "        self.aa_emb = aa_embedding(\n",
    "            out_features-mod_hidden\n",
    "        )\n",
    "        self.pos_encoder = PositionalEncoding(\n",
    "            out_features, max_len\n",
    "        )\n",
    "        \n",
    "    def forward(self, \n",
    "        aa_indices, mod_x\n",
    "    ):\n",
    "        mod_x = self.mod_nn(mod_x)\n",
    "        x = self.aa_emb(aa_indices)\n",
    "        return self.pos_encoder(torch.cat((x, mod_x), 2))\n",
    "#legacy\n",
    "AATransformerEncoding = Input_AA_Mod_Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM\n",
    "Applying LSTMs to the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "        \n",
    "class Input_AA_MOD_LSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    applies an LSTM network to a peptide-modification combination\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        mod_hidden = 8\n",
    "        self.mod_nn = InputModNetFixFirstK(mod_hidden)\n",
    "        self.lstm = SeqLSTM(\n",
    "            aa_embedding_size+mod_hidden,\n",
    "            out_features,\n",
    "            rnn_layer=1, bidirectional=True\n",
    "        )\n",
    "    def forward(self, aa_indices, mod_x):\n",
    "        mod_x = self.mod_nn(mod_x)\n",
    "        x = aa_one_hot(aa_indices, mod_x)\n",
    "        return self.lstm(x)\n",
    "#legacy\n",
    "InputAALSTM = Input_AA_MOD_LSTM\n",
    "\n",
    "        \n",
    "class Input_AA_MOD_Meta_LSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    applies a LSTM network to a peptide-modification combination and concatenates with 'meta' information (charge, nce, instrument_indices) \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        meta_dim = 4\n",
    "        mod_hidden = 8\n",
    "        self.mod_nn = InputModNetFixFirstK(mod_hidden)\n",
    "        self.meta_nn = InputMetaNet(meta_dim)\n",
    "        self.nn = SeqLSTM(\n",
    "            aa_embedding_size+mod_hidden,\n",
    "            out_features-meta_dim,\n",
    "            rnn_layer=1, bidirectional=True\n",
    "        )\n",
    "        \n",
    "    def forward(self, \n",
    "        aa_indices, mod_x, charges, NCEs, instrument_indices\n",
    "    ):\n",
    "        mod_x = self.mod_nn(mod_x)\n",
    "        x = aa_one_hot(aa_indices, mod_x)\n",
    "        x = self.nn(x)\n",
    "        meta_x = self.meta_nn(\n",
    "            charges, NCEs, instrument_indices\n",
    "        ).unsqueeze(1).repeat(1, mod_x.size(1), 1)\n",
    "        return torch.cat((x, meta_x), 2)\n",
    "#legacy\n",
    "InputAALSTM_cat_Meta = Input_AA_MOD_Meta_LSTM\n",
    "\n",
    "\n",
    "class Input_AA_MOD_CHARGE_LSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    applies a LSTM network to a peptide-modification combination and concatenates with charge state information\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.charge_dim = 2\n",
    "        mod_hidden = 8\n",
    "        self.mod_nn = InputModNetFixFirstK(mod_hidden)\n",
    "        self.nn = SeqLSTM(\n",
    "            aa_embedding_size+mod_hidden,\n",
    "            out_features-self.charge_dim,\n",
    "            rnn_layer=1, bidirectional=True\n",
    "        )\n",
    "        \n",
    "    def forward(self, aa_indices, mod_x, charges):\n",
    "        mod_x = self.mod_nn(mod_x)\n",
    "        x = aa_one_hot(aa_indices, mod_x)\n",
    "        x = self.nn(x)\n",
    "        charge_x = charges.unsqueeze(1).repeat(\n",
    "            1, mod_x.size(1), self.charge_dim\n",
    "        )\n",
    "        return torch.cat((x, charge_x), 2)\n",
    "#legacy\n",
    "InputAALSTM_cat_Charge = Input_AA_MOD_CHARGE_LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Networks\n",
    "The 'Output' classes represent the output layers of the networks, meaning they take the hidden layer of a network as input, transform it into the output such as a spectrum, ccs value, rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Output_META_LSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    takes a hidden layer which processed the 'meta' information of NCE, Instrument, Charge\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        in_features,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        meta_dim = 4\n",
    "        self.meta_nn = InputMetaNet(meta_dim)\n",
    "        self.nn = SeqLSTM(\n",
    "            in_features+meta_dim,\n",
    "            out_features,\n",
    "            rnn_layer=1, bidirectional=False\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, charges, NCEs, instrument_indices):\n",
    "        meta_x = self.meta_nn(\n",
    "            charges, NCEs, instrument_indices\n",
    "        ).unsqueeze(1).repeat(1, x.size(1), 1)\n",
    "        return self.nn(torch.cat((x, meta_x), 2))\n",
    "#legacy\n",
    "OutputLSTM_cat_Meta = Output_META_LSTM\n",
    "    \n",
    "class Output_META_Linear(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    takes a hidden linear which processed the 'meta' information of NCE, Instrument, Charge\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        in_features,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        meta_dim = 4\n",
    "        self.meta_nn = InputMetaNet(meta_dim)\n",
    "        self.nn = torch.nn.Linear(\n",
    "            in_features+meta_dim,\n",
    "            out_features,\n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, charges, NCEs, instrument_indices):\n",
    "        meta_x = self.meta_nn(\n",
    "            charges, NCEs, instrument_indices\n",
    "        ).unsqueeze(1).repeat(1, x.size(1), 1)\n",
    "        return self.nn(torch.cat((x, meta_x), 2))\n",
    "#legacy\n",
    "OutputLinear_cat_Meta = Output_META_Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq Networks\n",
    "The seq networks take the sequence and possible accompanying information such as charge state or modification and apply neural network transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SeqCNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    extracts sequence features using `torch.nn.Conv1D` with different kernel sizes (3,5,7), and then concatenates the outputs of these Conv1Ds\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_hidden):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn_short = torch.nn.Conv1d(\n",
    "            embedding_hidden, embedding_hidden,\n",
    "            kernel_size=3, padding=1\n",
    "        )\n",
    "        self.cnn_medium = torch.nn.Conv1d(\n",
    "            embedding_hidden, embedding_hidden,\n",
    "            kernel_size=5, padding=2\n",
    "        )\n",
    "        self.cnn_long = torch.nn.Conv1d(\n",
    "            embedding_hidden, embedding_hidden,\n",
    "            kernel_size=7, padding=3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x1 = self.cnn_short(x)\n",
    "        x2 = self.cnn_medium(x)\n",
    "        x3 = self.cnn_long(x)\n",
    "        return torch.cat((x, x1, x2, x3), dim=1).transpose(1,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class SeqLSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, \n",
    "                 rnn_layer=2, bidirectional=True\n",
    "        ):\n",
    "        \"\"\"\n",
    "        returns LSTM applied on sequence input\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        if bidirectional:\n",
    "            if out_features%2 != 0:\n",
    "                raise ValueError(\"'out_features' must be able to be divided by 2\")\n",
    "            hidden = out_features//2\n",
    "        else:\n",
    "            hidden = out_features\n",
    "\n",
    "        self.rnn_h0 = init_state(\n",
    "            rnn_layer+rnn_layer*bidirectional,\n",
    "            1, hidden\n",
    "        )\n",
    "        self.rnn_c0 = init_state(\n",
    "            rnn_layer+rnn_layer*bidirectional,\n",
    "            1, hidden\n",
    "        ) \n",
    "        self.rnn = torch.nn.LSTM(\n",
    "            input_size = in_features,\n",
    "            hidden_size = hidden,\n",
    "            num_layers = rnn_layer,\n",
    "            batch_first = True,\n",
    "            bidirectional = bidirectional,\n",
    "        )\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        h0 = self.rnn_h0.repeat(1, x.size(0), 1)\n",
    "        c0 = self.rnn_c0.repeat(1, x.size(0), 1)\n",
    "        x, _ = self.rnn(x, (h0,c0))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SeqGRU(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, \n",
    "                 rnn_layer=2, bidirectional=True\n",
    "        ):\n",
    "        \"\"\"\n",
    "        returns GRU applied on sequence input\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        if bidirectional:\n",
    "            if out_features%2 != 0:\n",
    "                raise ValueError(\"'out_features' must be able to be divided by 2\")\n",
    "            # to make sure that output dim is out_features\n",
    "            # as `bidirectional` will cat forward and reverse RNNs\n",
    "            hidden = out_features//2\n",
    "        else:\n",
    "            hidden = out_features\n",
    "        \n",
    "        self.rnn_h0 = init_state(\n",
    "            rnn_layer+rnn_layer*bidirectional, \n",
    "            1, hidden\n",
    "        )\n",
    "        self.rnn = torch.nn.GRU(\n",
    "            input_size = in_features,\n",
    "            hidden_size = hidden,\n",
    "            num_layers = rnn_layer,\n",
    "            batch_first = True,\n",
    "            bidirectional = bidirectional,\n",
    "        )\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        h0 = self.rnn_h0.repeat(1, x.size(0), 1)\n",
    "        x, _ = self.rnn(x, h0)\n",
    "        return x\n",
    "\n",
    "class SeqTransformer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    return Transformer applied on sequence input\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        in_features,\n",
    "        hidden_features,\n",
    "        nhead=8,\n",
    "        nlayers=2,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        encoder_layers = torch.nn.TransformerEncoderLayer(\n",
    "            in_features, nhead, hidden_features, dropout\n",
    "        )\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(\n",
    "            encoder_layers, nlayers\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.transformer_encoder(x.permute(1,0,2)).permute(1,0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Seq Transformations\n",
    "\n",
    "Takes in a sequence and applies a linear transformation on it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SeqAttentionSum(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    apply linear transformation and tensor rescaling with softmax\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.attn = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features, 1, bias=False),\n",
    "            torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        attn = self.attn(x)\n",
    "        return torch.sum(torch.mul(x, attn), dim=1)\n",
    "\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    transform sequence input into a positional representation\n",
    "    \"\"\"\n",
    "    def __init__(self, out_features=128, max_len = 200):\n",
    "        super().__init__()\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(\n",
    "                0, out_features, 2\n",
    "            ) * (-np.log(max_len) / out_features)\n",
    "        )\n",
    "        pe = torch.zeros(1, max_len, out_features)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:,:x.size(1),:]\n",
    "\n",
    "class PositionalEmbedding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    transform sequence with the standard embedding function\n",
    "    \"\"\"\n",
    "    def __init__(self, out_features=128, max_len=200):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pos_emb = torch.nn.Embedding(\n",
    "            max_len, out_features\n",
    "        )\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        return x + self.pos_emb(torch.arange(\n",
    "            x.size(1), dtype=torch.long, device=x.device\n",
    "        ).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoders\n",
    "The encoder classes transform the features into a learned representation. Within the encoder, the `Input..` classes are used to transform the features into a network representation. Subsequently, Convolutional Neural Networks (CNNs) and/or Long Short-Term Memory (LSTM) Networks and/or Linear transformations are applied to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class Encoder_AA_MOD_LSTM_LSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    two LSTM layers on AA and mod info\n",
    "    \"\"\"\n",
    "    def __init__(self, out_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_nn = InputAALSTM(out_features)\n",
    "        self.nn = SeqLSTM(\n",
    "            out_features, out_features, rnn_layer=1\n",
    "        )\n",
    "\n",
    "    def forward(self, aa_indices, mod_x):\n",
    "        x = self.input_nn(aa_indices, mod_x)\n",
    "        x = self.nn(x)\n",
    "        return x\n",
    "\n",
    "#legacy\n",
    "Input_AA_LSTM_Encoder = Encoder_AA_MOD_LSTM_LSTM\n",
    "\n",
    "\n",
    "class Encoder_AA_MOD_CNN_LSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    linear NN for modification, CNN and LSTM layer\n",
    "    \"\"\"\n",
    "    def __init__(self, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        mod_hidden = 8\n",
    "        self.mod_nn = InputModNetFixFirstK(mod_hidden)\n",
    "        input_dim = aa_embedding_size+mod_hidden\n",
    "        self.input_cnn = SeqCNN(input_dim)\n",
    "        self.hidden_nn = SeqLSTM(\n",
    "            input_dim*4, out_features, rnn_layer=1\n",
    "        ) #SeqCNN outputs 4*input_dim\n",
    "\n",
    "    def forward(self, aa_indices, mod_x):\n",
    "        mod_x = self.mod_nn(mod_x)\n",
    "        x = aa_one_hot(aa_indices, mod_x)\n",
    "        x = self.input_cnn(x)\n",
    "        x = self.hidden_nn(x)\n",
    "        return x\n",
    "\n",
    "#legacy\n",
    "Input_AA_CNN_Encoder = Encoder_AA_MOD_CNN_LSTM\n",
    "\n",
    "\n",
    "class Encoder_AA_MOD_CNN_LSTM_ATTSUM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    linear NN for modification, CNN, LSTM, Attention sum (linear + softmax)\n",
    "    \"\"\"\n",
    "    def __init__(self, out_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        mod_hidden = 8\n",
    "        self.mod_nn = InputModNetFixFirstK(mod_hidden)\n",
    "\n",
    "        input_dim = aa_embedding_size+mod_hidden\n",
    "        self.input_cnn = SeqCNN(input_dim)\n",
    "        self.hidden_nn = SeqLSTM(\n",
    "            input_dim*4, out_features, rnn_layer=2\n",
    "        ) #SeqCNN outputs 4*input_dim\n",
    "        self.attn_sum = SeqAttentionSum(out_features)\n",
    "\n",
    "    def forward(self, aa_indices, mod_x):\n",
    "        mod_x = self.mod_nn(mod_x)\n",
    "        x = aa_one_hot(aa_indices, mod_x)\n",
    "        x = self.input_cnn(x)\n",
    "        x = self.hidden_nn(x)\n",
    "        x = self.attn_sum(x)\n",
    "        return x\n",
    "#legacy\n",
    "Input_AA_CNN_LSTM_Encoder = Encoder_AA_MOD_CNN_LSTM_ATTSUM\n",
    "\n",
    "\n",
    "class Encoder_AA_MOD_CH_CNN_LSTM_ATTSUM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    linear NN for modification, charge concatenated, CNN, LSTM, Attention sum (linear + softmax)\n",
    "    \"\"\"\n",
    "    def __init__(self, out_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        mod_hidden = 8\n",
    "        self.mod_nn = InputModNetFixFirstK(mod_hidden)\n",
    "\n",
    "        input_dim = aa_embedding_size+mod_hidden+1\n",
    "        self.input_cnn = SeqCNN(input_dim)\n",
    "        self.hidden_nn = SeqLSTM(\n",
    "            input_dim*4, out_features, rnn_layer=2\n",
    "        ) #SeqCNN outputs 4*input_dim\n",
    "        self.attn_sum = SeqAttentionSum(out_features)\n",
    "\n",
    "    def forward(self, aa_indices, mod_x, charges):\n",
    "        mod_x = self.mod_nn(mod_x)\n",
    "        x = aa_one_hot(\n",
    "            aa_indices, mod_x, \n",
    "            charges.unsqueeze(1).repeat(1,mod_x.size(1),1)\n",
    "        )\n",
    "        x = self.input_cnn(x)\n",
    "        x = self.hidden_nn(x)\n",
    "        x = self.attn_sum(x)\n",
    "        return x\n",
    "\n",
    "#legacy\n",
    "Input_AA_CNN_LSTM_cat_Charge_Encoder = Encoder_AA_MOD_CH_CNN_LSTM_ATTSUM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Decoder_AA_LSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Decode with LSTM\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden = 128\n",
    "        self.rnn = SeqLSTM(\n",
    "            in_features, out_features,\n",
    "            rnn_layer=1, bidirectional=False,\n",
    "        )\n",
    "\n",
    "        self.output_nn = torch.nn.Linear(\n",
    "            hidden, out_features, bias=False\n",
    "        )\n",
    "    \n",
    "    def forward(self, x:torch.tensor, output_len):\n",
    "        x = self.rnn(\n",
    "            x.unsqueeze(1).repeat(1,output_len,1)\n",
    "        )\n",
    "        x = self.output_nn(x)\n",
    "        return x\n",
    "#legacy\n",
    "SeqLSTMDecoder = Decoder_AA_LSTM\n",
    "\n",
    "class Decoder_AA_GRU(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Decode with GRU\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden = 128\n",
    "        self.rnn = SeqGRU(\n",
    "            in_features, out_features,\n",
    "            rnn_layer=1, bidirectional=False,\n",
    "        )\n",
    "\n",
    "        self.output_nn = torch.nn.Linear(\n",
    "            hidden, out_features, bias=False\n",
    "        )\n",
    "    \n",
    "    def forward(self, x:torch.tensor, output_len):\n",
    "        x = self.rnn(\n",
    "            x.unsqueeze(1).repeat(1,output_len,1)\n",
    "        )\n",
    "        x = self.output_nn(x)\n",
    "        return x\n",
    "#legacy\n",
    "SeqGRUDecoder = Decoder_AA_GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Decoder_AA_Linear(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Decode w linear NN\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.nn = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features, 64),\n",
    "            torch.nn.PReLU(),\n",
    "            torch.nn.Linear(64, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.nn(x)\n",
    "#legacy\n",
    "LinearDecoder = Decoder_AA_Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#BERT from huggingface\n",
    "import numpy as np\n",
    "from transformers.models.bert.modeling_bert import BertEncoder\n",
    "\n",
    "class HiddenTransformer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer NN based on pytorch's built-in TransformerLayer class\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "        hidden, hidden_expand=4,\n",
    "        nhead=8, nlayers=4, dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.transormer = SeqTransformer(\n",
    "            hidden, hidden*hidden_expand, nhead=nhead, \n",
    "            nlayers=nlayers, dropout=dropout\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.transormer(x)\n",
    "\n",
    "\n",
    "\n",
    "class HiddenBert(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer NN based on HuggingFace's BertEncoder class\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "        hidden, hidden_expand=4,\n",
    "        nhead=8, nlayers=4, dropout=0.1,\n",
    "        output_attentions=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.config = _PseudoBertConfig(\n",
    "            hidden_size=hidden,\n",
    "            intermediate_size=hidden*hidden_expand,\n",
    "            num_attention_heads=nhead,\n",
    "            num_bert_layers=nlayers,\n",
    "            dropout=dropout,\n",
    "            output_attentions=False\n",
    "        )\n",
    "        self.output_attentions = output_attentions\n",
    "        self.bert = BertEncoder(self.config)\n",
    "    def forward(self, x:torch.Tensor)->tuple:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            (Tensor, [Tensor]): out[0] is the hidden layer output, \n",
    "              and out[1] is the output attention \n",
    "              if self.output_attentions==True\n",
    "        \"\"\"\n",
    "        return self.bert(\n",
    "            x,\n",
    "            output_attentions=self.output_attentions,\n",
    "            return_dict=False\n",
    "        )\n",
    "\n",
    "\n",
    "class _PseudoBertConfig:\n",
    "    def __init__(self, \n",
    "        hidden_size=256, \n",
    "        intermediate_size=1024,\n",
    "        num_attention_heads=8,\n",
    "        num_bert_layers=4,\n",
    "        dropout=0.1,\n",
    "        output_attentions=False,\n",
    "    ):\n",
    "        self.add_cross_attention = False\n",
    "        self.chunk_size_feed_forward = 0\n",
    "        self.is_decoder = False\n",
    "        self.seq_len_dim = 1\n",
    "        self.training = False\n",
    "        self.hidden_act = \"gelu\"\n",
    "        self.hidden_dropout_prob = dropout\n",
    "        self.attention_probs_dropout_prob = dropout\n",
    "        self.hidden_size = hidden_size\n",
    "        self.initializer_range = 0.02\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.layer_norm_eps = 1e-8\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.num_hidden_layers = num_bert_layers\n",
    "        self.output_attentions = output_attentions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
