{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp model.model_shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import peptdeep.model.building_block as building_block\n",
    "from peptdeep.model.model_interface import ModelInterface\n",
    "from peptdeep.model.featurize import (\n",
    "    get_ascii_indices, get_batch_mod_feature\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ASCII_NUM=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalar Regression Models for a Given Amino Acid Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class ScalarRegression_LSTM_Model_for_AASeq(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        *,\n",
    "        hidden_dim=256,\n",
    "        n_lstm_layers=4,\n",
    "        dropout=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "        self.nn = torch.nn.Sequential(\n",
    "            building_block.ascii_embedding(hidden_dim//4),\n",
    "            building_block.SeqCNN(hidden_dim//4),\n",
    "            self.dropout,\n",
    "            building_block.SeqLSTM(\n",
    "                hidden_dim, hidden_dim, \n",
    "                rnn_layer=n_lstm_layers\n",
    "            ),\n",
    "            building_block.SeqAttentionSum(hidden_dim),\n",
    "            self.dropout,\n",
    "            torch.nn.Linear(hidden_dim,64),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(64, 1),\n",
    "        )\n",
    "    def forward(self, aa_x):\n",
    "        return self.nn(aa_x).squeeze(-1)\n",
    "\n",
    "class ScalarRegression_Transformer_Model_for_AASeq(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        hidden_dim = 256,\n",
    "        nlayers = 4,\n",
    "        output_attentions=False,\n",
    "        dropout = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model based on a transformer Architecture from \n",
    "        Huggingface's BertEncoder class.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.input_nn =  torch.nn.Sequential(\n",
    "            building_block.ascii_embedding(hidden_dim),\n",
    "        )\n",
    "\n",
    "        self._output_attentions = output_attentions\n",
    "        \n",
    "        self.hidden_nn = building_block.HFace_Transformer_with_PositionalEncoder(\n",
    "            hidden_dim, nlayers=nlayers, dropout=dropout,\n",
    "            output_attentions=output_attentions\n",
    "        )\n",
    "\n",
    "        self.output_nn = torch.nn.Sequential(\n",
    "            building_block.SeqAttentionSum(hidden_dim),\n",
    "            torch.nn.PReLU(),\n",
    "            self.dropout,\n",
    "            torch.nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def output_attentions(self):\n",
    "        return self._output_attentions\n",
    "\n",
    "    @output_attentions.setter\n",
    "    def output_attentions(self, val:bool):\n",
    "        self._output_attentions = val\n",
    "        self.hidden_nn.output_attentions = val\n",
    "\n",
    "    def forward(self, aa_x):\n",
    "        aa_x = self.dropout(self.input_nn(aa_x))\n",
    "\n",
    "        aa_x = self.hidden_nn(aa_x)\n",
    "        if self.output_attentions:\n",
    "            self.attentions = aa_x[1]\n",
    "        else:\n",
    "            self.attentions = None\n",
    "        aa_x = self.dropout(aa_x[0])\n",
    "\n",
    "        return self.output_nn(aa_x).squeeze(1)\n",
    "\n",
    "class ScalarRegression_ModelInterface_for_AASeq(ModelInterface):\n",
    "    def __init__(self, \n",
    "        dropout=0.1,\n",
    "        model_class:torch.nn.Module=ScalarRegression_LSTM_Model_for_AASeq, #model defined above\n",
    "        device:str='gpu',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(device=device)\n",
    "        self.build(\n",
    "            model_class,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.loss_func = torch.nn.L1Loss() # for regression\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "    ):\n",
    "        self._predict_column_in_df = 'target_value_pred'\n",
    "        precursor_df[self._predict_column_in_df] = 0.\n",
    "        self.predict_df = precursor_df\n",
    "\n",
    "    def _get_features_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        aa_indices = self._as_tensor(\n",
    "            get_ascii_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            ), \n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        return aa_indices\n",
    "\n",
    "    def _get_targets_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor:\n",
    "        return self._as_tensor(\n",
    "            batch_df['target_value'].values, \n",
    "            dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a RT model for only sequences based on `ScalarRegression_LSTM_Model_for_AASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_value</th>\n",
       "      <th>target_value_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.199488</td>\n",
       "      <td>0.226986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.298671</td>\n",
       "      <td>0.226745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.357909</td>\n",
       "      <td>0.354989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.429315</td>\n",
       "      <td>0.484007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.466699</td>\n",
       "      <td>0.547663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.537784</td>\n",
       "      <td>0.668599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.710436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.764009</td>\n",
       "      <td>0.899760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.897775</td>\n",
       "      <td>1.030823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.162040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_value  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9      0.000000   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14      0.199488   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13      0.298671   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10      0.357909   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12      0.429315   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12      0.466699   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13      0.537784   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13      0.636728   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12      0.764009   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12      0.897775   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14      1.000000   \n",
       "\n",
       "    target_value_pred  \n",
       "0            0.000000  \n",
       "1            0.226986  \n",
       "2            0.226745  \n",
       "3            0.354989  \n",
       "4            0.484007  \n",
       "5            0.547663  \n",
       "6            0.668599  \n",
       "7            0.710436  \n",
       "8            0.899760  \n",
       "9            1.030823  \n",
       "10           1.162040  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_value'] = (\n",
    "    IRT_PEPTIDE_DF.irt-IRT_PEPTIDE_DF.irt.min()\n",
    ")/(IRT_PEPTIDE_DF.irt.max()-IRT_PEPTIDE_DF.irt.min())\n",
    "model = ScalarRegression_ModelInterface_for_AASeq(\n",
    "    model_class=ScalarRegression_LSTM_Model_for_AASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a RT model for only sequences based on `ScalarRegression_Transformer_Model_for_AASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_value</th>\n",
       "      <th>target_value_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.284259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.199488</td>\n",
       "      <td>0.570077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.298671</td>\n",
       "      <td>0.600805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.357909</td>\n",
       "      <td>0.545549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.429315</td>\n",
       "      <td>0.625066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.466699</td>\n",
       "      <td>0.642667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.537784</td>\n",
       "      <td>0.648241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.898216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.764009</td>\n",
       "      <td>0.907477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.897775</td>\n",
       "      <td>0.967381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.047851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_value  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9      0.000000   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14      0.199488   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13      0.298671   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10      0.357909   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12      0.429315   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12      0.466699   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13      0.537784   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13      0.636728   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12      0.764009   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12      0.897775   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14      1.000000   \n",
       "\n",
       "    target_value_pred  \n",
       "0            0.284259  \n",
       "1            0.570077  \n",
       "2            0.600805  \n",
       "3            0.545549  \n",
       "4            0.625066  \n",
       "5            0.642667  \n",
       "6            0.648241  \n",
       "7            0.898216  \n",
       "8            0.907477  \n",
       "9            0.967381  \n",
       "10           1.047851  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_value'] = (\n",
    "    IRT_PEPTIDE_DF.irt-IRT_PEPTIDE_DF.irt.min()\n",
    ")/(IRT_PEPTIDE_DF.irt.max()-IRT_PEPTIDE_DF.irt.min())\n",
    "model = ScalarRegression_ModelInterface_for_AASeq(\n",
    "    model_class=ScalarRegression_Transformer_Model_for_AASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Models for a Given Amino Acid Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BinaryClassification_LSTM_Model_for_AASeq(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        *,\n",
    "        hidden_dim=256,\n",
    "        n_lstm_layers=4,\n",
    "        dropout=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.nn = ScalarRegression_LSTM_Model_for_AASeq(\n",
    "            hidden_dim=hidden_dim, \n",
    "            input_dim=ASCII_NUM, \n",
    "            n_lstm_layers=n_lstm_layers,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "    def forward(self, aa_x):\n",
    "        return torch.sigmoid(self.nn(aa_x))\n",
    "\n",
    "class BinaryClassification_Transformer_Model_for_AASeq(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        hidden_dim = 256,\n",
    "        nlayers = 4,\n",
    "        output_attentions=False,\n",
    "        dropout = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model based on a transformer Architecture from \n",
    "        Huggingface's BertEncoder class.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.nn =  ScalarRegression_Transformer_Model_for_AASeq(\n",
    "            nlayers=nlayers,\n",
    "            input_dim=ASCII_NUM,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_attentions=output_attentions,\n",
    "            dropout=dropout,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def output_attentions(self):\n",
    "        return self._output_attentions\n",
    "\n",
    "    @output_attentions.setter\n",
    "    def output_attentions(self, val:bool):\n",
    "        self._output_attentions = val\n",
    "        self.hidden_nn.output_attentions = val\n",
    "\n",
    "    def forward(self, aa_x):\n",
    "        return torch.sigmoid(self.nn(aa_x))\n",
    "\n",
    "class BinaryClassification_ModelInterface_for_AASeq(ModelInterface):\n",
    "    def __init__(self, \n",
    "        dropout=0.1,\n",
    "        model_class:torch.nn.Module=BinaryClassification_LSTM_Model_for_AASeq, #model defined above\n",
    "        device:str='gpu',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Class to predict retention times from precursor dataframes.\n",
    "        \"\"\"\n",
    "        super().__init__(device=device)\n",
    "        self.build(\n",
    "            model_class,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.loss_func = torch.nn.BCELoss() # for binary classification\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "    ):\n",
    "        self._predict_column_in_df = 'target_prob_pred'\n",
    "        precursor_df[self._predict_column_in_df] = 0.\n",
    "        self.predict_df = precursor_df\n",
    "\n",
    "    def _get_features_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        aa_indices = self._as_tensor(\n",
    "            get_ascii_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            ), dtype=torch.long\n",
    "        )\n",
    "\n",
    "        return aa_indices\n",
    "\n",
    "    def _get_targets_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor:\n",
    "        return self._as_tensor(\n",
    "            batch_df['target_prob'].values, \n",
    "            dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A sequence classification model using `BinaryClassification_LSTM_Model_for_AASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_prob</th>\n",
       "      <th>target_prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.367720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.379180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.357393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_prob  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9            1   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14            1   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13            1   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10            1   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12            1   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12            1   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13            0   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13            0   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12            0   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12            0   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14            0   \n",
       "\n",
       "    target_prob_pred  \n",
       "0           0.992084  \n",
       "1           0.991962  \n",
       "2           0.992317  \n",
       "3           0.991497  \n",
       "4           0.991560  \n",
       "5           0.986580  \n",
       "6           0.365364  \n",
       "7           0.367720  \n",
       "8           0.379180  \n",
       "9           0.365868  \n",
       "10          0.357393  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_prob'] = 0\n",
    "IRT_PEPTIDE_DF.loc[:5,'target_prob']=1\n",
    "model = BinaryClassification_ModelInterface_for_AASeq(\n",
    "    model_class=BinaryClassification_LSTM_Model_for_AASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A sequence classification model using `BinaryClassification_LSTM_Model_for_AASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_prob</th>\n",
       "      <th>target_prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.968527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.955795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.126706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_prob  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9            1   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14            1   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13            1   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10            1   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12            1   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12            1   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13            0   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13            0   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12            0   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12            0   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14            0   \n",
       "\n",
       "    target_prob_pred  \n",
       "0           0.993336  \n",
       "1           0.987852  \n",
       "2           0.968527  \n",
       "3           0.991404  \n",
       "4           0.979454  \n",
       "5           0.955795  \n",
       "6           0.012674  \n",
       "7           0.126706  \n",
       "8           0.017562  \n",
       "9           0.012213  \n",
       "10          0.011547  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_prob'] = 0\n",
    "IRT_PEPTIDE_DF.loc[:5,'target_prob']=1\n",
    "model = BinaryClassification_ModelInterface_for_AASeq(\n",
    "    model_class=BinaryClassification_Transformer_Model_for_AASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=10)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalar Regression Models for Given Amino Acid Sequence and Site-specific PTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ScalarRegression_LSTM_Model_for_ModAASeq(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        *,\n",
    "        hidden_dim=256,\n",
    "        n_lstm_layers=4,\n",
    "        dropout=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.encoder_nn = building_block.Encoder_AsciiAA_Mod_CNN_LSTM_AttnSum(\n",
    "            hidden_dim,\n",
    "            n_lstm_layers=n_lstm_layers,\n",
    "        )\n",
    "        self.output_nn = torch.nn.Sequential(\n",
    "            self.dropout,\n",
    "            torch.nn.Linear(hidden_dim,64),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(64, 1),\n",
    "        )\n",
    "    def forward(self, aa_x, mod_x):\n",
    "        x = self.encoder_nn(aa_x, mod_x)\n",
    "        return self.output_nn(x).squeeze(-1)\n",
    "\n",
    "class ScalarRegression_Transformer_Model_for_ModAASeq(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        hidden_dim = 256,\n",
    "        nlayers = 4,\n",
    "        output_attentions=False,\n",
    "        dropout = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model based on a transformer Architecture from \n",
    "        Huggingface's BertEncoder class.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.input_nn = building_block.AA_Mod_Embedding(hidden_dim)\n",
    "\n",
    "        self._output_attentions = output_attentions\n",
    "        \n",
    "        self.hidden_nn = building_block.HFace_Transformer_with_PositionalEncoder(\n",
    "            hidden_dim, nlayers=nlayers, dropout=dropout,\n",
    "            output_attentions=output_attentions\n",
    "        )\n",
    "\n",
    "        self.output_nn = torch.nn.Sequential(\n",
    "            building_block.SeqAttentionSum(hidden_dim),\n",
    "            torch.nn.PReLU(),\n",
    "            self.dropout,\n",
    "            torch.nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def output_attentions(self):\n",
    "        return self._output_attentions\n",
    "\n",
    "    @output_attentions.setter\n",
    "    def output_attentions(self, val:bool):\n",
    "        self._output_attentions = val\n",
    "        self.hidden_nn.output_attentions = val\n",
    "\n",
    "    def forward(self, \n",
    "        aa_indices, \n",
    "        mod_x,\n",
    "    ):\n",
    "        x = self.dropout(self.input_nn(\n",
    "            aa_indices, mod_x\n",
    "        ))\n",
    "\n",
    "        hidden_x = self.hidden_nn(x)\n",
    "        if self.output_attentions:\n",
    "            self.attentions = hidden_x[1]\n",
    "        else:\n",
    "            self.attentions = None\n",
    "        x = self.dropout(hidden_x[0]+x*0.2)\n",
    "\n",
    "        return self.output_nn(x).squeeze(1)\n",
    "\n",
    "class ScalarRegression_ModelInterface_for_ModAASeq(ModelInterface):\n",
    "    def __init__(self, \n",
    "        dropout=0.1,\n",
    "        model_class:torch.nn.Module=ScalarRegression_LSTM_Model_for_ModAASeq, #model defined above\n",
    "        device:str='gpu',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(device=device)\n",
    "        self.build(\n",
    "            model_class,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.loss_func = torch.nn.L1Loss() # for regression\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "    ):\n",
    "        self._predict_column_in_df = 'target_value_pred'\n",
    "        precursor_df[self._predict_column_in_df] = 0.\n",
    "        self.predict_df = precursor_df\n",
    "\n",
    "    def _get_features_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        aa_indices = self._as_tensor(\n",
    "            get_ascii_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            ),\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        \n",
    "        mod_x = self._as_tensor(\n",
    "            get_batch_mod_feature(\n",
    "                batch_df\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return aa_indices, mod_x\n",
    "\n",
    "    def _get_targets_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor:\n",
    "        return self._as_tensor(\n",
    "            batch_df['target_value'].values, \n",
    "            dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar regression model (RT) with modified AA sequences using `ScalarRegression_LSTM_Model_for_ModAASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_value</th>\n",
       "      <th>target_value_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.199488</td>\n",
       "      <td>0.153369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.298671</td>\n",
       "      <td>0.217336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.357909</td>\n",
       "      <td>0.334083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.429315</td>\n",
       "      <td>0.331022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.466699</td>\n",
       "      <td>0.449149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.537784</td>\n",
       "      <td>0.500230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.556495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.764009</td>\n",
       "      <td>0.725871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.897775</td>\n",
       "      <td>0.913588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.014829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_value  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9      0.000000   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14      0.199488   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13      0.298671   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10      0.357909   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12      0.429315   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12      0.466699   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13      0.537784   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13      0.636728   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12      0.764009   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12      0.897775   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14      1.000000   \n",
       "\n",
       "    target_value_pred  \n",
       "0            0.023022  \n",
       "1            0.153369  \n",
       "2            0.217336  \n",
       "3            0.334083  \n",
       "4            0.331022  \n",
       "5            0.449149  \n",
       "6            0.500230  \n",
       "7            0.556495  \n",
       "8            0.725871  \n",
       "9            0.913588  \n",
       "10           1.014829  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_value'] = (\n",
    "    IRT_PEPTIDE_DF.irt-IRT_PEPTIDE_DF.irt.min()\n",
    ")/(IRT_PEPTIDE_DF.irt.max()-IRT_PEPTIDE_DF.irt.min())\n",
    "model = ScalarRegression_ModelInterface_for_ModAASeq(\n",
    "    model_class=ScalarRegression_LSTM_Model_for_ModAASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar regression model (RT) with modified AA sequences using `ScalarRegression_Transformer_Model_for_ModAASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_value</th>\n",
       "      <th>target_value_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.199488</td>\n",
       "      <td>0.350402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.298671</td>\n",
       "      <td>0.372654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.357909</td>\n",
       "      <td>0.352173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.429315</td>\n",
       "      <td>0.462331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.466699</td>\n",
       "      <td>0.509501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.537784</td>\n",
       "      <td>0.588974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.630189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.764009</td>\n",
       "      <td>0.705910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.897775</td>\n",
       "      <td>0.840132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_value  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9      0.000000   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14      0.199488   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13      0.298671   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10      0.357909   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12      0.429315   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12      0.466699   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13      0.537784   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13      0.636728   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12      0.764009   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12      0.897775   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14      1.000000   \n",
       "\n",
       "    target_value_pred  \n",
       "0            0.100091  \n",
       "1            0.350402  \n",
       "2            0.372654  \n",
       "3            0.352173  \n",
       "4            0.462331  \n",
       "5            0.509501  \n",
       "6            0.588974  \n",
       "7            0.630189  \n",
       "8            0.705910  \n",
       "9            0.840132  \n",
       "10           0.988775  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_value'] = (\n",
    "    IRT_PEPTIDE_DF.irt-IRT_PEPTIDE_DF.irt.min()\n",
    ")/(IRT_PEPTIDE_DF.irt.max()-IRT_PEPTIDE_DF.irt.min())\n",
    "model = ScalarRegression_ModelInterface_for_ModAASeq(\n",
    "    model_class=ScalarRegression_Transformer_Model_for_ModAASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=10)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Models for Given Amino Acid Sequence and Site-specific PTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BinaryClassification_LSTM_Model_for_ModAASeq(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        *,\n",
    "        hidden_dim=256,\n",
    "        n_lstm_layers=4,\n",
    "        dropout=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.nn = ScalarRegression_LSTM_Model_for_ModAASeq(\n",
    "            hidden_dim=hidden_dim,\n",
    "            n_lstm_layers=n_lstm_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, aa_x, mod_x):\n",
    "        return torch.sigmoid(self.nn(aa_x, mod_x))\n",
    "\n",
    "class BinaryClassification_Transformer_Model_for_ModAASeq(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        hidden_dim = 256,\n",
    "        nlayers = 4,\n",
    "        output_attentions=False,\n",
    "        dropout = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model based on a transformer Architecture from \n",
    "        Huggingface's BertEncoder class.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.nn = ScalarRegression_Transformer_Model_for_ModAASeq(\n",
    "            nlayers=nlayers,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_attentions=output_attentions,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def output_attentions(self):\n",
    "        return self._output_attentions\n",
    "\n",
    "    @output_attentions.setter\n",
    "    def output_attentions(self, val:bool):\n",
    "        self._output_attentions = val\n",
    "        self.hidden_nn.output_attentions = val\n",
    "\n",
    "    def forward(self, \n",
    "        aa_indices, \n",
    "        mod_x,\n",
    "    ):\n",
    "        return torch.sigmoid(self.nn(aa_indices, mod_x))\n",
    "\n",
    "class BinaryClassification_ModelInterface_for_ModAASeq(ModelInterface):\n",
    "    def __init__(self, \n",
    "        dropout=0.1,\n",
    "        model_class:torch.nn.Module=BinaryClassification_LSTM_Model_for_ModAASeq, #model defined above\n",
    "        device:str='gpu',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(device=device)\n",
    "        self.build(\n",
    "            model_class,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.loss_func = torch.nn.BCELoss() # for regression\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "    ):\n",
    "        self._predict_column_in_df = 'target_prob_pred'\n",
    "        precursor_df[self._predict_column_in_df] = 0.\n",
    "        self.predict_df = precursor_df\n",
    "\n",
    "    def _get_features_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "    ):\n",
    "        aa_indices = self._as_tensor(\n",
    "            get_ascii_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            ),\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        \n",
    "        mod_x = self._as_tensor(\n",
    "            get_batch_mod_feature(\n",
    "                batch_df\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return aa_indices, mod_x\n",
    "\n",
    "    def _get_targets_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor:\n",
    "        return self._as_tensor(\n",
    "            batch_df['target_prob'].values, \n",
    "            dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar regression model (RT) with modified AA sequences using `BinaryClassification_LSTM_Model_for_ModAASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_prob</th>\n",
       "      <th>target_prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.372550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.379109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.372425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.366102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_prob  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9            1   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14            1   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13            1   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10            1   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12            1   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12            1   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13            0   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13            0   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12            0   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12            0   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14            0   \n",
       "\n",
       "    target_prob_pred  \n",
       "0           0.990910  \n",
       "1           0.989390  \n",
       "2           0.990863  \n",
       "3           0.990191  \n",
       "4           0.987697  \n",
       "5           0.990062  \n",
       "6           0.371550  \n",
       "7           0.372550  \n",
       "8           0.379109  \n",
       "9           0.372425  \n",
       "10          0.366102  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_prob'] = 0\n",
    "IRT_PEPTIDE_DF.loc[:5,'target_prob']=1\n",
    "model = BinaryClassification_ModelInterface_for_ModAASeq(\n",
    "    model_class=BinaryClassification_LSTM_Model_for_ModAASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar regression model (RT) with modified AA sequences using `BinaryClassification_Transformer_Model_for_ModAASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_prob</th>\n",
       "      <th>target_prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_prob  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9            1   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14            1   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13            1   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10            1   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12            1   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12            1   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13            0   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13            0   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12            0   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12            0   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14            0   \n",
       "\n",
       "    target_prob_pred  \n",
       "0           0.994696  \n",
       "1           0.971599  \n",
       "2           0.990369  \n",
       "3           0.994455  \n",
       "4           0.987329  \n",
       "5           0.984665  \n",
       "6           0.033939  \n",
       "7           0.091140  \n",
       "8           0.014022  \n",
       "9           0.011016  \n",
       "10          0.009181  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_prob'] = 0\n",
    "IRT_PEPTIDE_DF.loc[:5,'target_prob']=1\n",
    "model = BinaryClassification_ModelInterface_for_ModAASeq(\n",
    "    model_class=BinaryClassification_Transformer_Model_for_ModAASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=10)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a3b27e141e49c996c9b863f8707e97aabd49c4a7e8445b9b783b34e4a21a9b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
