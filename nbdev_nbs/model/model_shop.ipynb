{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp model.model_shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import peptdeep.model.building_block as building_block\n",
    "from peptdeep.model.model_interface import ModelInterface\n",
    "from peptdeep.model.featurize import (\n",
    "    get_ascii_indices, get_batch_mod_feature\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ASCII_NUM=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalar Regression Models for a Given Amino Acid Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class ScalarRegression_LSTM_Model_for_AASeq(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        *,\n",
    "        hidden_dim=256,\n",
    "        n_lstm_layers=4,\n",
    "        dropout=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "        self.nn = torch.nn.Sequential(\n",
    "            building_block.ascii_embedding(hidden_dim//4),\n",
    "            building_block.SeqCNN(hidden_dim//4),\n",
    "            self.dropout,\n",
    "            building_block.SeqLSTM(\n",
    "                hidden_dim, hidden_dim, \n",
    "                rnn_layer=n_lstm_layers\n",
    "            ),\n",
    "            building_block.SeqAttentionSum(hidden_dim),\n",
    "            self.dropout,\n",
    "            torch.nn.Linear(hidden_dim,64),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(64, 1),\n",
    "        )\n",
    "    def forward(self, aa_x):\n",
    "        return self.nn(aa_x).squeeze(-1)\n",
    "\n",
    "class ScalarRegression_Transformer_Model_for_AASeq(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        hidden_dim = 256,\n",
    "        nlayers = 4,\n",
    "        output_attentions=False,\n",
    "        dropout = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model based on a transformer Architecture from \n",
    "        Huggingface's BertEncoder class.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.input_nn =  torch.nn.Sequential(\n",
    "            building_block.ascii_embedding(hidden_dim),\n",
    "        )\n",
    "\n",
    "        self.output_attentions = output_attentions\n",
    "        \n",
    "        self.hidden_nn = building_block.HFace_Transformer_with_PositionalEncoder(\n",
    "            hidden_dim, nlayers=nlayers, dropout=dropout,\n",
    "            output_attentions=output_attentions\n",
    "        )\n",
    "\n",
    "        self.output_nn = torch.nn.Sequential(\n",
    "            building_block.SeqAttentionSum(hidden_dim),\n",
    "            torch.nn.PReLU(),\n",
    "            self.dropout,\n",
    "            torch.nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def output_attentions(self)->bool:\n",
    "        return self._output_attentions\n",
    "\n",
    "    @output_attentions.setter\n",
    "    def output_attentions(self, val:bool):\n",
    "        self._output_attentions = val\n",
    "\n",
    "    def forward(self, aa_x):\n",
    "        aa_x = self.dropout(self.input_nn(aa_x))\n",
    "\n",
    "        aa_x = self.hidden_nn(aa_x)\n",
    "        if self.output_attentions:\n",
    "            self.attentions = aa_x[1]\n",
    "        else:\n",
    "            self.attentions = None\n",
    "        aa_x = self.dropout(aa_x[0])\n",
    "\n",
    "        return self.output_nn(aa_x).squeeze(1)\n",
    "\n",
    "class ScalarRegression_ModelInterface_for_AASeq(ModelInterface):\n",
    "    def __init__(self, \n",
    "        dropout=0.1,\n",
    "        model_class:torch.nn.Module=ScalarRegression_LSTM_Model_for_AASeq, #model defined above\n",
    "        device:str='gpu',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(device=device)\n",
    "        self.build(\n",
    "            model_class,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.loss_func = torch.nn.L1Loss() # for regression\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "    ):\n",
    "        self._predict_column_in_df = 'predicted_property'\n",
    "        precursor_df[self._predict_column_in_df] = 0.\n",
    "        self.predict_df = precursor_df\n",
    "\n",
    "    def _get_features_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        aa_indices = self._as_tensor(\n",
    "            get_ascii_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            ), \n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        return aa_indices\n",
    "\n",
    "    def _get_targets_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor:\n",
    "        return self._as_tensor(\n",
    "            batch_df['detected_property'].values, \n",
    "            dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a RT model for only sequences based on `ScalarRegression_LSTM_Model_for_AASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>detected_property</th>\n",
       "      <th>predicted_property</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.199488</td>\n",
       "      <td>0.203749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.298671</td>\n",
       "      <td>0.254368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.357909</td>\n",
       "      <td>0.398172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.429315</td>\n",
       "      <td>0.508226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.466699</td>\n",
       "      <td>0.472749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.537784</td>\n",
       "      <td>0.602823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.633547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.764009</td>\n",
       "      <td>0.941932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.897775</td>\n",
       "      <td>1.046042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.144919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  detected_property  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9           0.000000   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14           0.199488   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13           0.298671   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10           0.357909   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12           0.429315   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12           0.466699   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13           0.537784   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13           0.636728   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12           0.764009   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12           0.897775   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14           1.000000   \n",
       "\n",
       "    predicted_property  \n",
       "0             0.000000  \n",
       "1             0.203749  \n",
       "2             0.254368  \n",
       "3             0.398172  \n",
       "4             0.508226  \n",
       "5             0.472749  \n",
       "6             0.602823  \n",
       "7             0.633547  \n",
       "8             0.941932  \n",
       "9             1.046042  \n",
       "10            1.144919  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['detected_property'] = (\n",
    "    IRT_PEPTIDE_DF.irt-IRT_PEPTIDE_DF.irt.min()\n",
    ")/(IRT_PEPTIDE_DF.irt.max()-IRT_PEPTIDE_DF.irt.min())\n",
    "model = ScalarRegression_ModelInterface_for_AASeq(\n",
    "    model_class=ScalarRegression_LSTM_Model_for_AASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a RT model for only sequences based on `ScalarRegression_Transformer_Model_for_AASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>detected_property</th>\n",
       "      <th>predicted_property</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.199488</td>\n",
       "      <td>0.076221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.298671</td>\n",
       "      <td>0.163718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.357909</td>\n",
       "      <td>0.205459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.429315</td>\n",
       "      <td>0.233966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.466699</td>\n",
       "      <td>0.262998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.537784</td>\n",
       "      <td>0.323232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.407841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.764009</td>\n",
       "      <td>0.554401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.897775</td>\n",
       "      <td>0.605493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  detected_property  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9           0.000000   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14           0.199488   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13           0.298671   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10           0.357909   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12           0.429315   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12           0.466699   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13           0.537784   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13           0.636728   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12           0.764009   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12           0.897775   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14           1.000000   \n",
       "\n",
       "    predicted_property  \n",
       "0             0.005624  \n",
       "1             0.076221  \n",
       "2             0.163718  \n",
       "3             0.205459  \n",
       "4             0.233966  \n",
       "5             0.262998  \n",
       "6             0.323232  \n",
       "7             0.407841  \n",
       "8             0.554401  \n",
       "9             0.605493  \n",
       "10            0.677240  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['detected_property'] = (\n",
    "    IRT_PEPTIDE_DF.irt-IRT_PEPTIDE_DF.irt.min()\n",
    ")/(IRT_PEPTIDE_DF.irt.max()-IRT_PEPTIDE_DF.irt.min())\n",
    "model = ScalarRegression_ModelInterface_for_AASeq(\n",
    "    model_class=ScalarRegression_Transformer_Model_for_AASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Models for a Given Amino Acid Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BinaryClassification_LSTM_Model_for_AASeq(\n",
    "    ScalarRegression_LSTM_Model_for_AASeq\n",
    "):\n",
    "    def __init__(self, \n",
    "        *,\n",
    "        hidden_dim=256,\n",
    "        n_lstm_layers=4,\n",
    "        dropout=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            hidden_dim=hidden_dim,\n",
    "            n_lstm_layers=n_lstm_layers,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "    def forward(self, aa_x):\n",
    "        x = super().forward(aa_x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "class BinaryClassification_Transformer_Model_for_AASeq(\n",
    "    ScalarRegression_Transformer_Model_for_AASeq\n",
    "):\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        hidden_dim = 256,\n",
    "        nlayers = 4,\n",
    "        output_attentions=False,\n",
    "        dropout = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model based on a transformer Architecture from \n",
    "        Huggingface's BertEncoder class.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            nlayers=nlayers,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_attentions=output_attentions,\n",
    "            dropout=dropout,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def forward(self, aa_x):\n",
    "        x = super().forward(aa_x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "class BinaryClassification_ModelInterface_for_AASeq(ModelInterface):\n",
    "    def __init__(self, \n",
    "        dropout=0.1,\n",
    "        model_class:torch.nn.Module=BinaryClassification_LSTM_Model_for_AASeq, #model defined above\n",
    "        device:str='gpu',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Class to predict retention times from precursor dataframes.\n",
    "        \"\"\"\n",
    "        super().__init__(device=device)\n",
    "        self.build(\n",
    "            model_class,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.loss_func = torch.nn.BCELoss() # for binary classification\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "    ):\n",
    "        self._predict_column_in_df = 'predicted_prob'\n",
    "        precursor_df[self._predict_column_in_df] = 0.\n",
    "        self.predict_df = precursor_df\n",
    "\n",
    "    def _get_features_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        aa_indices = self._as_tensor(\n",
    "            get_ascii_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            ), dtype=torch.long\n",
    "        )\n",
    "\n",
    "        return aa_indices\n",
    "\n",
    "    def _get_targets_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor:\n",
    "        return self._as_tensor(\n",
    "            batch_df['detected_prob'].values, \n",
    "            dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A sequence classification model using `BinaryClassification_LSTM_Model_for_AASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>detected_prob</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.388740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.386249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.395431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.384820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.383687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  detected_prob  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9              1   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14              1   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13              1   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10              1   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12              1   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12              1   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13              0   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13              0   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12              0   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12              0   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14              0   \n",
       "\n",
       "    predicted_prob  \n",
       "0         0.989100  \n",
       "1         0.988890  \n",
       "2         0.989772  \n",
       "3         0.987212  \n",
       "4         0.987834  \n",
       "5         0.983028  \n",
       "6         0.388740  \n",
       "7         0.386249  \n",
       "8         0.395431  \n",
       "9         0.384820  \n",
       "10        0.383687  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['detected_prob'] = 0\n",
    "IRT_PEPTIDE_DF.loc[:5,'detected_prob']=1\n",
    "model = BinaryClassification_ModelInterface_for_AASeq(\n",
    "    model_class=BinaryClassification_LSTM_Model_for_AASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A sequence classification model using `BinaryClassification_LSTM_Model_for_AASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>detected_prob</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.982300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  detected_prob  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9              1   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14              1   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13              1   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10              1   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12              1   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12              1   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13              0   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13              0   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12              0   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12              0   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14              0   \n",
       "\n",
       "    predicted_prob  \n",
       "0         0.994008  \n",
       "1         0.987759  \n",
       "2         0.947251  \n",
       "3         0.993353  \n",
       "4         0.988444  \n",
       "5         0.982300  \n",
       "6         0.050207  \n",
       "7         0.035540  \n",
       "8         0.013822  \n",
       "9         0.010823  \n",
       "10        0.010823  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['detected_prob'] = 0\n",
    "IRT_PEPTIDE_DF.loc[:5,'detected_prob']=1\n",
    "model = BinaryClassification_ModelInterface_for_AASeq(\n",
    "    model_class=BinaryClassification_Transformer_Model_for_AASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=10)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalar Regression Models for Given Amino Acid Sequence and Site-specific PTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ScalarRegression_LSTM_Model_for_ModAASeq(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        *,\n",
    "        hidden_dim=256,\n",
    "        n_lstm_layers=4,\n",
    "        dropout=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.encoder_nn = building_block.Encoder_AsciiAA_Mod_CNN_LSTM_AttnSum(\n",
    "            hidden_dim,\n",
    "            n_lstm_layers=n_lstm_layers,\n",
    "        )\n",
    "        self.output_nn = torch.nn.Sequential(\n",
    "            self.dropout,\n",
    "            torch.nn.Linear(hidden_dim,64),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(64, 1),\n",
    "        )\n",
    "    def forward(self, aa_x, mod_x):\n",
    "        x = self.encoder_nn(aa_x, mod_x)\n",
    "        return self.output_nn(x).squeeze(-1)\n",
    "\n",
    "class ScalarRegression_Transformer_Model_for_ModAASeq(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        hidden_dim = 256,\n",
    "        nlayers = 4,\n",
    "        output_attentions=False,\n",
    "        dropout = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model based on a transformer Architecture from \n",
    "        Huggingface's BertEncoder class.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.input_nn = building_block.AA_Mod_Embedding(hidden_dim)\n",
    "\n",
    "        self._output_attentions = output_attentions\n",
    "        \n",
    "        self.hidden_nn = building_block.HFace_Transformer_with_PositionalEncoder(\n",
    "            hidden_dim, nlayers=nlayers, dropout=dropout,\n",
    "            output_attentions=output_attentions\n",
    "        )\n",
    "\n",
    "        self.output_nn = torch.nn.Sequential(\n",
    "            building_block.SeqAttentionSum(hidden_dim),\n",
    "            torch.nn.PReLU(),\n",
    "            self.dropout,\n",
    "            torch.nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def output_attentions(self)->bool:\n",
    "        return self._output_attentions\n",
    "\n",
    "    @output_attentions.setter\n",
    "    def output_attentions(self, val:bool):\n",
    "        self._output_attentions = val\n",
    "\n",
    "    def forward(self, \n",
    "        aa_indices, \n",
    "        mod_x,\n",
    "    ):\n",
    "        x = self.dropout(self.input_nn(\n",
    "            aa_indices, mod_x\n",
    "        ))\n",
    "\n",
    "        hidden_x = self.hidden_nn(x)\n",
    "        if self.output_attentions:\n",
    "            self.attentions = hidden_x[1]\n",
    "        else:\n",
    "            self.attentions = None\n",
    "        x = self.dropout(hidden_x[0]+x*0.2)\n",
    "\n",
    "        return self.output_nn(x).squeeze(1)\n",
    "\n",
    "class ScalarRegression_ModelInterface_for_ModAASeq(ModelInterface):\n",
    "    def __init__(self, \n",
    "        dropout=0.1,\n",
    "        model_class:torch.nn.Module=ScalarRegression_LSTM_Model_for_ModAASeq, #model defined above\n",
    "        device:str='gpu',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(device=device)\n",
    "        self.build(\n",
    "            model_class,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.loss_func = torch.nn.L1Loss() # for regression\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "    ):\n",
    "        self._predict_column_in_df = 'predicted_property'\n",
    "        precursor_df[self._predict_column_in_df] = 0.\n",
    "        self.predict_df = precursor_df\n",
    "\n",
    "    def _get_features_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        aa_indices = self._as_tensor(\n",
    "            get_ascii_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            ),\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        \n",
    "        mod_x = self._as_tensor(\n",
    "            get_batch_mod_feature(\n",
    "                batch_df\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return aa_indices, mod_x\n",
    "\n",
    "    def _get_targets_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor:\n",
    "        return self._as_tensor(\n",
    "            batch_df['detected_property'].values, \n",
    "            dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar regression model (RT) with modified AA sequences using `ScalarRegression_LSTM_Model_for_ModAASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>detected_property</th>\n",
       "      <th>predicted_property</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.199488</td>\n",
       "      <td>0.201225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.298671</td>\n",
       "      <td>0.198412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.357909</td>\n",
       "      <td>0.311826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.429315</td>\n",
       "      <td>0.323035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.466699</td>\n",
       "      <td>0.358762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.537784</td>\n",
       "      <td>0.512773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.683389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.764009</td>\n",
       "      <td>0.685461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.897775</td>\n",
       "      <td>0.898756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  detected_property  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9           0.000000   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14           0.199488   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13           0.298671   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10           0.357909   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12           0.429315   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12           0.466699   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13           0.537784   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13           0.636728   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12           0.764009   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12           0.897775   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14           1.000000   \n",
       "\n",
       "    predicted_property  \n",
       "0             0.050365  \n",
       "1             0.201225  \n",
       "2             0.198412  \n",
       "3             0.311826  \n",
       "4             0.323035  \n",
       "5             0.358762  \n",
       "6             0.512773  \n",
       "7             0.683389  \n",
       "8             0.685461  \n",
       "9             0.898756  \n",
       "10            0.958151  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['detected_property'] = (\n",
    "    IRT_PEPTIDE_DF.irt-IRT_PEPTIDE_DF.irt.min()\n",
    ")/(IRT_PEPTIDE_DF.irt.max()-IRT_PEPTIDE_DF.irt.min())\n",
    "model = ScalarRegression_ModelInterface_for_ModAASeq(\n",
    "    model_class=ScalarRegression_LSTM_Model_for_ModAASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar regression model (RT) with modified AA sequences using `ScalarRegression_Transformer_Model_for_ModAASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>detected_property</th>\n",
       "      <th>predicted_property</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.199488</td>\n",
       "      <td>0.473362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.298671</td>\n",
       "      <td>0.414256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.357909</td>\n",
       "      <td>0.419980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.429315</td>\n",
       "      <td>0.618031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.466699</td>\n",
       "      <td>0.682028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.537784</td>\n",
       "      <td>0.658774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.615138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.764009</td>\n",
       "      <td>0.969858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.897775</td>\n",
       "      <td>0.978745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.098058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  detected_property  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9           0.000000   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14           0.199488   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13           0.298671   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10           0.357909   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12           0.429315   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12           0.466699   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13           0.537784   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13           0.636728   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12           0.764009   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12           0.897775   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14           1.000000   \n",
       "\n",
       "    predicted_property  \n",
       "0             0.279440  \n",
       "1             0.473362  \n",
       "2             0.414256  \n",
       "3             0.419980  \n",
       "4             0.618031  \n",
       "5             0.682028  \n",
       "6             0.658774  \n",
       "7             0.615138  \n",
       "8             0.969858  \n",
       "9             0.978745  \n",
       "10            1.098058  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['detected_property'] = (\n",
    "    IRT_PEPTIDE_DF.irt-IRT_PEPTIDE_DF.irt.min()\n",
    ")/(IRT_PEPTIDE_DF.irt.max()-IRT_PEPTIDE_DF.irt.min())\n",
    "model = ScalarRegression_ModelInterface_for_ModAASeq(\n",
    "    model_class=ScalarRegression_Transformer_Model_for_ModAASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=10)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Models for Given Amino Acid Sequence and Site-specific PTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BinaryClassification_LSTM_Model_for_ModAASeq(\n",
    "    ScalarRegression_LSTM_Model_for_ModAASeq\n",
    "):\n",
    "    def __init__(self, \n",
    "        *,\n",
    "        hidden_dim=256,\n",
    "        n_lstm_layers=4,\n",
    "        dropout=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            hidden_dim=hidden_dim,\n",
    "            n_lstm_layers=n_lstm_layers,\n",
    "            dropout=dropout,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def forward(self, aa_x, mod_x):\n",
    "        x = super().forward(aa_x, mod_x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "class BinaryClassification_Transformer_Model_for_ModAASeq(\n",
    "    ScalarRegression_Transformer_Model_for_ModAASeq\n",
    "):\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        hidden_dim = 256,\n",
    "        nlayers = 4,\n",
    "        output_attentions=False,\n",
    "        dropout = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model based on a transformer Architecture from \n",
    "        Huggingface's BertEncoder class.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            nlayers=nlayers,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_attentions=output_attentions,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def output_attentions(self)->bool:\n",
    "        return self._output_attentions\n",
    "\n",
    "    @output_attentions.setter\n",
    "    def output_attentions(self, val:bool):\n",
    "        self._output_attentions = val\n",
    "\n",
    "    def forward(self, \n",
    "        aa_indices, \n",
    "        mod_x,\n",
    "    ):\n",
    "        x = super().forward(aa_indices, mod_x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "class BinaryClassification_ModelInterface_for_ModAASeq(ModelInterface):\n",
    "    def __init__(self, \n",
    "        dropout=0.1,\n",
    "        model_class:torch.nn.Module=BinaryClassification_LSTM_Model_for_ModAASeq, #model defined above\n",
    "        device:str='gpu',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(device=device)\n",
    "        self.build(\n",
    "            model_class,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.loss_func = torch.nn.BCELoss() # for regression\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "    ):\n",
    "        self._predict_column_in_df = 'predicted_prob'\n",
    "        precursor_df[self._predict_column_in_df] = 0.\n",
    "        self.predict_df = precursor_df\n",
    "\n",
    "    def _get_features_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "    ):\n",
    "        aa_indices = self._as_tensor(\n",
    "            get_ascii_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            ),\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        \n",
    "        mod_x = self._as_tensor(\n",
    "            get_batch_mod_feature(\n",
    "                batch_df\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return aa_indices, mod_x\n",
    "\n",
    "    def _get_targets_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor:\n",
    "        return self._as_tensor(\n",
    "            batch_df['detected_prob'].values, \n",
    "            dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar regression model (RT) with modified AA sequences using `BinaryClassification_LSTM_Model_for_ModAASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>detected_prob</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.354859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.367485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.361229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.358054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.352971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  detected_prob  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9              1   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14              1   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13              1   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10              1   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12              1   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12              1   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13              0   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13              0   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12              0   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12              0   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14              0   \n",
       "\n",
       "    predicted_prob  \n",
       "0         0.986498  \n",
       "1         0.984277  \n",
       "2         0.987346  \n",
       "3         0.985844  \n",
       "4         0.986121  \n",
       "5         0.985664  \n",
       "6         0.354859  \n",
       "7         0.367485  \n",
       "8         0.361229  \n",
       "9         0.358054  \n",
       "10        0.352971  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['detected_prob'] = 0\n",
    "IRT_PEPTIDE_DF.loc[:5,'detected_prob']=1\n",
    "model = BinaryClassification_ModelInterface_for_ModAASeq(\n",
    "    model_class=BinaryClassification_LSTM_Model_for_ModAASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar regression model (RT) with modified AA sequences using `BinaryClassification_Transformer_Model_for_ModAASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>detected_prob</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  detected_prob  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9              1   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14              1   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13              1   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10              1   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12              1   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12              1   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13              0   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13              0   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12              0   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12              0   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14              0   \n",
       "\n",
       "    predicted_prob  \n",
       "0         0.994057  \n",
       "1         0.993531  \n",
       "2         0.991094  \n",
       "3         0.994169  \n",
       "4         0.992342  \n",
       "5         0.992439  \n",
       "6         0.007014  \n",
       "7         0.021107  \n",
       "8         0.007093  \n",
       "9         0.006821  \n",
       "10        0.014188  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['detected_prob'] = 0\n",
    "IRT_PEPTIDE_DF.loc[:5,'detected_prob']=1\n",
    "model = BinaryClassification_ModelInterface_for_ModAASeq(\n",
    "    model_class=BinaryClassification_Transformer_Model_for_ModAASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=10)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
