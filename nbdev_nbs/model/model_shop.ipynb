{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp model.model_shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import peptdeep.model.building_block as building_block\n",
    "from peptdeep.model.model_interface import ModelInterface\n",
    "from peptdeep.model.featurize import (\n",
    "    get_ascii_indices, get_batch_mod_feature\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ASCII_NUM=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalar Regression Models for a Given Amino Acid Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class ScalarRegression_LSTM_Model_for_AASeq(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        *,\n",
    "        hidden_dim=256,\n",
    "        n_lstm_layers=4,\n",
    "        dropout=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "        self.nn = torch.nn.Sequential(\n",
    "            building_block.ascii_embedding(hidden_dim//4),\n",
    "            building_block.SeqCNN(hidden_dim//4),\n",
    "            self.dropout,\n",
    "            building_block.SeqLSTM(\n",
    "                hidden_dim, hidden_dim, \n",
    "                rnn_layer=n_lstm_layers\n",
    "            ),\n",
    "            building_block.SeqAttentionSum(hidden_dim),\n",
    "            self.dropout,\n",
    "            torch.nn.Linear(hidden_dim,64),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(64, 1),\n",
    "        )\n",
    "    def forward(self, aa_x):\n",
    "        return self.nn(aa_x).squeeze(-1)\n",
    "\n",
    "class ScalarRegression_Transformer_Model_for_AASeq(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        hidden_dim = 256,\n",
    "        nlayers = 4,\n",
    "        output_attentions=False,\n",
    "        dropout = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model based on a transformer Architecture from \n",
    "        Huggingface's BertEncoder class.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.input_nn =  torch.nn.Sequential(\n",
    "            building_block.ascii_embedding(hidden_dim),\n",
    "        )\n",
    "\n",
    "        self._output_attentions = output_attentions\n",
    "        \n",
    "        self.hidden_nn = building_block.HFace_Transformer_with_PositionalEncoder(\n",
    "            hidden_dim, nlayers=nlayers, dropout=dropout,\n",
    "            output_attentions=output_attentions\n",
    "        )\n",
    "\n",
    "        self.output_nn = torch.nn.Sequential(\n",
    "            building_block.SeqAttentionSum(hidden_dim),\n",
    "            torch.nn.PReLU(),\n",
    "            self.dropout,\n",
    "            torch.nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def output_attentions(self):\n",
    "        return self._output_attentions\n",
    "\n",
    "    @output_attentions.setter\n",
    "    def output_attentions(self, val:bool):\n",
    "        self._output_attentions = val\n",
    "        self.hidden_nn.output_attentions = val\n",
    "\n",
    "    def forward(self, aa_x):\n",
    "        aa_x = self.dropout(self.input_nn(aa_x))\n",
    "\n",
    "        aa_x = self.hidden_nn(aa_x)\n",
    "        if self.output_attentions:\n",
    "            self.attentions = aa_x[1]\n",
    "        else:\n",
    "            self.attentions = None\n",
    "        aa_x = self.dropout(aa_x[0])\n",
    "\n",
    "        return self.output_nn(aa_x).squeeze(1)\n",
    "\n",
    "class ScalarRegression_ModelInterface_for_AASeq(ModelInterface):\n",
    "    def __init__(self, \n",
    "        dropout=0.1,\n",
    "        model_class:torch.nn.Module=ScalarRegression_LSTM_Model_for_AASeq, #model defined above\n",
    "        device:str='gpu',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(device=device)\n",
    "        self.build(\n",
    "            model_class,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.loss_func = torch.nn.L1Loss() # for regression\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "    ):\n",
    "        self._predict_column_in_df = 'target_value_pred'\n",
    "        precursor_df[self._predict_column_in_df] = 0.\n",
    "        self.predict_df = precursor_df\n",
    "\n",
    "    def _get_features_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        aa_indices = self._as_tensor(\n",
    "            get_ascii_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            ), \n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        return aa_indices\n",
    "\n",
    "    def _get_targets_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor:\n",
    "        return self._as_tensor(\n",
    "            batch_df['target_value'].values, \n",
    "            dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a RT model for only sequences based on `ScalarRegression_LSTM_Model_for_AASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_value</th>\n",
       "      <th>target_value_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.199488</td>\n",
       "      <td>0.192163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.298671</td>\n",
       "      <td>0.285212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.357909</td>\n",
       "      <td>0.297688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.429315</td>\n",
       "      <td>0.400290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.466699</td>\n",
       "      <td>0.454063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.537784</td>\n",
       "      <td>0.476768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.643109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.764009</td>\n",
       "      <td>0.748537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.897775</td>\n",
       "      <td>0.887803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_value  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9      0.000000   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14      0.199488   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13      0.298671   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10      0.357909   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12      0.429315   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12      0.466699   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13      0.537784   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13      0.636728   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12      0.764009   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12      0.897775   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14      1.000000   \n",
       "\n",
       "    target_value_pred  \n",
       "0            0.000994  \n",
       "1            0.192163  \n",
       "2            0.285212  \n",
       "3            0.297688  \n",
       "4            0.400290  \n",
       "5            0.454063  \n",
       "6            0.476768  \n",
       "7            0.643109  \n",
       "8            0.748537  \n",
       "9            0.887803  \n",
       "10           0.872553  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_value'] = (\n",
    "    IRT_PEPTIDE_DF.irt-IRT_PEPTIDE_DF.irt.min()\n",
    ")/(IRT_PEPTIDE_DF.irt.max()-IRT_PEPTIDE_DF.irt.min())\n",
    "model = ScalarRegression_ModelInterface_for_AASeq(\n",
    "    model_class=ScalarRegression_LSTM_Model_for_AASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a RT model for only sequences based on `ScalarRegression_Transformer_Model_for_AASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_value</th>\n",
       "      <th>target_value_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.199488</td>\n",
       "      <td>0.487597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.298671</td>\n",
       "      <td>0.307094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.357909</td>\n",
       "      <td>0.600564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.429315</td>\n",
       "      <td>0.517983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.466699</td>\n",
       "      <td>0.513337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.537784</td>\n",
       "      <td>0.826682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.747432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.764009</td>\n",
       "      <td>0.814937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.897775</td>\n",
       "      <td>0.879203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.210588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_value  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9      0.000000   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14      0.199488   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13      0.298671   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10      0.357909   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12      0.429315   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12      0.466699   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13      0.537784   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13      0.636728   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12      0.764009   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12      0.897775   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14      1.000000   \n",
       "\n",
       "    target_value_pred  \n",
       "0            0.244017  \n",
       "1            0.487597  \n",
       "2            0.307094  \n",
       "3            0.600564  \n",
       "4            0.517983  \n",
       "5            0.513337  \n",
       "6            0.826682  \n",
       "7            0.747432  \n",
       "8            0.814937  \n",
       "9            0.879203  \n",
       "10           1.210588  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_value'] = (\n",
    "    IRT_PEPTIDE_DF.irt-IRT_PEPTIDE_DF.irt.min()\n",
    ")/(IRT_PEPTIDE_DF.irt.max()-IRT_PEPTIDE_DF.irt.min())\n",
    "model = ScalarRegression_ModelInterface_for_AASeq(\n",
    "    model_class=ScalarRegression_Transformer_Model_for_AASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Models for a Given Amino Acid Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BinaryClassification_LSTM_Model_for_AASeq(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        *,\n",
    "        hidden_dim=256,\n",
    "        n_lstm_layers=4,\n",
    "        dropout=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.nn = torch.nn.Sequential(\n",
    "            ScalarRegression_LSTM_Model_for_AASeq(\n",
    "                hidden_dim=hidden_dim, \n",
    "                input_dim=ASCII_NUM, \n",
    "                n_lstm_layers=n_lstm_layers,\n",
    "                dropout=dropout,\n",
    "            ),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, aa_x):\n",
    "        return self.nn(aa_x)\n",
    "\n",
    "class BinaryClassification_Transformer_Model_for_AASeq(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        hidden_dim = 256,\n",
    "        nlayers = 4,\n",
    "        output_attentions=False,\n",
    "        dropout = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model based on a transformer Architecture from \n",
    "        Huggingface's BertEncoder class.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.nn =  torch.nn.Sequential(\n",
    "            ScalarRegression_Transformer_Model_for_AASeq(\n",
    "                nlayers=nlayers,\n",
    "                input_dim=ASCII_NUM,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_attentions=output_attentions,\n",
    "                dropout=dropout,\n",
    "                **kwargs,\n",
    "            ),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def output_attentions(self):\n",
    "        return self._output_attentions\n",
    "\n",
    "    @output_attentions.setter\n",
    "    def output_attentions(self, val:bool):\n",
    "        self._output_attentions = val\n",
    "        self.hidden_nn.output_attentions = val\n",
    "\n",
    "    def forward(self, aa_x):\n",
    "        return self.nn(aa_x)\n",
    "\n",
    "class BinaryClassification_ModelInterface_for_AASeq(ModelInterface):\n",
    "    def __init__(self, \n",
    "        dropout=0.1,\n",
    "        model_class:torch.nn.Module=BinaryClassification_LSTM_Model_for_AASeq, #model defined above\n",
    "        device:str='gpu',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Class to predict retention times from precursor dataframes.\n",
    "        \"\"\"\n",
    "        super().__init__(device=device)\n",
    "        self.build(\n",
    "            model_class,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.loss_func = torch.nn.BCELoss() # for binary classification\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "    ):\n",
    "        self._predict_column_in_df = 'target_prob_pred'\n",
    "        precursor_df[self._predict_column_in_df] = 0.\n",
    "        self.predict_df = precursor_df\n",
    "\n",
    "    def _get_features_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        aa_indices = self._as_tensor(\n",
    "            get_ascii_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            ), dtype=torch.long\n",
    "        )\n",
    "\n",
    "        return aa_indices\n",
    "\n",
    "    def _get_targets_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor:\n",
    "        return self._as_tensor(\n",
    "            batch_df['target_prob'].values, \n",
    "            dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A sequence classification model using `BinaryClassification_LSTM_Model_for_AASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_prob</th>\n",
       "      <th>target_prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.398900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.406135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.408582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.401338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.395050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_prob  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9            1   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14            1   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13            1   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10            1   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12            1   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12            1   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13            0   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13            0   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12            0   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12            0   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14            0   \n",
       "\n",
       "    target_prob_pred  \n",
       "0           0.993328  \n",
       "1           0.991818  \n",
       "2           0.993159  \n",
       "3           0.993384  \n",
       "4           0.992593  \n",
       "5           0.991249  \n",
       "6           0.398900  \n",
       "7           0.406135  \n",
       "8           0.408582  \n",
       "9           0.401338  \n",
       "10          0.395050  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_prob'] = 0\n",
    "IRT_PEPTIDE_DF.loc[:5,'target_prob']=1\n",
    "model = BinaryClassification_ModelInterface_for_AASeq(\n",
    "    model_class=BinaryClassification_LSTM_Model_for_AASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A sequence classification model using `BinaryClassification_LSTM_Model_for_AASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_prob</th>\n",
       "      <th>target_prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_prob  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9            1   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14            1   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13            1   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10            1   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12            1   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12            1   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13            0   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13            0   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12            0   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12            0   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14            0   \n",
       "\n",
       "    target_prob_pred  \n",
       "0           0.993672  \n",
       "1           0.987666  \n",
       "2           0.931523  \n",
       "3           0.992653  \n",
       "4           0.986995  \n",
       "5           0.983034  \n",
       "6           0.111750  \n",
       "7           0.064402  \n",
       "8           0.022789  \n",
       "9           0.015627  \n",
       "10          0.014961  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_prob'] = 0\n",
    "IRT_PEPTIDE_DF.loc[:5,'target_prob']=1\n",
    "model = BinaryClassification_ModelInterface_for_AASeq(\n",
    "    model_class=BinaryClassification_Transformer_Model_for_AASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=10)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalar Regression Models for Given Amino Acid Sequence and Site-specific PTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ScalarRegression_LSTM_Model_for_ModAASeq(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        *,\n",
    "        hidden_dim=256,\n",
    "        n_lstm_layers=4,\n",
    "        dropout=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.encoder_nn = building_block.Encoder_AsciiAA_Mod_CNN_LSTM_AttnSum(\n",
    "            hidden_dim,\n",
    "            n_lstm_layers=n_lstm_layers,\n",
    "        )\n",
    "        self.output_nn = torch.nn.Sequential(\n",
    "            self.dropout,\n",
    "            torch.nn.Linear(hidden_dim,64),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(64, 1),\n",
    "        )\n",
    "    def forward(self, aa_x, mod_x):\n",
    "        x = self.encoder_nn(aa_x, mod_x)\n",
    "        return self.output_nn(x).squeeze(-1)\n",
    "\n",
    "class ScalarRegression_Transformer_Model_for_ModAASeq(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        hidden_dim = 256,\n",
    "        nlayers = 4,\n",
    "        output_attentions=False,\n",
    "        dropout = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model based on a transformer Architecture from \n",
    "        Huggingface's BertEncoder class.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.input_nn = building_block.AA_Mod_Embedding(hidden_dim)\n",
    "\n",
    "        self._output_attentions = output_attentions\n",
    "        \n",
    "        self.hidden_nn = building_block.HFace_Transformer_with_PositionalEncoder(\n",
    "            hidden_dim, nlayers=nlayers, dropout=dropout,\n",
    "            output_attentions=output_attentions\n",
    "        )\n",
    "\n",
    "        self.output_nn = torch.nn.Sequential(\n",
    "            building_block.SeqAttentionSum(hidden_dim),\n",
    "            torch.nn.PReLU(),\n",
    "            self.dropout,\n",
    "            torch.nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def output_attentions(self):\n",
    "        return self._output_attentions\n",
    "\n",
    "    @output_attentions.setter\n",
    "    def output_attentions(self, val:bool):\n",
    "        self._output_attentions = val\n",
    "        self.hidden_nn.output_attentions = val\n",
    "\n",
    "    def forward(self, \n",
    "        aa_indices, \n",
    "        mod_x,\n",
    "    ):\n",
    "        x = self.dropout(self.input_nn(\n",
    "            aa_indices, mod_x\n",
    "        ))\n",
    "\n",
    "        hidden_x = self.hidden_nn(x)\n",
    "        if self.output_attentions:\n",
    "            self.attentions = hidden_x[1]\n",
    "        else:\n",
    "            self.attentions = None\n",
    "        x = self.dropout(hidden_x[0]+x*0.2)\n",
    "\n",
    "        return self.output_nn(x).squeeze(1)\n",
    "\n",
    "class ScalarRegression_ModelInterface_for_ModAASeq(ModelInterface):\n",
    "    def __init__(self, \n",
    "        dropout=0.1,\n",
    "        model_class:torch.nn.Module=ScalarRegression_LSTM_Model_for_ModAASeq, #model defined above\n",
    "        device:str='gpu',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(device=device)\n",
    "        self.build(\n",
    "            model_class,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.loss_func = torch.nn.L1Loss() # for regression\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "    ):\n",
    "        self._predict_column_in_df = 'target_value_pred'\n",
    "        precursor_df[self._predict_column_in_df] = 0.\n",
    "        self.predict_df = precursor_df\n",
    "\n",
    "    def _get_features_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        aa_indices = self._as_tensor(\n",
    "            get_ascii_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            ),\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        \n",
    "        mod_x = self._as_tensor(\n",
    "            get_batch_mod_feature(\n",
    "                batch_df\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return aa_indices, mod_x\n",
    "\n",
    "    def _get_targets_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor:\n",
    "        return self._as_tensor(\n",
    "            batch_df['target_value'].values, \n",
    "            dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar regression model (RT) with modified AA sequences using `ScalarRegression_LSTM_Model_for_ModAASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_value</th>\n",
       "      <th>target_value_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.199488</td>\n",
       "      <td>0.203807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.298671</td>\n",
       "      <td>0.207264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.357909</td>\n",
       "      <td>0.307607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.429315</td>\n",
       "      <td>0.392669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.466699</td>\n",
       "      <td>0.434279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.537784</td>\n",
       "      <td>0.647267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.639735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.764009</td>\n",
       "      <td>0.770797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.897775</td>\n",
       "      <td>0.960279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.063865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_value  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9      0.000000   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14      0.199488   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13      0.298671   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10      0.357909   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12      0.429315   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12      0.466699   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13      0.537784   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13      0.636728   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12      0.764009   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12      0.897775   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14      1.000000   \n",
       "\n",
       "    target_value_pred  \n",
       "0            0.031287  \n",
       "1            0.203807  \n",
       "2            0.207264  \n",
       "3            0.307607  \n",
       "4            0.392669  \n",
       "5            0.434279  \n",
       "6            0.647267  \n",
       "7            0.639735  \n",
       "8            0.770797  \n",
       "9            0.960279  \n",
       "10           1.063865  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_value'] = (\n",
    "    IRT_PEPTIDE_DF.irt-IRT_PEPTIDE_DF.irt.min()\n",
    ")/(IRT_PEPTIDE_DF.irt.max()-IRT_PEPTIDE_DF.irt.min())\n",
    "model = ScalarRegression_ModelInterface_for_ModAASeq(\n",
    "    model_class=ScalarRegression_LSTM_Model_for_ModAASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar regression model (RT) with modified AA sequences using `ScalarRegression_Transformer_Model_for_ModAASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_value</th>\n",
       "      <th>target_value_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.199488</td>\n",
       "      <td>0.494886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.298671</td>\n",
       "      <td>0.617833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.357909</td>\n",
       "      <td>0.587855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.429315</td>\n",
       "      <td>0.601013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.466699</td>\n",
       "      <td>0.635832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.537784</td>\n",
       "      <td>0.908289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.952417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.764009</td>\n",
       "      <td>0.693814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.897775</td>\n",
       "      <td>0.946233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_value  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9      0.000000   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14      0.199488   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13      0.298671   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10      0.357909   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12      0.429315   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12      0.466699   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13      0.537784   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13      0.636728   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12      0.764009   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12      0.897775   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14      1.000000   \n",
       "\n",
       "    target_value_pred  \n",
       "0            0.204853  \n",
       "1            0.494886  \n",
       "2            0.617833  \n",
       "3            0.587855  \n",
       "4            0.601013  \n",
       "5            0.635832  \n",
       "6            0.908289  \n",
       "7            0.952417  \n",
       "8            0.693814  \n",
       "9            0.946233  \n",
       "10           0.806592  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_value'] = (\n",
    "    IRT_PEPTIDE_DF.irt-IRT_PEPTIDE_DF.irt.min()\n",
    ")/(IRT_PEPTIDE_DF.irt.max()-IRT_PEPTIDE_DF.irt.min())\n",
    "model = ScalarRegression_ModelInterface_for_ModAASeq(\n",
    "    model_class=ScalarRegression_Transformer_Model_for_ModAASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=10)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Models for Given Amino Acid Sequence and Site-specific PTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BinaryClassification_LSTM_Model_for_ModAASeq(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        *,\n",
    "        hidden_dim=256,\n",
    "        n_lstm_layers=4,\n",
    "        dropout=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.nn = ScalarRegression_LSTM_Model_for_ModAASeq(\n",
    "            hidden_dim=hidden_dim,\n",
    "            n_lstm_layers=n_lstm_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, aa_x, mod_x):\n",
    "        return torch.sigmoid(self.nn(aa_x, mod_x))\n",
    "\n",
    "class BinaryClassification_Transformer_Model_for_ModAASeq(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        hidden_dim = 256,\n",
    "        nlayers = 4,\n",
    "        output_attentions=False,\n",
    "        dropout = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model based on a transformer Architecture from \n",
    "        Huggingface's BertEncoder class.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.nn = ScalarRegression_Transformer_Model_for_ModAASeq(\n",
    "            nlayers=nlayers,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_attentions=output_attentions,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def output_attentions(self):\n",
    "        return self._output_attentions\n",
    "\n",
    "    @output_attentions.setter\n",
    "    def output_attentions(self, val:bool):\n",
    "        self._output_attentions = val\n",
    "        self.hidden_nn.output_attentions = val\n",
    "\n",
    "    def forward(self, \n",
    "        aa_indices, \n",
    "        mod_x,\n",
    "    ):\n",
    "        return torch.sigmoid(self.nn(aa_indices, mod_x))\n",
    "\n",
    "class BinaryClassification_ModelInterface_for_ModAASeq(ModelInterface):\n",
    "    def __init__(self, \n",
    "        dropout=0.1,\n",
    "        model_class:torch.nn.Module=BinaryClassification_LSTM_Model_for_ModAASeq, #model defined above\n",
    "        device:str='gpu',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(device=device)\n",
    "        self.build(\n",
    "            model_class,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.loss_func = torch.nn.BCELoss() # for regression\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "    ):\n",
    "        self._predict_column_in_df = 'target_prob_pred'\n",
    "        precursor_df[self._predict_column_in_df] = 0.\n",
    "        self.predict_df = precursor_df\n",
    "\n",
    "    def _get_features_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "    ):\n",
    "        aa_indices = self._as_tensor(\n",
    "            get_ascii_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            ),\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        \n",
    "        mod_x = self._as_tensor(\n",
    "            get_batch_mod_feature(\n",
    "                batch_df\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return aa_indices, mod_x\n",
    "\n",
    "    def _get_targets_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor:\n",
    "        return self._as_tensor(\n",
    "            batch_df['target_prob'].values, \n",
    "            dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar regression model (RT) with modified AA sequences using `BinaryClassification_LSTM_Model_for_ModAASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_prob</th>\n",
       "      <th>target_prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.386843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.385768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.393007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.389048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.383659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_prob  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9            1   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14            1   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13            1   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10            1   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12            1   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12            1   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13            0   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13            0   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12            0   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12            0   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14            0   \n",
       "\n",
       "    target_prob_pred  \n",
       "0           0.993227  \n",
       "1           0.992641  \n",
       "2           0.993642  \n",
       "3           0.992739  \n",
       "4           0.992071  \n",
       "5           0.991699  \n",
       "6           0.386843  \n",
       "7           0.385768  \n",
       "8           0.393007  \n",
       "9           0.389048  \n",
       "10          0.383659  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_prob'] = 0\n",
    "IRT_PEPTIDE_DF.loc[:5,'target_prob']=1\n",
    "model = BinaryClassification_ModelInterface_for_ModAASeq(\n",
    "    model_class=BinaryClassification_LSTM_Model_for_ModAASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar regression model (RT) with modified AA sequences using `BinaryClassification_Transformer_Model_for_ModAASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_prob</th>\n",
       "      <th>target_prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.981500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.967895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.194570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_prob  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9            1   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14            1   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13            1   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10            1   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12            1   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12            1   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13            0   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13            0   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12            0   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12            0   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14            0   \n",
       "\n",
       "    target_prob_pred  \n",
       "0           0.992182  \n",
       "1           0.978105  \n",
       "2           0.989655  \n",
       "3           0.991840  \n",
       "4           0.981500  \n",
       "5           0.967895  \n",
       "6           0.157435  \n",
       "7           0.194570  \n",
       "8           0.034146  \n",
       "9           0.022817  \n",
       "10          0.019280  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_prob'] = 0\n",
    "IRT_PEPTIDE_DF.loc[:5,'target_prob']=1\n",
    "model = BinaryClassification_ModelInterface_for_ModAASeq(\n",
    "    model_class=BinaryClassification_Transformer_Model_for_ModAASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=10)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a3b27e141e49c996c9b863f8707e97aabd49c4a7e8445b9b783b34e4a21a9b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
