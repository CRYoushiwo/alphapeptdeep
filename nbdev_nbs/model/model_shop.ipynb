{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp model.model_shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import peptdeep.model.building_block as building_block\n",
    "from peptdeep.model.model_interface import ModelInterface\n",
    "from peptdeep.model.featurize import (\n",
    "    get_ascii_indices, get_batch_mod_feature\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ASCII_NUM=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalar Regression Models for a Given Amino Acid Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class ScalarRegression_LSTM_Model_for_AASeq(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        *,\n",
    "        hidden_dim=256,\n",
    "        n_lstm_layers=4,\n",
    "        dropout=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "        self.nn = torch.nn.Sequential(\n",
    "            building_block.ascii_embedding(hidden_dim//4),\n",
    "            building_block.SeqCNN(hidden_dim//4),\n",
    "            self.dropout,\n",
    "            building_block.SeqLSTM(\n",
    "                hidden_dim, hidden_dim, \n",
    "                rnn_layer=n_lstm_layers\n",
    "            ),\n",
    "            building_block.SeqAttentionSum(hidden_dim),\n",
    "            self.dropout,\n",
    "            torch.nn.Linear(hidden_dim,64),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(64, 1),\n",
    "        )\n",
    "    def forward(self, aa_x):\n",
    "        return self.nn(aa_x).squeeze(-1)\n",
    "\n",
    "class ScalarRegression_Transformer_Model_for_AASeq(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        hidden_dim = 256,\n",
    "        nlayers = 4,\n",
    "        output_attentions=False,\n",
    "        dropout = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model based on a transformer Architecture from \n",
    "        Huggingface's BertEncoder class.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.input_nn =  torch.nn.Sequential(\n",
    "            building_block.ascii_embedding(hidden_dim),\n",
    "        )\n",
    "\n",
    "        self._output_attentions = output_attentions\n",
    "        \n",
    "        self.hidden_nn = building_block.HFace_Transformer_with_PositionalEncoder(\n",
    "            hidden_dim, nlayers=nlayers, dropout=dropout,\n",
    "            output_attentions=output_attentions\n",
    "        )\n",
    "\n",
    "        self.output_nn = torch.nn.Sequential(\n",
    "            building_block.SeqAttentionSum(hidden_dim),\n",
    "            torch.nn.PReLU(),\n",
    "            self.dropout,\n",
    "            torch.nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def output_attentions(self):\n",
    "        return self._output_attentions\n",
    "\n",
    "    @output_attentions.setter\n",
    "    def output_attentions(self, val:bool):\n",
    "        self._output_attentions = val\n",
    "        self.hidden_nn.output_attentions = val\n",
    "\n",
    "    def forward(self, aa_x):\n",
    "        aa_x = self.dropout(self.input_nn(aa_x))\n",
    "\n",
    "        aa_x = self.hidden_nn(aa_x)\n",
    "        if self.output_attentions:\n",
    "            self.attentions = aa_x[1]\n",
    "        else:\n",
    "            self.attentions = None\n",
    "        aa_x = self.dropout(aa_x[0])\n",
    "\n",
    "        return self.output_nn(aa_x).squeeze(1)\n",
    "\n",
    "class ScalarRegression_ModelInterface_for_AASeq(ModelInterface):\n",
    "    def __init__(self, \n",
    "        dropout=0.1,\n",
    "        model_class:torch.nn.Module=ScalarRegression_LSTM_Model_for_AASeq, #model defined above\n",
    "        device:str='gpu',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(device=device)\n",
    "        self.build(\n",
    "            model_class,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.loss_func = torch.nn.L1Loss() # for regression\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "    ):\n",
    "        self._predict_column_in_df = 'target_value_pred'\n",
    "        precursor_df[self._predict_column_in_df] = 0.\n",
    "        self.predict_df = precursor_df\n",
    "\n",
    "    def _get_features_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        aa_indices = self._as_tensor(\n",
    "            get_ascii_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            ), \n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        return aa_indices\n",
    "\n",
    "    def _get_targets_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor:\n",
    "        return self._as_tensor(\n",
    "            batch_df['target_value'].values, \n",
    "            dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a RT model for only sequences based on `ScalarRegression_LSTM_Model_for_AASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_value</th>\n",
       "      <th>target_value_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.199488</td>\n",
       "      <td>0.270292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.298671</td>\n",
       "      <td>0.312048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.357909</td>\n",
       "      <td>0.375588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.429315</td>\n",
       "      <td>0.511878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.466699</td>\n",
       "      <td>0.567923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.537784</td>\n",
       "      <td>0.811736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.687210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.764009</td>\n",
       "      <td>0.610351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.897775</td>\n",
       "      <td>0.827414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_value  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9      0.000000   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14      0.199488   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13      0.298671   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10      0.357909   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12      0.429315   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12      0.466699   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13      0.537784   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13      0.636728   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12      0.764009   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12      0.897775   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14      1.000000   \n",
       "\n",
       "    target_value_pred  \n",
       "0            0.000000  \n",
       "1            0.270292  \n",
       "2            0.312048  \n",
       "3            0.375588  \n",
       "4            0.511878  \n",
       "5            0.567923  \n",
       "6            0.811736  \n",
       "7            0.687210  \n",
       "8            0.610351  \n",
       "9            0.827414  \n",
       "10           0.974178  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_value'] = (\n",
    "    IRT_PEPTIDE_DF.irt-IRT_PEPTIDE_DF.irt.min()\n",
    ")/(IRT_PEPTIDE_DF.irt.max()-IRT_PEPTIDE_DF.irt.min())\n",
    "model = ScalarRegression_ModelInterface_for_AASeq(\n",
    "    model_class=ScalarRegression_LSTM_Model_for_AASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_value</th>\n",
       "      <th>target_value_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.199488</td>\n",
       "      <td>0.270292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.298671</td>\n",
       "      <td>0.312048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.357909</td>\n",
       "      <td>0.375588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.429315</td>\n",
       "      <td>0.511878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.466699</td>\n",
       "      <td>0.567923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.537784</td>\n",
       "      <td>0.811736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.687210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.764009</td>\n",
       "      <td>0.610351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.897775</td>\n",
       "      <td>0.827414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_value  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9      0.000000   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14      0.199488   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13      0.298671   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10      0.357909   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12      0.429315   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12      0.466699   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13      0.537784   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13      0.636728   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12      0.764009   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12      0.897775   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14      1.000000   \n",
       "\n",
       "    target_value_pred  \n",
       "0            0.000000  \n",
       "1            0.270292  \n",
       "2            0.312048  \n",
       "3            0.375588  \n",
       "4            0.511878  \n",
       "5            0.567923  \n",
       "6            0.811736  \n",
       "7            0.687210  \n",
       "8            0.610351  \n",
       "9            0.827414  \n",
       "10           0.974178  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "model.predict_mp(IRT_PEPTIDE_DF, mp_batch_size=2, process_num=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a RT model for only sequences based on `ScalarRegression_Transformer_Model_for_AASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_value</th>\n",
       "      <th>target_value_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.199488</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.298671</td>\n",
       "      <td>0.066876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.357909</td>\n",
       "      <td>0.122096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.429315</td>\n",
       "      <td>0.196392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.466699</td>\n",
       "      <td>0.244039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.537784</td>\n",
       "      <td>0.112480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.353008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.764009</td>\n",
       "      <td>0.590600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.897775</td>\n",
       "      <td>0.647294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_value  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9      0.000000   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14      0.199488   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13      0.298671   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10      0.357909   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12      0.429315   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12      0.466699   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13      0.537784   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13      0.636728   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12      0.764009   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12      0.897775   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14      1.000000   \n",
       "\n",
       "    target_value_pred  \n",
       "0            0.000000  \n",
       "1            0.000000  \n",
       "2            0.066876  \n",
       "3            0.122096  \n",
       "4            0.196392  \n",
       "5            0.244039  \n",
       "6            0.112480  \n",
       "7            0.353008  \n",
       "8            0.590600  \n",
       "9            0.647294  \n",
       "10           0.686098  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_value'] = (\n",
    "    IRT_PEPTIDE_DF.irt-IRT_PEPTIDE_DF.irt.min()\n",
    ")/(IRT_PEPTIDE_DF.irt.max()-IRT_PEPTIDE_DF.irt.min())\n",
    "model = ScalarRegression_ModelInterface_for_AASeq(\n",
    "    model_class=ScalarRegression_Transformer_Model_for_AASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Models for a Given Amino Acid Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BinaryClassification_LSTM_Model_for_AASeq(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        *,\n",
    "        hidden_dim=256,\n",
    "        n_lstm_layers=4,\n",
    "        dropout=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.nn = torch.nn.Sequential(\n",
    "            ScalarRegression_LSTM_Model_for_AASeq(\n",
    "                hidden_dim=hidden_dim, \n",
    "                input_dim=ASCII_NUM, \n",
    "                n_lstm_layers=n_lstm_layers,\n",
    "                dropout=dropout,\n",
    "            ),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, aa_x):\n",
    "        return self.nn(aa_x)\n",
    "\n",
    "class BinaryClassification_Transformer_Model_for_AASeq(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        hidden_dim = 256,\n",
    "        nlayers = 4,\n",
    "        output_attentions=False,\n",
    "        dropout = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model based on a transformer Architecture from \n",
    "        Huggingface's BertEncoder class.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.nn =  torch.nn.Sequential(\n",
    "            ScalarRegression_Transformer_Model_for_AASeq(\n",
    "                nlayers=nlayers,\n",
    "                input_dim=ASCII_NUM,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_attentions=output_attentions,\n",
    "                dropout=dropout,\n",
    "                **kwargs,\n",
    "            ),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def output_attentions(self):\n",
    "        return self._output_attentions\n",
    "\n",
    "    @output_attentions.setter\n",
    "    def output_attentions(self, val:bool):\n",
    "        self._output_attentions = val\n",
    "        self.hidden_nn.output_attentions = val\n",
    "\n",
    "    def forward(self, aa_x):\n",
    "        return self.nn(aa_x)\n",
    "\n",
    "class BinaryClassification_ModelInterface_for_AASeq(ModelInterface):\n",
    "    def __init__(self, \n",
    "        dropout=0.1,\n",
    "        model_class:torch.nn.Module=BinaryClassification_LSTM_Model_for_AASeq, #model defined above\n",
    "        device:str='gpu',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Class to predict retention times from precursor dataframes.\n",
    "        \"\"\"\n",
    "        super().__init__(device=device)\n",
    "        self.build(\n",
    "            model_class,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.loss_func = torch.nn.BCELoss() # for binary classification\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "    ):\n",
    "        self._predict_column_in_df = 'target_prob_pred'\n",
    "        precursor_df[self._predict_column_in_df] = 0.\n",
    "        self.predict_df = precursor_df\n",
    "\n",
    "    def _get_features_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        aa_indices = self._as_tensor(\n",
    "            get_ascii_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            ), dtype=torch.long\n",
    "        )\n",
    "\n",
    "        return aa_indices\n",
    "\n",
    "    def _get_targets_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor:\n",
    "        return self._as_tensor(\n",
    "            batch_df['target_prob'].values, \n",
    "            dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A sequence classification model using `BinaryClassification_LSTM_Model_for_AASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_prob</th>\n",
       "      <th>target_prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.373829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.381207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.387663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.369978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_prob  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9            1   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14            1   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13            1   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10            1   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12            1   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12            1   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13            0   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13            0   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12            0   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12            0   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14            0   \n",
       "\n",
       "    target_prob_pred  \n",
       "0           0.994553  \n",
       "1           0.993269  \n",
       "2           0.994685  \n",
       "3           0.994273  \n",
       "4           0.992981  \n",
       "5           0.992346  \n",
       "6           0.373829  \n",
       "7           0.381207  \n",
       "8           0.387663  \n",
       "9           0.380410  \n",
       "10          0.369978  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_prob'] = 0\n",
    "IRT_PEPTIDE_DF.loc[:5,'target_prob']=1\n",
    "model = BinaryClassification_ModelInterface_for_AASeq(\n",
    "    model_class=BinaryClassification_LSTM_Model_for_AASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A sequence classification model using `BinaryClassification_LSTM_Model_for_AASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_prob</th>\n",
       "      <th>target_prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_prob  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9            1   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14            1   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13            1   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10            1   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12            1   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12            1   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13            0   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13            0   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12            0   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12            0   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14            0   \n",
       "\n",
       "    target_prob_pred  \n",
       "0           0.994852  \n",
       "1           0.986813  \n",
       "2           0.978719  \n",
       "3           0.993586  \n",
       "4           0.987523  \n",
       "5           0.986699  \n",
       "6           0.014846  \n",
       "7           0.021635  \n",
       "8           0.010523  \n",
       "9           0.009125  \n",
       "10          0.008429  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_prob'] = 0\n",
    "IRT_PEPTIDE_DF.loc[:5,'target_prob']=1\n",
    "model = BinaryClassification_ModelInterface_for_AASeq(\n",
    "    model_class=BinaryClassification_Transformer_Model_for_AASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=10)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalar Regression Models for Given Amino Acid Sequence and Site-specific PTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ScalarRegression_LSTM_Model_for_ModAASeq(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        *,\n",
    "        hidden_dim=256,\n",
    "        n_lstm_layers=4,\n",
    "        dropout=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.encoder_nn = building_block.Encoder_AsciiAA_Mod_CNN_LSTM_AttnSum(\n",
    "            hidden_dim,\n",
    "            n_lstm_layers=n_lstm_layers,\n",
    "        )\n",
    "        self.output_nn = torch.nn.Sequential(\n",
    "            self.dropout,\n",
    "            torch.nn.Linear(hidden_dim,64),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(64, 1),\n",
    "        )\n",
    "    def forward(self, aa_x, mod_x):\n",
    "        x = self.encoder_nn(aa_x, mod_x)\n",
    "        return self.output_nn(x).squeeze(-1)\n",
    "\n",
    "class ScalarRegression_Transformer_Model_for_ModAASeq(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        hidden_dim = 256,\n",
    "        nlayers = 4,\n",
    "        output_attentions=False,\n",
    "        dropout = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model based on a transformer Architecture from \n",
    "        Huggingface's BertEncoder class.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.input_nn = building_block.AA_Mod_Embedding(hidden_dim)\n",
    "\n",
    "        self._output_attentions = output_attentions\n",
    "        \n",
    "        self.hidden_nn = building_block.HFace_Transformer_with_PositionalEncoder(\n",
    "            hidden_dim, nlayers=nlayers, dropout=dropout,\n",
    "            output_attentions=output_attentions\n",
    "        )\n",
    "\n",
    "        self.output_nn = torch.nn.Sequential(\n",
    "            building_block.SeqAttentionSum(hidden_dim),\n",
    "            torch.nn.PReLU(),\n",
    "            self.dropout,\n",
    "            torch.nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def output_attentions(self):\n",
    "        return self._output_attentions\n",
    "\n",
    "    @output_attentions.setter\n",
    "    def output_attentions(self, val:bool):\n",
    "        self._output_attentions = val\n",
    "        self.hidden_nn.output_attentions = val\n",
    "\n",
    "    def forward(self, \n",
    "        aa_indices, \n",
    "        mod_x,\n",
    "    ):\n",
    "        x = self.dropout(self.input_nn(\n",
    "            aa_indices, mod_x\n",
    "        ))\n",
    "\n",
    "        hidden_x = self.hidden_nn(x)\n",
    "        if self.output_attentions:\n",
    "            self.attentions = hidden_x[1]\n",
    "        else:\n",
    "            self.attentions = None\n",
    "        x = self.dropout(hidden_x[0]+x*0.2)\n",
    "\n",
    "        return self.output_nn(x).squeeze(1)\n",
    "\n",
    "class ScalarRegression_ModelInterface_for_ModAASeq(ModelInterface):\n",
    "    def __init__(self, \n",
    "        dropout=0.1,\n",
    "        model_class:torch.nn.Module=ScalarRegression_LSTM_Model_for_ModAASeq, #model defined above\n",
    "        device:str='gpu',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(device=device)\n",
    "        self.build(\n",
    "            model_class,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.loss_func = torch.nn.L1Loss() # for regression\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "    ):\n",
    "        self._predict_column_in_df = 'target_value_pred'\n",
    "        precursor_df[self._predict_column_in_df] = 0.\n",
    "        self.predict_df = precursor_df\n",
    "\n",
    "    def _get_features_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        aa_indices = self._as_tensor(\n",
    "            get_ascii_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            ),\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        \n",
    "        mod_x = self._as_tensor(\n",
    "            get_batch_mod_feature(\n",
    "                batch_df\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return aa_indices, mod_x\n",
    "\n",
    "    def _get_targets_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor:\n",
    "        return self._as_tensor(\n",
    "            batch_df['target_value'].values, \n",
    "            dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar regression model (RT) with modified AA sequences using `ScalarRegression_LSTM_Model_for_ModAASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_value</th>\n",
       "      <th>target_value_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.199488</td>\n",
       "      <td>0.176670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.298671</td>\n",
       "      <td>0.240738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.357909</td>\n",
       "      <td>0.358938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.429315</td>\n",
       "      <td>0.320344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.466699</td>\n",
       "      <td>0.405891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.537784</td>\n",
       "      <td>0.569023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.555376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.764009</td>\n",
       "      <td>0.823821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.897775</td>\n",
       "      <td>0.939385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_value  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9      0.000000   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14      0.199488   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13      0.298671   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10      0.357909   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12      0.429315   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12      0.466699   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13      0.537784   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13      0.636728   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12      0.764009   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12      0.897775   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14      1.000000   \n",
       "\n",
       "    target_value_pred  \n",
       "0            0.002815  \n",
       "1            0.176670  \n",
       "2            0.240738  \n",
       "3            0.358938  \n",
       "4            0.320344  \n",
       "5            0.405891  \n",
       "6            0.569023  \n",
       "7            0.555376  \n",
       "8            0.823821  \n",
       "9            0.939385  \n",
       "10           0.894696  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_value'] = (\n",
    "    IRT_PEPTIDE_DF.irt-IRT_PEPTIDE_DF.irt.min()\n",
    ")/(IRT_PEPTIDE_DF.irt.max()-IRT_PEPTIDE_DF.irt.min())\n",
    "model = ScalarRegression_ModelInterface_for_ModAASeq(\n",
    "    model_class=ScalarRegression_LSTM_Model_for_ModAASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar regression model (RT) with modified AA sequences using `ScalarRegression_Transformer_Model_for_ModAASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_value</th>\n",
       "      <th>target_value_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.199488</td>\n",
       "      <td>0.093673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.298671</td>\n",
       "      <td>0.285840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.357909</td>\n",
       "      <td>0.372704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.429315</td>\n",
       "      <td>0.433030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.466699</td>\n",
       "      <td>0.371391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.537784</td>\n",
       "      <td>0.618134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.665806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.764009</td>\n",
       "      <td>0.814970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.897775</td>\n",
       "      <td>0.890673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.873607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_value  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9      0.000000   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14      0.199488   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13      0.298671   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10      0.357909   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12      0.429315   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12      0.466699   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13      0.537784   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13      0.636728   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12      0.764009   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12      0.897775   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14      1.000000   \n",
       "\n",
       "    target_value_pred  \n",
       "0            0.000000  \n",
       "1            0.093673  \n",
       "2            0.285840  \n",
       "3            0.372704  \n",
       "4            0.433030  \n",
       "5            0.371391  \n",
       "6            0.618134  \n",
       "7            0.665806  \n",
       "8            0.814970  \n",
       "9            0.890673  \n",
       "10           0.873607  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_value'] = (\n",
    "    IRT_PEPTIDE_DF.irt-IRT_PEPTIDE_DF.irt.min()\n",
    ")/(IRT_PEPTIDE_DF.irt.max()-IRT_PEPTIDE_DF.irt.min())\n",
    "model = ScalarRegression_ModelInterface_for_ModAASeq(\n",
    "    model_class=ScalarRegression_Transformer_Model_for_ModAASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=10)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Models for Given Amino Acid Sequence and Site-specific PTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BinaryClassification_LSTM_Model_for_ModAASeq(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        *,\n",
    "        hidden_dim=256,\n",
    "        n_lstm_layers=4,\n",
    "        dropout=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.nn = ScalarRegression_LSTM_Model_for_ModAASeq(\n",
    "            hidden_dim=hidden_dim,\n",
    "            n_lstm_layers=n_lstm_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, aa_x, mod_x):\n",
    "        return torch.sigmoid(self.nn(aa_x, mod_x))\n",
    "\n",
    "class BinaryClassification_Transformer_Model_for_ModAASeq(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        hidden_dim = 256,\n",
    "        nlayers = 4,\n",
    "        output_attentions=False,\n",
    "        dropout = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model based on a transformer Architecture from \n",
    "        Huggingface's BertEncoder class.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.nn = ScalarRegression_Transformer_Model_for_ModAASeq(\n",
    "            nlayers=nlayers,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_attentions=output_attentions,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def output_attentions(self):\n",
    "        return self._output_attentions\n",
    "\n",
    "    @output_attentions.setter\n",
    "    def output_attentions(self, val:bool):\n",
    "        self._output_attentions = val\n",
    "        self.hidden_nn.output_attentions = val\n",
    "\n",
    "    def forward(self, \n",
    "        aa_indices, \n",
    "        mod_x,\n",
    "    ):\n",
    "        return torch.sigmoid(self.nn(aa_indices, mod_x))\n",
    "\n",
    "class BinaryClassification_ModelInterface_for_ModAASeq(ModelInterface):\n",
    "    def __init__(self, \n",
    "        dropout=0.1,\n",
    "        model_class:torch.nn.Module=BinaryClassification_LSTM_Model_for_ModAASeq, #model defined above\n",
    "        device:str='gpu',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(device=device)\n",
    "        self.build(\n",
    "            model_class,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.loss_func = torch.nn.BCELoss() # for regression\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "    ):\n",
    "        self._predict_column_in_df = 'target_prob_pred'\n",
    "        precursor_df[self._predict_column_in_df] = 0.\n",
    "        self.predict_df = precursor_df\n",
    "\n",
    "    def _get_features_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "    ):\n",
    "        aa_indices = self._as_tensor(\n",
    "            get_ascii_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            ),\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        \n",
    "        mod_x = self._as_tensor(\n",
    "            get_batch_mod_feature(\n",
    "                batch_df\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return aa_indices, mod_x\n",
    "\n",
    "    def _get_targets_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor:\n",
    "        return self._as_tensor(\n",
    "            batch_df['target_prob'].values, \n",
    "            dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar regression model (RT) with modified AA sequences using `BinaryClassification_LSTM_Model_for_ModAASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_prob</th>\n",
       "      <th>target_prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.409278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.412872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.411099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.406247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_prob  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9            1   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14            1   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13            1   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10            1   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12            1   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12            1   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13            0   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13            0   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12            0   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12            0   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14            0   \n",
       "\n",
       "    target_prob_pred  \n",
       "0           0.993448  \n",
       "1           0.991897  \n",
       "2           0.993917  \n",
       "3           0.993438  \n",
       "4           0.991815  \n",
       "5           0.992453  \n",
       "6           0.409278  \n",
       "7           0.416397  \n",
       "8           0.412872  \n",
       "9           0.411099  \n",
       "10          0.406247  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_prob'] = 0\n",
    "IRT_PEPTIDE_DF.loc[:5,'target_prob']=1\n",
    "model = BinaryClassification_ModelInterface_for_ModAASeq(\n",
    "    model_class=BinaryClassification_LSTM_Model_for_ModAASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=20)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar regression model (RT) with modified AA sequences using `BinaryClassification_Transformer_Model_for_ModAASeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_prob</th>\n",
       "      <th>target_prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.982783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.063267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_prob  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9            1   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14            1   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13            1   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10            1   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12            1   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12            1   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13            0   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13            0   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12            0   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12            0   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14            0   \n",
       "\n",
       "    target_prob_pred  \n",
       "0           0.993029  \n",
       "1           0.982783  \n",
       "2           0.983086  \n",
       "3           0.992445  \n",
       "4           0.984391  \n",
       "5           0.977889  \n",
       "6           0.036614  \n",
       "7           0.063267  \n",
       "8           0.011384  \n",
       "9           0.009429  \n",
       "10          0.009761  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "\n",
    "IRT_PEPTIDE_DF=IRT_PEPTIDE_DF.copy()\n",
    "IRT_PEPTIDE_DF['target_prob'] = 0\n",
    "IRT_PEPTIDE_DF.loc[:5,'target_prob']=1\n",
    "model = BinaryClassification_ModelInterface_for_ModAASeq(\n",
    "    model_class=BinaryClassification_Transformer_Model_for_ModAASeq\n",
    ")\n",
    "model.train(IRT_PEPTIDE_DF, epoch=10)\n",
    "model.predict(IRT_PEPTIDE_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>target_prob</th>\n",
       "      <th>target_prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.982783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.063267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA  target_prob  \\\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9            1   \n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14            1   \n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13            1   \n",
       "3       YILAGVENSK  RT-pep d   19.79                  10            1   \n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12            1   \n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12            1   \n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13            0   \n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13            0   \n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12            0   \n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12            0   \n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14            0   \n",
       "\n",
       "    target_prob_pred  \n",
       "0           0.993029  \n",
       "1           0.982783  \n",
       "2           0.983086  \n",
       "3           0.992445  \n",
       "4           0.984391  \n",
       "5           0.977889  \n",
       "6           0.036614  \n",
       "7           0.063267  \n",
       "8           0.011384  \n",
       "9           0.009429  \n",
       "10          0.009761  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "model.predict_mp(IRT_PEPTIDE_DF, mp_batch_size=2, process_num=2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a3b27e141e49c996c9b863f8707e97aabd49c4a7e8445b9b783b34e4a21a9b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
