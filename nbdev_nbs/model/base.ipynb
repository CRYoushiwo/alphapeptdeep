{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp model.base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from typing import IO, Tuple, List, Union\n",
    "from alphabase.yaml_utils import save_yaml\n",
    "from alphadeep._settings import model_const"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelImplBase\n",
    "The base model for operations of all models, it does not contains the model (torch.nn.Module), but just provides some common APIs, including `load()` to load models, `save()` to save modles, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ModelImplBase(object):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if 'GPU' in kwargs:\n",
    "            self.use_GPU(kwargs['GPU'])\n",
    "        else:\n",
    "            self.use_GPU(True)\n",
    "\n",
    "    def use_GPU(self, GPU=True):\n",
    "        if not torch.cuda.is_available():\n",
    "            GPU=False\n",
    "        self.device = torch.device('cuda' if GPU else 'cpu')\n",
    "\n",
    "    def init_train(self, lr=0.001):\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.loss_func = torch.nn.L1Loss()\n",
    "\n",
    "    def build(self,\n",
    "        model_class: torch.nn.Module,\n",
    "        lr = 0.001,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.model = model_class(**kwargs)\n",
    "        self.model.to(self.device)\n",
    "        self.init_train(lr)\n",
    "\n",
    "    def get_parameter_num(self):\n",
    "        return np.sum([p.numel() for p in self.model.parameters()])\n",
    "\n",
    "    def save(self, save_as):\n",
    "        dir = os.path.dirname(save_as)\n",
    "        if not dir: dir = './'\n",
    "        if not os.path.exists(dir): os.makedirs(dir)\n",
    "        torch.save(self.model.state_dict(), save_as)\n",
    "        with open(save_as+'.txt','w') as f: f.write(str(self.model))\n",
    "        save_yaml(save_as+'.model_const.yaml', model_const)\n",
    "\n",
    "    def _load_model_file(self, stream):\n",
    "        self.model.load_state_dict(torch.load(\n",
    "            stream, map_location=self.device)\n",
    "        )\n",
    "\n",
    "    def load(\n",
    "        self,\n",
    "        model_file: Tuple[str, IO],\n",
    "        model_name_in_zip: str = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if isinstance(model_file, str):\n",
    "            # We may release all models (msms, rt, ccs, ...) in a single zip file\n",
    "            if model_file.lower().endswith('.zip'):\n",
    "                with ZipFile(model_file, 'rb') as model_zip:\n",
    "                    with model_zip.open(model_name_in_zip) as pt_file:\n",
    "                        self._load_model_file(pt_file)\n",
    "            else:\n",
    "                with open(model_file,'rb') as pt_file:\n",
    "                    self._load_model_file(pt_file)\n",
    "        else:\n",
    "            self._load_model_file(model_file)\n",
    "\n",
    "    def _train_one_batch(\n",
    "        self, \n",
    "        targets:Union[torch.Tensor,List[torch.Tensor]], \n",
    "        *features,\n",
    "    ):\n",
    "        self.optimizer.zero_grad()\n",
    "        predicts = self.model(*[fea.to(self.device) for fea in features])\n",
    "        if isinstance(targets, list):\n",
    "            # predicts must be a list or tuple as well\n",
    "            cost = self.loss_func(\n",
    "                predicts,\n",
    "                [t.to(self.device) for t in targets]\n",
    "            )\n",
    "        else:\n",
    "            cost = self.loss_func(predicts, targets.to(self.device))\n",
    "        cost.backward()\n",
    "        self.optimizer.step()\n",
    "        return cost.item()\n",
    "\n",
    "    def _predict_one_batch(self,\n",
    "        *features\n",
    "    ):\n",
    "        predicts = self.model(*[fea.to(self.device) for fea in features])\n",
    "        if isinstance(predicts, torch.Tensor):\n",
    "            return predicts.cpu().detach().numpy()\n",
    "        else:\n",
    "            return [p.cpu().detach().numpy() for p in predicts]\n",
    "\n",
    "    def _get_targets_from_batch_df(self,\n",
    "        batch_df:pd.DataFrame,\n",
    "        nAA, **kwargs,\n",
    "    )->Union[torch.Tensor,List]:\n",
    "        raise NotImplementedError(\n",
    "            'Must implement _get_targets_from_batch_df() method'\n",
    "        )\n",
    "\n",
    "    def _get_features_from_batch_df(self,\n",
    "        batch_df:pd.DataFrame,\n",
    "        nAA, **kwargs,\n",
    "    )->Tuple[torch.Tensor]:\n",
    "        raise NotImplementedError(\n",
    "            'Must implement _get_features_from_batch_df() method'\n",
    "        )\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame, \n",
    "        **kwargs\n",
    "    ):\n",
    "        '''\n",
    "        This method must create a `self.predict_df` dataframe.\n",
    "        '''\n",
    "        self.predict_df = pd.DataFrame()\n",
    "\n",
    "    def _prepare_train_data_df(self,\n",
    "        precursor_df:pd.DataFrame, \n",
    "        **kwargs\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "    def _set_batch_predict_data(self,\n",
    "        batch_df:pd.DataFrame,\n",
    "        predicts:Union[torch.Tensor, List],\n",
    "        **kwargs\n",
    "    ):\n",
    "        raise NotImplementedError(\n",
    "            'Must implement _set_batch_predict_data_df() method'\n",
    "        )\n",
    "\n",
    "    def train(self,\n",
    "        precursor_df: pd.DataFrame,\n",
    "        batch_size=1024, \n",
    "        epoch=20, \n",
    "        verbose=False,\n",
    "        verbose_each_epoch=True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self._prepare_train_data_df(precursor_df, **kwargs)\n",
    "        self.model.train()\n",
    "\n",
    "        for epoch in range(epoch):\n",
    "            batch_cost = []\n",
    "            _grouped = list(precursor_df.sample(frac=1).groupby('nAA'))\n",
    "            rnd_nAA = np.random.permutation(len(_grouped))\n",
    "            if verbose_each_epoch:\n",
    "                batch_tqdm = tqdm(rnd_nAA)\n",
    "            else:\n",
    "                batch_tqdm = rnd_nAA\n",
    "            for i_group in batch_tqdm:\n",
    "                nAA, df_group = _grouped[i_group]\n",
    "                df_group = df_group.reset_index(drop=True)\n",
    "                for i in range(0, len(df_group), batch_size):\n",
    "                    batch_end = i+batch_size-1 # DataFrame.loc[start:end] inlcudes the end\n",
    "\n",
    "                    batch_df = df_group.loc[i:batch_end,:]\n",
    "                    targets = self._get_targets_from_batch_df(batch_df,nAA,**kargs)\n",
    "                    features = self._get_features_from_batch_df(batch_df,nAA,**kargs)\n",
    "                    \n",
    "                    cost = self._train_one_batch(\n",
    "                        targets, \n",
    "                        *features,\n",
    "                    )\n",
    "                    batch_cost.append(cost)\n",
    "                if verbose_each_epoch:\n",
    "                    batch_tqdm.set_description(\n",
    "                        f'Epoch={epoch+1}, nAA={nAA}, Batch={len(batch_cost)}, Loss={cost:.4f}'\n",
    "                    )\n",
    "            if verbose: print(f'[Training] Epoch={epoch+1}, Mean Loss={np.mean(batch_cost)}')\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def predict(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "        batch_size=1024,\n",
    "        verbose=False,**kwargs\n",
    "    )->pd.DataFrame:\n",
    "        self._prepare_predict_data_df(precursor_df,**kwargs)\n",
    "        self.model.eval()\n",
    "\n",
    "        _grouped = precursor_df.groupby('nAA')\n",
    "        if verbose:\n",
    "            batch_tqdm = tqdm(_grouped)\n",
    "        else:\n",
    "            batch_tqdm = _grouped\n",
    "\n",
    "        for nAA, df_group in batch_tqdm:\n",
    "            for i in range(0, len(df_group), batch_size):\n",
    "                batch_end = i+batch_size\n",
    "                \n",
    "                batch_df = df_group.iloc[i:batch_end,:]\n",
    "\n",
    "                features = self._get_features_from_batch_df(\n",
    "                    batch_df, nAA, **kwargs\n",
    "                )\n",
    "\n",
    "                predicts = self._predict_one_batch(*features)\n",
    "\n",
    "                self._set_batch_predict_data(\n",
    "                    batch_df, predicts, \n",
    "                    **kwargs\n",
    "                )\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        return self.predict_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we provide some basic torch sub-models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def zero_param(*shape):\n",
    "    return torch.nn.Parameter(torch.zeros(shape), requires_grad=False)\n",
    "\n",
    "def xavier_param(*shape):\n",
    "    x = torch.nn.Parameter(torch.empty(shape), requires_grad=False)\n",
    "    torch.nn.init.xavier_uniform_(x)\n",
    "    return x\n",
    "\n",
    "init_state = xavier_param\n",
    "\n",
    "def aa_embedding(embedding_size):\n",
    "    return torch.nn.Embedding(27, embedding_size, padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.8011, -0.2783, -0.9825,  1.0262],\n",
       "         [ 1.2833,  2.1443, -0.6163, -1.2240],\n",
       "         [ 0.7585,  0.5774,  0.4626,  0.4241],\n",
       "         [-0.1448, -0.6990,  0.5885,  0.0707],\n",
       "         [ 0.8830,  0.2838, -2.0916,  0.2912],\n",
       "         [-1.6932, -1.9353, -0.3225,  0.9136],\n",
       "         [-1.0500, -1.2422, -1.3428, -1.3569],\n",
       "         [ 1.0293, -0.5682,  0.3428, -0.7382],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from alphadeep.model.featurize import parse_aa_indices\n",
    "sequence = 'ACDEFGIK'\n",
    "\n",
    "embedding_hidden = 4\n",
    "embedding = aa_embedding(embedding_hidden)\n",
    "x = embedding(torch.LongTensor(parse_aa_indices([sequence])))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SeqCNN` or TextCNN extracts sequence features using `nn.Conv1D` with different kernel sizes (3,5,7), and then concatenates the outputs of these Conv1Ds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SeqCNN(torch.nn.Module):\n",
    "    def __init__(self, embedding_hidden):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn_short = torch.nn.Conv1d(\n",
    "            embedding_hidden, embedding_hidden,\n",
    "            kernel_size=3, padding=1\n",
    "        )\n",
    "        self.cnn_medium = torch.nn.Conv1d(\n",
    "            embedding_hidden, embedding_hidden,\n",
    "            kernel_size=5, padding=2\n",
    "        )\n",
    "        self.cnn_long = torch.nn.Conv1d(\n",
    "            embedding_hidden, embedding_hidden,\n",
    "            kernel_size=7, padding=3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x1 = self.cnn_short(x)\n",
    "        x2 = self.cnn_medium(x)\n",
    "        x3 = self.cnn_long(x)\n",
    "        return torch.cat((x, x1, x2, x3), dim=1).transpose(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SeqInput` takes embedded sequences as the input, processes inputs using `SeqCNN`, and outputs RNN results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SeqLSTM(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, \n",
    "                 rnn_layer=2, bidirectional=True\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        if bidirectional:\n",
    "            hidden = out_features//2\n",
    "        else:\n",
    "            hidden = out_features\n",
    "\n",
    "        self.rnn_h0 = init_state(\n",
    "            rnn_layer+rnn_layer*bidirectional,\n",
    "            1, hidden\n",
    "        )\n",
    "        self.rnn_c0 = init_state(\n",
    "            rnn_layer+rnn_layer*bidirectional,\n",
    "            1, hidden\n",
    "        )\n",
    "        self.rnn = torch.nn.LSTM(\n",
    "            input_size = in_features,\n",
    "            hidden_size = hidden,\n",
    "            num_layers = rnn_layer,\n",
    "            batch_first = True,\n",
    "            bidirectional = bidirectional,\n",
    "        )\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        h0 = self.rnn_h0.repeat(1, x.size(0), 1)\n",
    "        c0 = self.rnn_c0.repeat(1, x.size(0), 1)\n",
    "        x, _ = self.rnn(x, (h0,c0))\n",
    "        return x\n",
    "    \n",
    "\n",
    "class SeqGRU(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, \n",
    "                 rnn_layer=2, bidirectional=True\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        if bidirectional:\n",
    "            hidden = out_features//2\n",
    "        else:\n",
    "            hidden = out_features\n",
    "        \n",
    "        self.rnn_h0 = init_state(\n",
    "            rnn_layer+rnn_layer*bidirectional, \n",
    "            1, hidden\n",
    "        )\n",
    "        self.rnn = torch.nn.GRU(\n",
    "            input_size = in_features,\n",
    "            hidden_size = hidden,\n",
    "            num_layers = rnn_layer,\n",
    "            batch_first = True,\n",
    "            bidirectional = bidirectional,\n",
    "        )\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        h0 = self.rnn_h0.repeat(1, x.size(0), 1)\n",
    "        x, _ = self.rnn(x, h0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SeqTransformer(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        in_features,\n",
    "        out_features,\n",
    "        nhead=8,\n",
    "        nlayers=2,\n",
    "        dropout=0.2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        encoder_layers = torch.nn.TransformerEncoderLayer(\n",
    "            in_features, nhead, out_features, dropout\n",
    "        )\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(\n",
    "            encoder_layers, nlayers\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.transformer_encoder(x.permute(1,0,2)).permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SeqAttentionSum(torch.nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.attn = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features, 1, bias=False),\n",
    "            torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        attn = self.attn(x)\n",
    "        return torch.sum(torch.mul(x, attn), dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1867, 0.1412, 0.1935, 0.1944, 0.1429, 0.1412],\n",
       "        [0.0000, 0.3581, 0.2708, 0.3711, 0.0000, 0.0000, 0.0000]],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = [[1,2,3,4,5,6],[1,2,3,1,2,3]]\n",
    "x = torch.LongTensor(x)\n",
    "x = torch.nn.functional.one_hot(x, 7).float()\n",
    "attn = SeqAttentionSum(7)\n",
    "attn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LinearDecoder(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.nn = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features, 64),\n",
    "            torch.nn.PReLU(),\n",
    "            torch.nn.Linear(64, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.nn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test these basic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SeqEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout=0.2, rnn_layer=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.input_cnn = SeqCNN(in_features)\n",
    "        self.hidden_nn = SeqLSTM(in_features*4, out_features, rnn_layer=rnn_layer) #4 for MultiScaleCNN output\n",
    "        self.attn_sum = SeqAttentionSum(out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_cnn(x)\n",
    "        x = self.hidden_nn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.attn_sum(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2144,  0.3546, -0.1847,  0.1980],\n",
       "        [ 0.3311,  0.2976, -0.1796,  0.1984]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[1,2,3,4,5,6],[1,2,3,1,2,3]]\n",
    "x = torch.LongTensor(x)\n",
    "x = torch.nn.functional.one_hot(x, 7).float()\n",
    "embedding_hidden=7\n",
    "encoder = SeqEncoder(7,4)\n",
    "code = encoder(x)\n",
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqEncoder(\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (input_cnn): SeqCNN(\n",
       "    (cnn_short): Conv1d(7, 7, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (cnn_medium): Conv1d(7, 7, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (cnn_long): Conv1d(7, 7, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "  )\n",
       "  (hidden_nn): SeqLSTM(\n",
       "    (rnn): LSTM(28, 2, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (attn_sum): SeqAttentionSum(\n",
       "    (attn): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=1, bias=False)\n",
       "      (1): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SeqDecoder(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden = 128\n",
    "        self.rnn_h0 = init_state(1, 1, hidden)\n",
    "        self.rnn = torch.nn.GRU(\n",
    "            input_size = in_features,\n",
    "            hidden_size = hidden,\n",
    "            num_layers = 1,\n",
    "            batch_first = True,\n",
    "            bidirectional = False,\n",
    "        )\n",
    "\n",
    "        self.output_nn = torch.nn.Linear(\n",
    "            hidden, out_features, bias=False\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = self.rnn_h0.repeat(1, x.size(0), 1)\n",
    "        x, h = self.rnn(x, h0)\n",
    "        x = self.output_nn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.6585,  1.1273, -1.4849, -0.3010],\n",
       "          [ 0.0712,  1.3001, -1.5116,  0.1403],\n",
       "          [-0.0342,  0.8101, -1.6211,  0.8452],\n",
       "          [ 0.4575,  0.1316, -1.6362,  1.0470],\n",
       "          [ 0.2541,  1.0731, -1.6391,  0.3118],\n",
       "          [ 0.9879,  0.6866, -1.5958, -0.0787],\n",
       "          [ 0.5842,  0.4980, -1.7296,  0.6474],\n",
       "          [-0.4197,  0.8815, -1.4434,  0.9816]],\n",
       " \n",
       "         [[ 0.3686,  0.0590, -1.5866,  1.1590],\n",
       "          [ 1.0358, -0.0456, -1.5984,  0.6083],\n",
       "          [ 0.3819, -0.2015, -1.4681,  1.2877],\n",
       "          [ 0.8745, -0.1572, -1.5738,  0.8565],\n",
       "          [ 0.5738, -0.0923, -1.5723,  1.0909],\n",
       "          [ 0.0816, -0.0985, -1.4028,  1.4197],\n",
       "          [ 0.1831, -0.3048, -1.3295,  1.4512],\n",
       "          [ 0.0651,  0.2052, -1.5346,  1.2643]]], grad_fn=<PermuteBackward>),\n",
       " torch.Size([2, 8, 4]),\n",
       " 8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = SeqTransformer(4, 2, 4)\n",
    "\n",
    "decode = decoder(code.unsqueeze(1).repeat(1, len(sequence), 1))\n",
    "decode, decode.shape, len(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a3b27e141e49c996c9b863f8707e97aabd49c4a7e8445b9b783b34e4a21a9b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
