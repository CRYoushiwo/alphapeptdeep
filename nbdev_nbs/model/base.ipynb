{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#default_exp model.base"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#export\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from typing import IO, Type, Tuple, Callable\n",
    "from alphabase.yaml_utils import save_yaml\n",
    "from alphadeep._settings import model_const"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ModelImplBase\n",
    "The base model for operations of all models, it does not contains the model (torch.nn.Module), but just provides some common APIs, including `load()` to load models, `save()` to save modles, ..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#export\n",
    "class ModelImplBase(object):\n",
    "    def __init__(self, *args, **kargs):\n",
    "        if 'GPU' in kargs:\n",
    "            self.use_GPU(kargs['GPU'])\n",
    "        else:\n",
    "            self.use_GPU(True)\n",
    "\n",
    "    def use_GPU(self, GPU=True):\n",
    "        if GPU and not torch.cuda.is_available():\n",
    "            GPU=False\n",
    "        self.device = torch.device('cuda' if GPU else 'cpu')\n",
    "\n",
    "    def init_train(self, lr=0.001):\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.loss_func = torch.nn.L1Loss()\n",
    "\n",
    "    def build(self,\n",
    "        model_class: Type[torch.nn.Module],\n",
    "        lr = 0.001,\n",
    "        *args, **kargs\n",
    "    ):\n",
    "        self.model = model_class(*args, **kargs)\n",
    "        self.model.to(self.device)\n",
    "        self.init_train(lr)\n",
    "\n",
    "    def get_parameter_num(self):\n",
    "        return np.sum([p.numel() for p in self.model.parameters()])\n",
    "\n",
    "    def save(self, save_as):\n",
    "        dir = os.path.dirname(save_as)\n",
    "        if not dir: dir = './'\n",
    "        if not os.path.exists(dir): os.makedirs(dir)\n",
    "        torch.save(self.model.state_dict(), save_as)\n",
    "        with open(save_as+'.txt','w') as f: f.write(str(self.model))\n",
    "        save_yaml(save_as+'.model_const.txt', model_const)\n",
    "\n",
    "    def _load_model_file(self, stream):\n",
    "        self.model.load_state_dict(torch.load(\n",
    "            stream, map_location=self.device)\n",
    "        )\n",
    "\n",
    "    def load(\n",
    "        self,\n",
    "        model_file: Tuple[str, IO],\n",
    "        model_name_in_zip: str = None,\n",
    "        *args, **kargs\n",
    "    ):\n",
    "        if isinstance(model_file, str):\n",
    "            # We may release all models (msms, rt, ccs, ...) in a single zip file\n",
    "            if model_file.lower().endswith('.zip'):\n",
    "                with ZipFile(model_file, 'rb') as model_zip:\n",
    "                    with model_zip.open(model_name_in_zip) as pt_file:\n",
    "                        self._load_model_file(pt_file)\n",
    "            else:\n",
    "                with open(model_file,'rb') as pt_file:\n",
    "                    self._load_model_file(pt_file)\n",
    "        else:\n",
    "            self._load_model_file(model_file)\n",
    "\n",
    "    def _train_one_batch(\n",
    "        self, \n",
    "        targets:torch.Tensor, \n",
    "        *features\n",
    "    ):\n",
    "        self.optimizer.zero_grad()\n",
    "        predicts = self.model(*[fea.to(self.device) for fea in features])\n",
    "        cost = self.loss_func(predicts, targets.to(self.device))\n",
    "        cost.backward()\n",
    "        self.optimizer.step()\n",
    "        return cost\n",
    "\n",
    "    def _predict_one_batch(self,\n",
    "        *features\n",
    "    ):\n",
    "        return self.model(*[fea.to(self.device) for fea in features])\n",
    "\n",
    "    def train(self, \n",
    "        batch_size=1024, \n",
    "        epoch=20, \n",
    "        *args, **kargs\n",
    "    ):\n",
    "        raise NotImplementedError('train() function is not finished yet')\n",
    "\n",
    "    def predict(self, batch_size=1024, *args, **kargs):\n",
    "        raise NotImplementedError('predict() function is not finished yet')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Here we provide some basic torch sub-models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#export\n",
    "def zero_param(*shape):\n",
    "    return torch.nn.Parameter(torch.zeros(shape), requires_grad=False)\n",
    "\n",
    "def xavier_param(*shape):\n",
    "    x = torch.nn.Parameter(torch.empty(shape), requires_grad=False)\n",
    "    torch.nn.init.xavier_uniform_(x)\n",
    "    return x\n",
    "\n",
    "init_state = xavier_param\n",
    "\n",
    "def aa_embedding(embedding_size):\n",
    "    return torch.nn.Embedding(27, embedding_size, padding_idx=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from alphadeep.model.featurize import parse_aa_indices\n",
    "sequence = 'ACDEFGIK'\n",
    "\n",
    "embedding_hidden = 4\n",
    "embedding = aa_embedding(embedding_hidden)\n",
    "x = embedding(torch.LongTensor(parse_aa_indices([sequence])))\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.4168, -0.3556, -0.1749,  0.2717],\n",
       "         [-1.2152,  0.1948, -1.2864,  0.0697],\n",
       "         [ 0.3901,  1.7054,  0.0527,  1.1267],\n",
       "         [ 1.2733, -0.9918,  0.4241,  0.8180],\n",
       "         [-0.3250,  2.0396, -1.6054, -1.4044],\n",
       "         [ 0.2546, -0.1199,  0.2982,  0.0204],\n",
       "         [ 1.4263,  0.4961, -2.2491, -0.1558],\n",
       "         [ 0.1124, -1.0196, -1.3721,  0.8453],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`SeqCNN` or TextCNN extracts sequence features using `nn.Conv1D` with different kernel sizes (3,5,7), and then concatenates the outputs of these Conv1Ds."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#export\n",
    "class SeqCNN(torch.nn.Module):\n",
    "    def __init__(self, embedding_hidden):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn_short = torch.nn.Conv1d(\n",
    "            embedding_hidden, embedding_hidden,\n",
    "            kernel_size=3, padding=1\n",
    "        )\n",
    "        self.cnn_medium = torch.nn.Conv1d(\n",
    "            embedding_hidden, embedding_hidden,\n",
    "            kernel_size=5, padding=2\n",
    "        )\n",
    "        self.cnn_long = torch.nn.Conv1d(\n",
    "            embedding_hidden, embedding_hidden,\n",
    "            kernel_size=7, padding=3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x1 = self.cnn_short(x)\n",
    "        x2 = self.cnn_medium(x)\n",
    "        x3 = self.cnn_long(x)\n",
    "        return torch.cat((x, x1, x2, x3), dim=1).transpose(1,2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`SeqInput` takes embedded sequences as the input, processes inputs using `SeqCNN`, and outputs RNN results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#export\n",
    "class SeqLSTM(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, \n",
    "                 rnn_layer=2, bidirectional=True\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        if bidirectional:\n",
    "            hidden = out_features//2\n",
    "        else:\n",
    "            hidden = out_features\n",
    "\n",
    "        self.rnn_h0 = init_state(\n",
    "            rnn_layer+rnn_layer*bidirectional,\n",
    "            1, hidden\n",
    "        )\n",
    "        self.rnn_c0 = init_state(\n",
    "            rnn_layer+rnn_layer*bidirectional,\n",
    "            1, hidden\n",
    "        )\n",
    "        self.rnn = torch.nn.LSTM(\n",
    "            input_size = in_features,\n",
    "            hidden_size = hidden,\n",
    "            num_layers = rnn_layer,\n",
    "            batch_first = True,\n",
    "            bidirectional = bidirectional,\n",
    "        )\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        h0 = self.rnn_h0.repeat(1, x.size(0), 1)\n",
    "        c0 = self.rnn_c0.repeat(1, x.size(0), 1)\n",
    "        x, _ = self.rnn(x, (h0,c0))\n",
    "        return x\n",
    "    \n",
    "\n",
    "class SeqGRU(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, \n",
    "                 rnn_layer=2, bidirectional=True\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        if bidirectional:\n",
    "            hidden = out_features//2\n",
    "        else:\n",
    "            hidden = out_features\n",
    "        \n",
    "        self.rnn_h0 = init_state(\n",
    "            rnn_layer+rnn_layer*bidirectional, \n",
    "            1, hidden\n",
    "        )\n",
    "        self.rnn = torch.nn.GRU(\n",
    "            input_size = in_features,\n",
    "            hidden_size = hidden,\n",
    "            num_layers = rnn_layer,\n",
    "            batch_first = True,\n",
    "            bidirectional = bidirectional,\n",
    "        )\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        h0 = self.rnn_h0.repeat(1, x.size(0), 1)\n",
    "        x, _ = self.rnn(x, h0)\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#export\n",
    "class SeqAttentionSum(torch.nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.attn = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features, 1, bias=False),\n",
    "            torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        attn = self.attn(x)\n",
    "        return torch.sum(torch.mul(x, attn), dim=1)\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import torch\n",
    "x = [[1,2,3,4,5,6],[1,2,3,1,2,3]]\n",
    "x = torch.LongTensor(x)\n",
    "x = torch.nn.functional.one_hot(x, 7).float()\n",
    "attn = SeqAttentionSum(7)\n",
    "attn(x)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1640, 0.2180, 0.1619, 0.1434, 0.2000, 0.1128],\n",
       "        [0.0000, 0.3015, 0.4008, 0.2977, 0.0000, 0.0000, 0.0000]],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#export\n",
    "class LinearDecoder(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.nn = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features, 64),\n",
    "            torch.nn.PReLU(),\n",
    "            torch.nn.Linear(64, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.nn(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test these basic models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#export\n",
    "class SeqEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout=0.2, rnn_layer=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.input_cnn = SeqCNN(in_features)\n",
    "        self.hidden_nn = SeqLSTM(in_features*4, out_features, rnn_layer=rnn_layer) #4 for MultiScaleCNN output\n",
    "        self.attn_sum = SeqAttentionSum(out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_cnn(x)\n",
    "        x = self.hidden_nn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.attn_sum(x)\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "x = [[1,2,3,4,5,6],[1,2,3,1,2,3]]\n",
    "x = torch.LongTensor(x)\n",
    "x = torch.nn.functional.one_hot(x, 7).float()\n",
    "embedding_hidden=7\n",
    "encoder = SeqEncoder(7,4)\n",
    "code = encoder(x)\n",
    "code"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0889, -0.1589,  0.0364, -0.0170],\n",
       "        [ 0.1294, -0.1353,  0.0524, -0.0151]], grad_fn=<SumBackward1>)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "#hide\n",
    "encoder"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SeqEncoder(\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (input_cnn): SeqCNN(\n",
       "    (cnn_short): Conv1d(7, 7, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (cnn_medium): Conv1d(7, 7, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (cnn_long): Conv1d(7, 7, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "  )\n",
       "  (hidden_nn): SeqLSTM(\n",
       "    (rnn): LSTM(28, 2, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (attn_sum): SeqAttentionSum(\n",
       "    (attn): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=1, bias=False)\n",
       "      (1): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "#export\n",
    "class SeqDecoder(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden = 128\n",
    "        self.rnn_h0 = init_state(1, 1, hidden)\n",
    "        self.rnn = torch.nn.GRU(\n",
    "            input_size = in_features,\n",
    "            hidden_size = hidden,\n",
    "            num_layers = 1,\n",
    "            batch_first = True,\n",
    "            bidirectional = False,\n",
    "        )\n",
    "\n",
    "        self.output_nn = torch.nn.Linear(\n",
    "            hidden, out_features, bias=False\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = self.rnn_h0.repeat(1, x.size(0), 1)\n",
    "        x, h = self.rnn(x, h0)\n",
    "        x = self.output_nn(x)\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "decoder = SeqDecoder(4, 2)\n",
    "\n",
    "decode = decoder(code.unsqueeze(1).repeat(1, len(sequence), 1))\n",
    "decode"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 0.0200, -0.0371],\n",
       "         [ 0.0262, -0.0179],\n",
       "         [ 0.0292, -0.0076],\n",
       "         [ 0.0303, -0.0018],\n",
       "         [ 0.0305,  0.0017],\n",
       "         [ 0.0303,  0.0038],\n",
       "         [ 0.0299,  0.0052],\n",
       "         [ 0.0295,  0.0060]],\n",
       "\n",
       "        [[ 0.0192, -0.0378],\n",
       "         [ 0.0250, -0.0189],\n",
       "         [ 0.0279, -0.0087],\n",
       "         [ 0.0290, -0.0029],\n",
       "         [ 0.0291,  0.0005],\n",
       "         [ 0.0289,  0.0027],\n",
       "         [ 0.0285,  0.0040],\n",
       "         [ 0.0281,  0.0048]]], grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "47571f5fdb57242938b1c768688b8dffd916e56712176e488a19312fe26ffb57"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}