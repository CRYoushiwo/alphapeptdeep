{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp model.rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from alphadeep.model.featurize import (\n",
    "    parse_aa_indices, \n",
    "    get_batch_mod_feature\n",
    ")\n",
    "\n",
    "from alphadeep.settings import model_const\n",
    "\n",
    "import alphadeep.model.base as model_base\n",
    "\n",
    "mod_feature_size = len(model_const['mod_elements'])\n",
    "\n",
    "def regional_sampling(psm_df:pd.DataFrame, \n",
    "    target:str='rt_norm', n_train:int=1000, \n",
    "    return_test_df:bool=False,\n",
    "    random_state=1337,\n",
    ")->pd.DataFrame:\n",
    "    \"\"\" Divide `psm_df` into 10 bins by values in the `target` \n",
    "    column (`rt_norm` or `ccs`), and sample training PSMs (rows) \n",
    "    from each bins for model fine-tuning.\n",
    "\n",
    "    Args:\n",
    "        psm_df (pd.DataFrame): Dataframe of PSMs.\n",
    "        target (str, optional): Target columns to sample. \n",
    "            Defaults to 'rt_norm'.\n",
    "        n_train (int, optional): The number of training PSMs \n",
    "            to sample. Defaults to 1000.\n",
    "        return_test_df (bool, optional): If also return `test_df`. \n",
    "            `test_df` contains the PSMs that are not sampled.\n",
    "            Defaults to False.\n",
    "        random_state: `random_state` in `df.sample()`.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The sampled training PSMs (dataframe)\n",
    "        [pd.DataFrame]: The not sampled PSMs (dataframe) for testing. \n",
    "            Returned only if `return_test_df==True` in the arguments.\n",
    "    \"\"\"\n",
    "    x = np.arange(0, 11)/10*psm_df[target].max()\n",
    "    sub_n = n_train//(len(x)-1)\n",
    "    df_list = []\n",
    "    for i in range(len(x)-1):\n",
    "        _df = psm_df[\n",
    "            (psm_df[target]>=x[i])&(psm_df[target]<x[i+1])\n",
    "        ]\n",
    "        if len(_df) == 0: pass\n",
    "        elif len(_df)//2 < sub_n:\n",
    "            df_list.append(_df.sample(\n",
    "                len(_df)//2, \n",
    "                replace=False,\n",
    "                random_state=random_state\n",
    "            ))\n",
    "        else:\n",
    "            df_list.append(_df.sample(\n",
    "                sub_n, \n",
    "                replace=False,\n",
    "                random_state=random_state\n",
    "            ))\n",
    "    if return_test_df:\n",
    "        if len(df_list) == 0:\n",
    "            return pd.DataFrame(), pd.DataFrame()\n",
    "        train_df = pd.concat(df_list)\n",
    "        test_df = psm_df.drop(train_df.index)\n",
    "        return train_df, test_df\n",
    "    else:\n",
    "        if len(df_list) == 0:\n",
    "            return pd.DataFrame()\n",
    "        return pd.concat(df_list)\n",
    "\n",
    "# wrapper for legacy\n",
    "uniform_sampling = regional_sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ModelRT_Bert(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        dropout = 0.1,\n",
    "        nlayers = 4,\n",
    "        hidden = 128,\n",
    "        output_attentions=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.input_nn = model_base.AATransformerEncoding(hidden)\n",
    "\n",
    "        self._output_attentions = output_attentions\n",
    "        \n",
    "        self.hidden_nn = model_base.HiddenBert(\n",
    "            hidden, nlayers=nlayers, dropout=dropout,\n",
    "            output_attentions=output_attentions\n",
    "        )\n",
    "\n",
    "        self.output_nn = torch.nn.Sequential(\n",
    "            model_base.SeqAttentionSum(hidden),\n",
    "            torch.nn.PReLU(),\n",
    "            self.dropout,\n",
    "            torch.nn.Linear(hidden, 1),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def output_attentions(self):\n",
    "        return self._output_attentions\n",
    "\n",
    "    @output_attentions.setter\n",
    "    def output_attentions(self, val:bool):\n",
    "        self._output_attentions = val\n",
    "        self.hidden_nn.output_attentions = val\n",
    "\n",
    "    def forward(self, \n",
    "        aa_indices, \n",
    "        mod_x,\n",
    "    ):\n",
    "        x = self.dropout(self.input_nn(\n",
    "            aa_indices, mod_x\n",
    "        ))\n",
    "\n",
    "        hidden_x = self.hidden_nn(x)\n",
    "        if self.output_attentions:\n",
    "            self.attentions = hidden_x[1]\n",
    "        else:\n",
    "            self.attentions = None\n",
    "        x = self.dropout(hidden_x[0]+x*0.2)\n",
    "\n",
    "        return self.output_nn(x).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ModelRT_LSTM(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        dropout=0.2,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "        hidden = 256\n",
    "        self.rt_encoder = model_base.Input_AA_CNN_LSTM_Encoder(\n",
    "            hidden\n",
    "        )\n",
    "\n",
    "        self.rt_decoder = model_base.LinearDecoder(\n",
    "            hidden,\n",
    "            1\n",
    "        )\n",
    "\n",
    "    def forward(self, \n",
    "        aa_indices, \n",
    "        mod_x,\n",
    "    ):\n",
    "        x = self.rt_encoder(aa_indices, mod_x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return self.rt_decoder(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AlphaRTModel(model_base.ModelImplBase):\n",
    "    def __init__(self, \n",
    "        dropout=0.1, lr=0.001,\n",
    "        model_class:torch.nn.Module=ModelRT_Bert,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.build(\n",
    "            model_class,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.loss_func = torch.nn.L1Loss()\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "    ):\n",
    "        precursor_df['rt_pred'] = 0.\n",
    "        self.predict_df = precursor_df\n",
    "\n",
    "    def _get_features_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame, \n",
    "        nAA\n",
    "    ):\n",
    "        aa_indices = torch.LongTensor(\n",
    "            parse_aa_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            )\n",
    "        )\n",
    "\n",
    "        mod_x_batch = get_batch_mod_feature(batch_df, nAA)\n",
    "        mod_x = torch.Tensor(mod_x_batch)\n",
    "\n",
    "        return aa_indices, mod_x\n",
    "\n",
    "    def _get_targets_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame, \n",
    "        **kwargs,\n",
    "    ) -> torch.Tensor:\n",
    "        return torch.Tensor(batch_df['rt_norm'].values)\n",
    "\n",
    "    def _set_batch_predict_data(self, \n",
    "        batch_df: pd.DataFrame, \n",
    "        predicts: np.array,\n",
    "    ):\n",
    "        predicts[predicts<0] = 0.0\n",
    "        if self._predict_in_order:\n",
    "            self.predict_df.loc[:,'rt_pred'].values[\n",
    "                batch_df.index.values[0]:batch_df.index.values[-1]+1\n",
    "            ] = predicts\n",
    "        else:\n",
    "            self.predict_df.loc[\n",
    "                batch_df.index,'rt_pred'\n",
    "            ] = predicts\n",
    "\n",
    "    def rt_to_irt_pred(self,\n",
    "        precursor_df: pd.DataFrame\n",
    "    ):\n",
    "        convert_predicted_rt_to_irt(precursor_df, self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2303], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "model = AlphaRTModel()\n",
    "model.device = torch.device('cpu')\n",
    "model.model.to(model.device)\n",
    "mod_hidden = len(model_const['mod_elements'])\n",
    "model.model(torch.LongTensor([[1,2,3,4,5,6]]), torch.tensor([[[0.0]*mod_hidden]*6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "796792"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_parameter_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelRT_Bert(\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (input_nn): AATransformerEncoding(\n",
       "    (mod_nn): InputModNetFixFirstK(\n",
       "      (nn): Linear(in_features=103, out_features=2, bias=False)\n",
       "    )\n",
       "    (aa_emb): Embedding(27, 120, padding_idx=0)\n",
       "    (pos_encoder): PositionalEncoding()\n",
       "  )\n",
       "  (hidden_nn): HiddenBert(\n",
       "    (bert): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_nn): Sequential(\n",
       "    (0): SeqAttentionSum(\n",
       "      (attn): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=1, bias=False)\n",
       "        (1): Softmax(dim=1)\n",
       "      )\n",
       "    )\n",
       "    (1): PReLU(num_parameters=1)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>rt_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sequence                                               mods mod_sites  \\\n",
       "0  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "1  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "2  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "3  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "4  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "5  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "6  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "7  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "8  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "9  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "\n",
       "   nAA  rt_norm  \n",
       "0   11      0.6  \n",
       "1   11      0.6  \n",
       "2   11      0.6  \n",
       "3   11      0.6  \n",
       "4   11      0.6  \n",
       "5   11      0.6  \n",
       "6   11      0.6  \n",
       "7   11      0.6  \n",
       "8   11      0.6  \n",
       "9   11      0.6  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat = 10\n",
    "precursor_df = pd.DataFrame({\n",
    "    'sequence': ['AGHCEWQMKYR']*repeat,\n",
    "    'mods': ['Acetyl@Protein N-term;Carbamidomethyl@C;Oxidation@M']*repeat,\n",
    "    'mod_sites': ['0;4;8']*repeat,\n",
    "    'nAA': [11]*repeat,\n",
    "    'rt_norm': [0.6]*repeat\n",
    "})\n",
    "precursor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch=1, nAA=11, Batch=1, Loss=0.5187: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s]\n",
      "Epoch=2, nAA=11, Batch=1, Loss=0.1990: 100%|██████████| 1/1 [00:00<00:00, 21.07it/s]\n",
      "Epoch=3, nAA=11, Batch=1, Loss=0.1295: 100%|██████████| 1/1 [00:00<00:00, 22.44it/s]\n",
      "Epoch=4, nAA=11, Batch=1, Loss=0.1951: 100%|██████████| 1/1 [00:00<00:00, 28.15it/s]\n",
      "Epoch=5, nAA=11, Batch=1, Loss=0.2177: 100%|██████████| 1/1 [00:00<00:00, 31.43it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.train(precursor_df, epoch=5, verbose_each_epoch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>rt_norm</th>\n",
       "      <th>rt_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.714481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.714481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.714481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.714481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.714481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.714481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.714481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.714481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.714481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.714481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sequence                                               mods mod_sites  \\\n",
       "0  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "1  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "2  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "3  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "4  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "5  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "6  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "7  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "8  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "9  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "\n",
       "   nAA  rt_norm   rt_pred  \n",
       "0   11      0.6  0.714481  \n",
       "1   11      0.6  0.714481  \n",
       "2   11      0.6  0.714481  \n",
       "3   11      0.6  0.714481  \n",
       "4   11      0.6  0.714481  \n",
       "5   11      0.6  0.714481  \n",
       "6   11      0.6  0.714481  \n",
       "7   11      0.6  0.714481  \n",
       "8   11      0.6  0.714481  \n",
       "9   11      0.6  0.714481  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(precursor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_linear_regression(\n",
    "    df:pd.DataFrame, x='rt_pred', y='rt_norm', \n",
    "    ci=95, n_sample=100000\n",
    "):\n",
    "    if len(df) > n_sample:\n",
    "        df = df.sample(n_sample, replace=False)\n",
    "    gls = sm.GLS(df[y], sm.add_constant(df[x]))\n",
    "    res = gls.fit()\n",
    "    summary = res.summary(alpha=1-ci/100.0)\n",
    "    dfs = []\n",
    "    results_as_html = summary.tables[0].as_html()\n",
    "    dfs.append(pd.read_html(results_as_html, index_col=None)[0])\n",
    "    results_as_html = summary.tables[1].as_html()\n",
    "    dfs.append(pd.read_html(results_as_html, index_col=None)[0])\n",
    "    summary = pd.concat(dfs).reset_index(drop=True)\n",
    "    R_square = float(summary.loc[0,3])\n",
    "    R = np.sqrt(R_square)\n",
    "    n,b,w = summary.loc[[5,10,11],1].values.astype(float)\n",
    "    return pd.DataFrame(\n",
    "        dict(\n",
    "            R_square=[R_square],R=[R],\n",
    "            slope=[w],intercept=[b],n_sample=[n]\n",
    "        )\n",
    "    )\n",
    "\n",
    "def evaluate_linear_regression_plot(\n",
    "    df:pd.DataFrame, x='rt_pred', y='rt_norm', \n",
    "    ci=95, n_sample=100000\n",
    "):\n",
    "    if len(df) > n_sample:\n",
    "        df = df.sample(n_sample)\n",
    "    alpha = 0.05\n",
    "    if len(df) < 5000:\n",
    "        alpha = 1\n",
    "    elif len(df) < 50000:\n",
    "        alpha = 5000.0/len(df)\n",
    "    sns.regplot(\n",
    "        data=df, x=x, y=y, color='r', ci=ci, \n",
    "        scatter_kws={'s':0.05, 'alpha':alpha, 'color':'b'}\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({'rt_norm':np.arange(10), 'rt_pred':np.arange(10)+np.random.normal(0,0.3,10)})\n",
    "evaluate_linear_regression_plot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "irt_pep = pd.DataFrame(\n",
    "    [['LGGNEQVTR', 'RT-pep a', -24.92, '', ''],\n",
    "    ['GAGSSEPVTGLDAK', 'RT-pep b', 0.00, '', ''],\n",
    "    ['VEATFGVDESNAK', 'RT-pep c', 12.39, '', ''],\n",
    "    ['YILAGVENSK', 'RT-pep d', 19.79, '', ''],\n",
    "    ['TPVISGGPYEYR', 'RT-pep e', 28.71, '', ''],\n",
    "    ['TPVITGAPYEYR', 'RT-pep f', 33.38, '', ''],\n",
    "    ['DGLDAASYYAPVR', 'RT-pep g', 42.26, '', ''],\n",
    "    ['ADVTPADFSEWSK', 'RT-pep h', 54.62, '', ''],\n",
    "    ['GTFIIDPGGVIR', 'RT-pep i', 70.52, '', ''],\n",
    "    ['GTFIIDPAAVIR', 'RT-pep k', 87.23, '', ''],\n",
    "    ['LFLQFGAQGSPFLK', 'RT-pep l', 100.00, '', '']],\n",
    "    columns=['sequence','pep_name','irt', 'mods', 'mod_sites']\n",
    ")\n",
    "irt_pep['nAA'] = irt_pep.sequence.str.len()\n",
    "\n",
    "def convert_predicted_rt_to_irt(\n",
    "    df:pd.DataFrame, rt_model:AlphaRTModel\n",
    ")->pd.DataFrame:\n",
    "    rt_model.predict(irt_pep)\n",
    "    # simple linear regression\n",
    "    rt_pred_mean = irt_pep.rt_pred.mean()\n",
    "    irt_mean = irt_pep.irt.mean()\n",
    "    x = irt_pep.rt_pred.values - rt_pred_mean\n",
    "    y = irt_pep.irt.values - irt_mean\n",
    "    slope = np.sum(x*y)/np.sum(x*x)\n",
    "    intercept = irt_mean - slope*rt_pred_mean\n",
    "    # end linear regression\n",
    "    df['irt_pred'] = df.rt_pred*slope + intercept\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9\n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14\n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13\n",
       "3       YILAGVENSK  RT-pep d   19.79                  10\n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12\n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12\n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13\n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13\n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12\n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12\n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "irt_pep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pep_name</th>\n",
       "      <th>irt</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>rt_pred</th>\n",
       "      <th>irt_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGGNEQVTR</td>\n",
       "      <td>RT-pep a</td>\n",
       "      <td>-24.92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.072804</td>\n",
       "      <td>-28.148849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAGSSEPVTGLDAK</td>\n",
       "      <td>RT-pep b</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.271196</td>\n",
       "      <td>2.053492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEATFGVDESNAK</td>\n",
       "      <td>RT-pep c</td>\n",
       "      <td>12.39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.332649</td>\n",
       "      <td>11.408902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YILAGVENSK</td>\n",
       "      <td>RT-pep d</td>\n",
       "      <td>19.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.400949</td>\n",
       "      <td>21.806524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPVISGGPYEYR</td>\n",
       "      <td>RT-pep e</td>\n",
       "      <td>28.71</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.438901</td>\n",
       "      <td>27.584271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPVITGAPYEYR</td>\n",
       "      <td>RT-pep f</td>\n",
       "      <td>33.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.489774</td>\n",
       "      <td>35.328937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DGLDAASYYAPVR</td>\n",
       "      <td>RT-pep g</td>\n",
       "      <td>42.26</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.542729</td>\n",
       "      <td>43.390475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVTPADFSEWSK</td>\n",
       "      <td>RT-pep h</td>\n",
       "      <td>54.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.609782</td>\n",
       "      <td>53.598396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTFIIDPGGVIR</td>\n",
       "      <td>RT-pep i</td>\n",
       "      <td>70.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>76.035216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTFIIDPAAVIR</td>\n",
       "      <td>RT-pep k</td>\n",
       "      <td>87.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.846791</td>\n",
       "      <td>89.679588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LFLQFGAQGSPFLK</td>\n",
       "      <td>RT-pep l</td>\n",
       "      <td>100.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.857061</td>\n",
       "      <td>91.243048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  pep_name     irt mods mod_sites  nAA   rt_pred   irt_pred\n",
       "0        LGGNEQVTR  RT-pep a  -24.92                   9  0.072804 -28.148849\n",
       "1   GAGSSEPVTGLDAK  RT-pep b    0.00                  14  0.271196   2.053492\n",
       "2    VEATFGVDESNAK  RT-pep c   12.39                  13  0.332649  11.408902\n",
       "3       YILAGVENSK  RT-pep d   19.79                  10  0.400949  21.806524\n",
       "4     TPVISGGPYEYR  RT-pep e   28.71                  12  0.438901  27.584271\n",
       "5     TPVITGAPYEYR  RT-pep f   33.38                  12  0.489774  35.328937\n",
       "6    DGLDAASYYAPVR  RT-pep g   42.26                  13  0.542729  43.390475\n",
       "7    ADVTPADFSEWSK  RT-pep h   54.62                  13  0.609782  53.598396\n",
       "8     GTFIIDPGGVIR  RT-pep i   70.52                  12  0.757164  76.035216\n",
       "9     GTFIIDPAAVIR  RT-pep k   87.23                  12  0.846791  89.679588\n",
       "10  LFLQFGAQGSPFLK  RT-pep l  100.00                  14  0.857061  91.243048"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "from alphadeep.pretrained_models import ModelManager\n",
    "models = ModelManager()\n",
    "models.load_installed_models()\n",
    "irt_pep = models.rt_model.predict(irt_pep)\n",
    "irt_pep = convert_predicted_rt_to_irt(irt_pep, models.rt_model)\n",
    "irt_pep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert irt_pep.rt_pred.is_monotonic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
