# AUTOGENERATED! DO NOT EDIT! File to edit: nbdev_nbs/rescore/ML_score.ipynb (unless otherwise specified).

__all__ = ['fdr_to_q_values', 'get_q_values', 'score_to_q_value', 'MLPScore', 'Percolator']

# Cell
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
import numba
import numpy as np
import pandas as pd
from tqdm import tqdm
import torch

from alphadeep.rescore.feature_extractor import (
    ScoreFeatureExtractor
)

# Cell
@numba.njit
def fdr_to_q_values(fdr_values):
    q_values = np.zeros_like(fdr_values)
    min_q_value = np.max(fdr_values)
    for i in range(len(fdr_values) - 1, -1, -1):
        fdr = fdr_values[i]
        if fdr < min_q_value:
            min_q_value = fdr
        q_values[i] = min_q_value
    return q_values

def get_q_values(_df, score_column, decoy_column='decoy'):
    _df = _df.reset_index()
    _df = _df.sort_values([score_column,score_column], ascending=False)
    target_values = 1-_df[decoy_column].values
    decoy_cumsum = np.cumsum(_df[decoy_column].values)
    target_cumsum = np.cumsum(target_values)
    fdr_values = decoy_cumsum/target_cumsum
    _df['q_value'] = fdr_to_q_values(fdr_values)
    return _df

@numba.njit
def score_to_q_value(scores, base_scores, base_q_values):
    q_values = np.zeros_like(scores)
    i,j = 0,0
    while i < len(scores) and j < len(base_scores):
        if scores[i] >= base_scores[j]:
            q_values[i] = base_q_values[j]
            i += 1
        else:
            j += 1
    while i < len(scores):
        q_values[i] = base_q_values[-1]
        i += 1
    return q_values

class MLPScore(torch.nn.Module):
    def __init__(self, in_features, nlayer=8):
        super().__init__()
        hidden = 128
        self.nn = torch.nn.Sequential(
            torch.nn
        )

class Percolator:
    def __init__(self,
        score_model=LogisticRegression,
        cv_fold = 1,
        n_iteration = 5,
        ms2_ppm = True, ms2_tol=30,
        **sklearn_kwargs
    ):
        if score_model == LogisticRegression:
            self.model = LogisticRegression(solver='liblinear', **sklearn_kwargs)
        else:
            self.model = score_model(**sklearn_kwargs)
        self.cv_fold = cv_fold
        self.n_iter = n_iteration
        self.feature_extractor = ScoreFeatureExtractor(
            ppm=ms2_ppm, tol=ms2_tol
        )

    def _estimate_q_value(self, df, fdr_level='spectrum'):
        df = df.sort_values(['ML_score','decoy'], ascending=False)
        df = df.reset_index(drop=True)
        if fdr_level == 'spectrum':
            target_values = 1-df['decoy'].values
            decoy_cumsum = np.cumsum(df['decoy'].values)
            target_cumsum = np.cumsum(target_values)
            fdr_values = decoy_cumsum/target_cumsum
            df['q_value'] = fdr_to_q_values(fdr_values)
        else:
            if fdr_level == 'precursor':
                _df = df.groupby([
                    'sequence','mods','mod_sites','charge','decoy'
                ])['ML_score'].max()
            elif fdr_level == 'peptide':
                _df = df.groupby([
                    'sequence','mods','mod_sites','decoy'
                ])['ML_score'].max()
            else:
                _df = df.groupby(['sequence','decoy'])['ML_score'].max()
            _df = _df.reset_index()
            _df = _df.sort_values(['ML_score','decoy'], ascending=False)
            target_values = 1-_df['decoy'].values
            decoy_cumsum = np.cumsum(_df['decoy'].values)
            target_cumsum = np.cumsum(target_values)
            fdr_values = decoy_cumsum/target_cumsum
            _df['q_value'] = fdr_to_q_values(fdr_values)
            df['q_value'] = score_to_q_value(
                df['ML_score'].values, _df['ML_score'].values,
                _df['q_value'].values
            )
        return df

    def _cv_score(self, df):
        df = df.sample(frac=1).reset_index(drop=True)
        df_target = df[df['decoy'] == 0]
        df_decoy = df[df['decoy'] == 1]

        if self.cv_fold > 1:
            test_df_list = []
            for i in range(self.cv_fold):
                t_mask = np.ones(len(df_target), dtype=bool)
                _slice = slice(i, len(df_target), self.cv_fold)
                t_mask[_slice] = False
                cv_df_target = df_target[t_mask]
                train_t_df = cv_df_target[cv_df_target['q_value'] <= self.fdr]
                test_t_df = df_target[_slice]

                d_mask = np.ones(len(df_decoy), dtype=bool)
                _slice = slice(i, len(df_decoy), self.cv_fold)
                d_mask[_slice] = False
                train_d_df = df_decoy[d_mask]
                test_d_df = df_decoy[_slice]

                train_df = pd.concat((train_t_df, train_d_df))
                train_label = np.ones(len(train_df))
                train_label[len(train_t_df):] = 0
                test_df = pd.concat((test_t_df, test_d_df))

                if self.model == LogisticRegression:
                    _model = self.model(solver='liblinear')
                else:
                    _model = self.model()
                _model.fit(train_df[self.feature_list].values, train_label)
                if settings['percolator']['model'] in ['svm','lr']:
                    test_df['ML_score'] = _model.decision_function(test_df[self.feature_list].values)
                else:
                    test_df['ML_score'] = _model.predict_proba(test_df[self.feature_list].values)[:,1]
                test_df_list.append(test_df)

            return pd.concat(test_df_list)
        else:
            train_t_df = df_target[df_target['q_value'] <= self.fdr]

            train_df = pd.concat((train_t_df, df_decoy))
            train_label = np.ones(len(train_df))
            train_label[len(train_t_df):] = 0
            test_df = pd.concat((df_target, df_decoy))

            if self.model == LogisticRegression:
                _model = self.model(solver='liblinear')
            else:
                _model = self.model()
            _model.fit(train_df[self.feature_list].values, train_label)
            if settings['percolator']['model'] in ['svm','lr']:
                test_df['ML_score'] = _model.decision_function(test_df[self.feature_list].values)
            else:
                test_df['ML_score'] = _model.predict_proba(test_df[self.feature_list].values)[:,1]

            return test_df

    def alphapept_score(self, df, nce, instrument):
        from alphapept.score import filter_with_ML, train_RF
        exclude_features = ['sequence', 'precursor', 'raw_name', 'rt', 'scan', 'mobility',
                'peptide', 'modinfo', 'decoy','query_idx', 'db_idx','naked_sequence']
        df = self._extract_features(df, nce, instrument)
        cv, features = train_RF(df, exclude_features)
        df = filter_with_ML(df, cv, features = features)
        df['ML_score'] = df['score']
        return df

    def re_score(self, df, nce, instrument):
        df = self._extract_features(df, nce, instrument)
        df['ML_score'] = df['score']
        df = self._estimate_q_value(df, self.fdr_level)
        logging.info(f'{len(df[(df["q_value"]<=self.fdr) & (df["decoy"]==0)])} target PSMs at {self.fdr} spectrum-level FDR')
        for i in range(self.n_iter):
            logging.info(f'Iteration {i+1} of Percolator ...')
            df = self._cv_score(df)
            df = self._estimate_q_value(df)
            logging.info(f'{len(df[(df["q_value"]<=self.fdr) & (df["decoy"]==0)])} target PSMs at {self.fdr} spectrum-level FDR')
        df = self._estimate_q_value(df, self.fdr_level)
        logging.info(f'{len(df[(df["q_value"]<=self.fdr) & (df["decoy"]==0)])} target PSMs at {self.fdr} {self.fdr_level}-level FDR')
        return df